"""
Large model processor for Heightcraft.

This module provides the LargeModelProcessor class for processing large 3D models
with memory-efficient techniques.
"""

import gc
import logging
import os
import tempfile
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Optional, Tuple, Union

import numpy as np
import trimesh

from heightcraft.core.config import ApplicationConfig, ModelConfig, SamplingConfig
from heightcraft.core.config import ApplicationConfig
from heightcraft.core.exceptions import ProcessingError, SamplingError, ModelLoadError, HeightMapGenerationError
from heightcraft.domain.height_map import HeightMap
from heightcraft.domain.mesh import Mesh
from heightcraft.domain.point_cloud import PointCloud
from heightcraft.infrastructure.cache_manager import CacheManager
from heightcraft.infrastructure.gpu_manager import gpu_manager
from heightcraft.infrastructure.profiler import profiler
from heightcraft.processors.base_processor import BaseProcessor
from heightcraft.services.mesh_service import MeshService
from heightcraft.services.model_service import ModelService
from heightcraft.services.height_map_service import HeightMapService
from heightcraft.services.sampling_service import SamplingService
from heightcraft.services.point_cloud_service import PointCloudService
from heightcraft.utils.threading import ThreadPool


class LargeModelProcessor(BaseProcessor):
    """
    Processor for large 3D models with memory-efficient techniques.
    
    This processor implements memory-efficient techniques for loading,
    sampling, and processing large 3D models that may not fit in memory.
    """
    
    def __init__(self, config: ApplicationConfig):
        """
        Initialize the processor.
        
        Args:
            config: Application configuration
        """
        super().__init__(config)
        
        # Initialize services
        self.mesh_service = MeshService()
        self.model_service = ModelService()
        self.height_map_service = HeightMapService()
        self.sampling_service = SamplingService(self.sampling_config)
        
        # Lazy import to avoid TensorFlow overhead/crashes
        from heightcraft.services.upscaling_service import UpscalingService
        self.upscaling_service = UpscalingService(
            config=config.upscale_config,
            cache_manager=None,  # We'll set this later if cache is enabled
            height_map_service=self.height_map_service
        )
        
        # Initialize cache manager
        self.cache_manager = None
        if self.model_config.cache_dir:
            self.cache_manager = CacheManager(self.model_config.cache_dir)
            # Update upscaling service with cache manager
            self.upscaling_service.cache_manager = self.cache_manager
        
        # Initialize other required attributes
        self.mesh = None
        self.points = None
        self.height_map = None
        self.bounds = {}
        self.chunks = []
        self._temp_files = []  # List to track temporary files
        
        # Logging
        self.logger.info(f"Initialized LargeModelProcessor for large model processing")
        
        # Use the chunk size from the configuration
        self.chunk_size = self.model_config.chunk_size
        self.logger.info(f"Using chunk size: {self.chunk_size}")
        
        # Initialize state
        self.is_scene = False
        self.vertex_buffer = None
        self.face_buffer = None
    
    @profiler.profile()
    def load_model(self) -> None:
        """
        Load a 3D model with memory-efficient techniques.
        
        Raises:
            ModelLoadError: If the model cannot be loaded
        """
        try:
            self.logger.info(f"Loading large model from {self.model_config.file_path}")
            
            # Load the model
            raw_mesh = trimesh.load(self.model_config.file_path, process=False)
            
            # Check if it's a scene
            if isinstance(raw_mesh, trimesh.Scene):
                self.is_scene = True
                self.logger.info("Detected a scene with multiple meshes")
                self._process_scene(raw_mesh)
            else:
                self.is_scene = False
                self.logger.info("Detected a single mesh")
                self._process_single_mesh(raw_mesh)
            
            # Force garbage collection
            gc.collect()
            
            self.logger.info("Model loading complete")
            
        except Exception as e:
            raise ModelLoadError(f"Failed to load model: {e}")
    
    @profiler.profile()
    def _process_scene(self, scene: trimesh.Scene) -> None:
        """
        Process a scene with multiple meshes.
        
        Args:
            scene: The scene to process
            
        Raises:
            ModelLoadError: If the scene cannot be processed
        """
        # Clear existing state
        self.chunks = []
        self.vertex_buffer = None
        self.face_buffer = None
        
        try:
            # Get geometry count
            geometry_count = len(scene.geometry)
            self.logger.info(f"Processing scene with {geometry_count} geometries")
            
            # Initialize vertex buffer
            self.vertex_buffer = []
            vertex_offset = 0
            
            # Process each geometry in chunks
            with ThreadPool(max_workers=self.sampling_config.num_threads) as pool:
                for node_name in scene.graph.nodes_geometry:
                    # Get geometry
                    transform, geometry_name = scene.graph[node_name]
                    mesh = scene.geometry[geometry_name]
                    
                    self.logger.info(f"Processing node {node_name} with {len(mesh.vertices)} vertices")
                    
                    # Process vertices in chunks
                    vertex_chunks = np.array_split(
                        mesh.vertices,
                        max(1, len(mesh.vertices) // self.chunk_size)
                    )
                    
                    # Transform and store vertices
                    for chunk in vertex_chunks:
                        transformed_chunk = trimesh.transform_points(chunk, transform)
                        self.vertex_buffer.append(transformed_chunk)
                    
                    # Process faces with offset
                    face_chunks = np.array_split(
                        mesh.faces,
                        max(1, len(mesh.faces) // self.chunk_size)
                    )
                    
                    for chunk in face_chunks:
                        offset_chunk = chunk + vertex_offset
                        self.chunks.append({
                            "vertices": len(self.vertex_buffer) - len(vertex_chunks),
                            "vertex_count": len(vertex_chunks),
                            "faces": offset_chunk,
                            "vertex_offset": vertex_offset
                        })
                    
                    # Update vertex offset
                    vertex_offset += len(mesh.vertices)
            
            # Skip creating a sample mesh as it can cause index out of bounds errors
            # if vertex and face chunks are not aligned.
            # self.mesh is not used for large model processing logic.
            self.mesh = None
            
            # Center and align
            self._center_and_align()
            
            self.logger.info(f"Scene processing complete: {vertex_offset} vertices, {len(self.chunks)} chunks")
            
        except Exception as e:
            raise ModelLoadError(f"Failed to process scene: {e}")
    
    @profiler.profile()
    def _process_single_mesh(self, mesh: trimesh.Trimesh) -> None:
        """
        Process a single large mesh.
        
        Args:
            mesh: The mesh to process
            
        Raises:
            ModelLoadError: If the mesh cannot be processed
        """
        # Clear existing state
        self.chunks = []
        self.vertex_buffer = None
        self.face_buffer = None
        
        try:
            # Process in chunks
            vertex_chunks = np.array_split(
                mesh.vertices,
                max(1, len(mesh.vertices) // self.chunk_size)
            )
            
            face_chunks = np.array_split(
                mesh.faces,
                max(1, len(mesh.faces) // self.chunk_size)
            )
            
            # Store vertices
            self.vertex_buffer = vertex_chunks
            
            # Store face chunks
            for i, chunk in enumerate(face_chunks):
                self.chunks.append({
                    "vertices": 0,
                    "vertex_count": len(vertex_chunks),
                    "faces": chunk,
                    "vertex_offset": 0
                })
            
            # Skip creating a sample mesh as it can cause index out of bounds errors
            # if vertex and face chunks are not aligned.
            # self.mesh is not used for large model processing logic.
            self.mesh = None
            
            # Center and align
            self._center_and_align()
            
            self.logger.info(f"Mesh processing complete: {len(mesh.vertices)} vertices, {len(self.chunks)} chunks")
            
        except Exception as e:
            raise ModelLoadError(f"Failed to process mesh: {e}")
    
    @profiler.profile()
    def _center_and_align(self) -> None:
        """
        Center and align the model.
        
        This operation affects all vertices in the buffer.
        
        Note:
            We implement custom centering and alignment logic here instead of using
            MeshService because the model is loaded in chunks (vertex_buffer).
            MeshService expects a complete Mesh object, which we avoid creating
            to save memory.
        """
        # Calculate centroid from first vertex chunk
        if self.vertex_buffer and len(self.vertex_buffer) > 0:
            sample_vertices = self.vertex_buffer[0]
            centroid = np.mean(sample_vertices, axis=0)
            
            # Center each vertex chunk
            self.logger.info(f"Centering model by translating by {-centroid}")
            for i in range(len(self.vertex_buffer)):
                self.vertex_buffer[i] = self.vertex_buffer[i] - centroid
            
            # Align to XY plane
            self.logger.info("Aligning model to XY plane")
            rotation = trimesh.transformations.rotation_matrix(np.pi / 2, [1, 0, 0])
            for i in range(len(self.vertex_buffer)):
                self.vertex_buffer[i] = trimesh.transform_points(self.vertex_buffer[i], rotation)
                
            # Calculate global bounds after transformation
            self._calculate_global_bounds()
            
    def _calculate_global_bounds(self) -> None:
        """Calculate global bounds from all vertex chunks."""
        min_x, min_y, min_z = float('inf'), float('inf'), float('inf')
        max_x, max_y, max_z = float('-inf'), float('-inf'), float('-inf')
        
        for chunk in self.vertex_buffer:
            if len(chunk) == 0:
                continue
                
            c_min = np.min(chunk, axis=0)
            c_max = np.max(chunk, axis=0)
            
            min_x = min(min_x, c_min[0])
            min_y = min(min_y, c_min[1])
            min_z = min(min_z, c_min[2])
            
            max_x = max(max_x, c_max[0])
            max_y = max(max_y, c_max[1])
            max_z = max(max_z, c_max[2])
            
        self.bounds = {
            "min_x": min_x, "max_x": max_x,
            "min_y": min_y, "max_y": max_y,
            "min_z": min_z, "max_z": max_z
        }
        self.logger.info(f"Calculated global bounds: {self.bounds}")
    
    @profiler.profile()
    def sample_points(self) -> Union[np.ndarray, object]:
        """
        Sample points from the model with memory-efficient techniques.
        
        Returns:
            Generator yielding chunks of sampled points
            
        Raises:
            SamplingError: If point sampling fails
        """
        try:
            num_samples = self.sampling_config.num_samples
            use_gpu = self.sampling_config.use_gpu
            
            self.logger.info(f"Sampling {num_samples} points from the large model")
            
            # Handle normal sampling
            if self.is_scene:
                return self._sample_points_from_scene(num_samples, use_gpu)
            else:
                return self._sample_points_from_chunks(num_samples, use_gpu)
            
        except Exception as e:
            raise SamplingError(f"Failed to sample points: {e}")
    
    @profiler.profile()
    def _sample_points_from_scene(self, num_samples: int, use_gpu: bool):
        """
        Sample points from a scene.
        
        Args:
            num_samples: Number of points to sample
            use_gpu: Whether to use GPU for sampling
            
        Yields:
            Chunks of sampled points
        """
        # Calculate area for each geometry to distribute samples proportionally
        total_faces = sum(len(chunk["faces"]) for chunk in self.chunks)
        
        if total_faces == 0:
            return
            
        # Distribute samples proportionally to face count
        samples_per_chunk = []
        for chunk in self.chunks:
            face_ratio = len(chunk["faces"]) / total_faces
            chunk_samples = max(1, int(num_samples * face_ratio))
            samples_per_chunk.append(chunk_samples)
        
        # Adjust to ensure we get exactly num_samples
        total_assigned = sum(samples_per_chunk)
        if total_assigned < num_samples:
            # Add remaining samples to the largest chunk
            largest_idx = samples_per_chunk.index(max(samples_per_chunk))
            samples_per_chunk[largest_idx] += num_samples - total_assigned
        elif total_assigned > num_samples:
            # Remove excess samples from the largest chunk
            largest_idx = samples_per_chunk.index(max(samples_per_chunk))
            samples_per_chunk[largest_idx] -= total_assigned - num_samples
        
        # Sample points from each chunk
        # If using GPU, process chunks sequentially to avoid OOM
        max_workers = 1 if use_gpu else self.sampling_config.num_threads
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = []
            
            for i, (chunk, chunk_samples) in enumerate(zip(self.chunks, samples_per_chunk)):
                if chunk_samples <= 0:
                    continue
                
                self.logger.debug(f"Sampling {chunk_samples} points from chunk {i+1}/{len(self.chunks)}")
                
                # Submit task
                futures.append(executor.submit(
                    self._process_chunk_sampling,
                    chunk,
                    chunk_samples,
                    use_gpu
                ))
            
            # Yield results as they complete
            for future in as_completed(futures):
                try:
                    chunk_points = future.result()
                    if chunk_points.size > 0:
                        yield chunk_points.points
                    
                    # Explicit cleanup
                    del chunk_points
                    gc.collect()
                except Exception as e:
                    self.logger.error(f"Error sampling chunk: {e}")
    
    def _process_chunk_sampling(self, chunk, chunk_samples, use_gpu):
        """Helper method for parallel chunk sampling."""
        # Create a mesh for this chunk
        vertices = np.vstack(self.vertex_buffer[chunk["vertices"]:chunk["vertices"] + chunk["vertex_count"]])
        faces = chunk["faces"] - chunk["vertex_offset"]
        chunk_mesh = Mesh(trimesh.Trimesh(vertices=vertices, faces=faces))
        
        # Sample points
        return self.sampling_service.sample_points(
            chunk_mesh, chunk_samples, use_gpu, 
            1 # Use 1 thread per chunk since we parallelize chunks
        )
    
    @profiler.profile()
    def _sample_points_from_chunks(self, num_samples: int, use_gpu: bool):
        """
        Sample points from mesh chunks.
        
        Args:
            num_samples: Number of points to sample
            use_gpu: Whether to use GPU for sampling
            
        Yields:
            Chunks of sampled points
        """
        # Calculate total area to distribute samples proportionally
        total_area = 0.0
        chunk_areas = []
        
        # We need to calculate area for each chunk to distribute samples
        # This is a bit expensive but necessary for correct sampling density
        for chunk in self.chunks:
            # Get vertices for this chunk
            # chunk["vertices"] is the index in vertex_buffer
            # chunk["vertex_count"] is the number of arrays in vertex_buffer to use
            chunk_vertices_arrays = self.vertex_buffer[chunk["vertices"]:chunk["vertices"] + chunk["vertex_count"]]
            if not chunk_vertices_arrays:
                chunk_areas.append(0)
                continue
                
            vertices = np.vstack(chunk_vertices_arrays)
            faces = chunk["faces"] - chunk["vertex_offset"]
            
            # Create a temporary mesh for area calculation
            # We use trimesh directly to avoid overhead
            temp_mesh = trimesh.Trimesh(vertices=vertices, faces=faces, process=False)
            area = temp_mesh.area
            chunk_areas.append(area)
            total_area += area
            
            # Explicit cleanup
            del temp_mesh, vertices, faces
        
        # Distribute samples
        samples_per_chunk = []
        for area in chunk_areas:
            if total_area > 0:
                ratio = area / total_area
                samples_per_chunk.append(max(1, int(num_samples * ratio)))
            else:
                samples_per_chunk.append(0)
        
        # Adjust total samples
        current_total = sum(samples_per_chunk)
        if current_total > 0:
            if current_total < num_samples:
                # Add to largest chunk
                max_idx = samples_per_chunk.index(max(samples_per_chunk))
                samples_per_chunk[max_idx] += num_samples - current_total
            elif current_total > num_samples:
                # Remove from largest chunk
                max_idx = samples_per_chunk.index(max(samples_per_chunk))
                samples_per_chunk[max_idx] -= current_total - num_samples
        
        # Sample points from each chunk
        # If using GPU, process chunks sequentially to avoid OOM
        max_workers = 1 if use_gpu else self.sampling_config.num_threads
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = []
            
            for i, (chunk, chunk_samples) in enumerate(zip(self.chunks, samples_per_chunk)):
                if chunk_samples <= 0:
                    continue
                
                # Submit task
                futures.append(executor.submit(
                    self._process_chunk_sampling,
                    chunk,
                    chunk_samples,
                    use_gpu
                ))
                
            # Yield results as they complete
            for future in as_completed(futures):
                try:
                    chunk_points = future.result()
                    if chunk_points.size > 0:
                        yield chunk_points.points
                    
                    # Explicit cleanup
                    del chunk_points
                    gc.collect()
                except Exception as e:
                    self.logger.error(f"Error sampling chunk: {e}")
    
    @profiler.profile()
    def generate_height_map(self) -> np.ndarray:
        """
        Generate a height map from sampled points.
        
        Returns:
            Generated height map
            
        Raises:
            HeightMapGenerationError: If height map generation fails
        """
        try:
            if self.points is None:
                raise HeightMapGenerationError("No points available. Call sample_points() first.")
            
            # Calculate target resolution
            width, height = self._calculate_target_resolution()
            self.logger.info(f"Generating height map with resolution {width}x{height}")
            
            # Create buffer
            buffer = self.height_map_service.create_height_map_buffer(width, height)
            
            # Process points incrementally
            total_points = 0
            
            # Check if self.points is a generator or array
            if hasattr(self.points, '__iter__') and not isinstance(self.points, (np.ndarray, list)):
                # Generator
                for chunk_points in self.points:
                    self.height_map_service.update_height_map_buffer(
                        buffer,
                        chunk_points,
                        self.bounds,
                        width,
                        height,
                        self.sampling_config.num_threads
                    )
                    total_points += len(chunk_points)
                    self.logger.debug(f"Processed chunk with {len(chunk_points)} points")
            else:
                # Array or list
                self.height_map_service.update_height_map_buffer(
                    buffer,
                    self.points,
                    self.bounds,
                    width,
                    height,
                    self.sampling_config.num_threads
                )
                total_points = len(self.points)
            
            self.logger.info(f"Generated height map from {total_points} points")
            
            # Store the height map object for saving
            self.height_map = buffer
            
            return self.height_map
            
        except Exception as e:
            raise HeightMapGenerationError(f"Failed to generate height map: {e}")

    def upscale_height_map(self) -> None:
        """
        Upscale the generated height map.
        
        Raises:
            ProcessingError: If upscaling fails
        """
        try:
            if self.height_map is None:
                raise ProcessingError("No height map available. Call generate_height_map() first.")
            
            self.logger.info("Upscaling height map using UpscalingService")
            
            # Create HeightMap domain object
            height_map_obj = HeightMap(self.height_map, self.height_map_config.bit_depth)
            
            # Upscale using service
            upscaled_map = self.upscaling_service.upscale(
                height_map_obj,
                scale_factor=self.config.upscale_config.upscale_factor,
                use_gpu=self.config.sampling_config.use_gpu
            )
            
            # Update internal state
            self.height_map = upscaled_map.data
            
            self.logger.info(f"Height map upscaled to {self.height_map.shape}")
            
        except Exception as e:
            raise ProcessingError(f"Failed to upscale height map: {e}")
    
    @profiler.profile()
    def _calculate_target_resolution(self) -> Tuple[int, int]:
        """
        Calculate target resolution based on model bounds.
        
        Returns:
            Tuple of (width, height)
        """
        # Use ResolutionCalculator
        from heightcraft.utils.resolution_calculator import ResolutionCalculator
        calculator = ResolutionCalculator()
        
        width, height = calculator.calculate_resolution_from_bounds(
            self.bounds,
            max_resolution=self.height_map_config.max_resolution
        )
        
        self.logger.info(f"Calculated target resolution: {width}x{height}")
        
        return width, height
    
    @profiler.profile()
    def save_height_map(self, output_path: Optional[str] = None) -> str:
        """
        Save the height map to disk.
        
        Args:
            output_path: Path to save the height map (defaults to config.output_config.output_path)
            
        Returns:
            Path to the saved height map
            
        Raises:
            ProcessingError: If the height map cannot be saved
        """
        try:
            if self.height_map is None:
                raise ProcessingError("No height map available. Call generate_height_map() first.")
            
            # Use provided output path or default from config
            output_path = output_path or self.output_config.output_path
            
            # Create height map domain object
            height_map = HeightMap(self.height_map, self.height_map_config.bit_depth)
            
            # Apply Sea Level
            if self.height_map_config.sea_level is not None:
                # Convert world sea level to normalized sea level
                min_z = self.bounds.get("min_z", 0.0)
                max_z = self.bounds.get("max_z", 1.0)
                z_range = max_z - min_z
                
                if z_range <= 1e-9:
                    normalized_sea_level = 0.0
                else:
                    normalized_sea_level = (self.height_map_config.sea_level - min_z) / z_range
                
                self.logger.info(f"Applying sea level masking at {self.height_map_config.sea_level} (normalized: {normalized_sea_level:.4f})")
                
                height_map, water_mask = self.height_map_service.apply_sea_level(
                    height_map, normalized_sea_level
                )
                
                # Save water mask
                mask_path = self._derive_output_path(output_path, "water_mask")
                self.logger.info(f"Saving water mask to {mask_path}")
                self.height_map_service.save_height_map(water_mask, mask_path)
            
            # Generate Slope Map
            if self.height_map_config.slope_map:
                self.logger.info("Generating slope map")
                slope_map = self.height_map_service.generate_slope_map(height_map)
                slope_path = self._derive_output_path(output_path, "slope_map")
                self.logger.info(f"Saving slope map to {slope_path}")
                self.height_map_service.save_height_map(slope_map, slope_path)
                
            # Generate Curvature Map
            if self.height_map_config.curvature_map:
                self.logger.info("Generating curvature map")
                curvature_map = self.height_map_service.generate_curvature_map(height_map)
                curvature_path = self._derive_output_path(output_path, "curvature_map")
                self.logger.info(f"Saving curvature map to {curvature_path}")
                self.height_map_service.save_height_map(curvature_map, curvature_path)
            
            # Handle splitting
            if self.height_map_config.split > 1:
                # Split height map
                split_maps = self.height_map_service.split_height_map(
                    height_map, self.height_map_config.split
                )
                
                # Save split maps
                output_dir = self.height_map_service.save_split_height_maps(
                    split_maps, output_path
                )
                
                self.logger.info(f"Split height maps saved to {output_dir}")
                return output_dir
            else:
                # Save single height map
                saved_path = self.height_map_service.save_height_map(
                    height_map, output_path
                )
                
                self.logger.info(f"Height map saved to {saved_path}")
                return saved_path
            
        except Exception as e:
            raise ProcessingError(f"Failed to save height map: {e}")
    
    @profiler.profile()
    def cleanup(self) -> None:
        """Clean up resources."""
        super().cleanup()
        
        # Clear vertex buffer
        if self.vertex_buffer:
            self.vertex_buffer.clear()
            self.vertex_buffer = None
        
        # Clear chunks
        self.chunks.clear()
        
        # Force garbage collection
        gc.collect()
    

            
 