jinx_name: alicanto
description: Deep research mode - multi-perspective exploration with gold insights and cliff warnings
npc: forenpc
inputs:
  - query: null
  - num_npcs: 5
  - depth: 3
  - model: null
  - provider: null
  - max_steps: 20
  - skip_research: true
  - exploration: 0.3
  - creativity: 0.5
  - format: report

steps:
  - name: alicanto_research
    engine: python
    code: |
      import os
      from termcolor import colored

      from npcpy.llm_funcs import get_llm_response
      from npcpy.data.web import search_web
      from npcpy.npc_compiler import NPC

      npc = context.get('npc')
      team = context.get('team')
      messages = context.get('messages', [])

      query = context.get('query')
      num_npcs = int(context.get('num_npcs', 5))
      depth = int(context.get('depth', 3))
      max_steps = int(context.get('max_steps', 20))
      skip_research = context.get('skip_research', True)
      exploration = float(context.get('exploration', 0.3))
      creativity = float(context.get('creativity', 0.5))
      output_format = context.get('format', 'report')

      model = context.get('model') or (npc.model if npc else 'gemini-1.5-pro')
      provider = context.get('provider') or (npc.provider if npc else 'gemini')

      if not query:
          context['output'] = """Usage: /alicanto <research query>

      Options:
        --num-npcs N      Number of research perspectives (default: 5)
        --depth N         Research depth (default: 3)
        --max-steps N     Maximum research steps (default: 20)
        --exploration F   Exploration factor 0-1 (default: 0.3)
        --creativity F    Creativity factor 0-1 (default: 0.5)
        --format FORMAT   Output: report|summary|full (default: report)

      Example: /alicanto What are the latest advances in quantum computing?"""
          context['messages'] = messages
          exit()

      print(f"""
       █████╗ ██╗     ██╗ ██████╗ █████╗ ███╗   ██╗████████╗ ██████╗
      ██╔══██╗██║     ██║██╔════╝██╔══██╗████╗  ██║╚══██╔══╝██╔═══██╗
      ███████║██║     ██║██║     ███████║██╔██╗ ██║   ██║   ██║   ██║
      ██╔══██║██║     ██║██║     ██╔══██║██║╚██╗██║   ██║   ██║   ██║
      ██║  ██║███████╗██║╚██████╗██║  ██║██║ ╚████║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚══════╝╚═╝ ╚═════╝╚═╝  ╚═╝╚═╝  ╚═══╝   ╚═╝    ╚═════╝

      Deep Research Mode
      Query: {query}
      Perspectives: {num_npcs} | Depth: {depth} | Max Steps: {max_steps}
      """)

      # Generate research perspectives
      perspectives_prompt = f"""Generate {num_npcs} distinct research perspectives for investigating: "{query}"

      For each perspective, provide:
      1. Name (a descriptive title)
      2. Approach (how this perspective would investigate)
      3. Key questions to explore

      Return as a numbered list."""

      print(colored("Generating research perspectives...", "cyan"))
      resp = get_llm_response(
          perspectives_prompt,
          model=model,
          provider=provider,
          npc=npc
      )
      perspectives = str(resp.get('response', ''))
      print(perspectives)

      # Conduct web research if not skipped
      research_findings = ""
      if not skip_research:
          print(colored("\nConducting web research...", "cyan"))
          try:
              search_results = search_web(query, n_results=5)
              if search_results:
                  research_findings = "\n\nWeb Research Findings:\n"
                  for i, result in enumerate(search_results[:5], 1):
                      title = result.get('title', 'No title')
                      snippet = result.get('snippet', result.get('body', ''))[:200]
                      research_findings += f"\n{i}. {title}\n   {snippet}...\n"
                  print(colored(f"Found {len(search_results)} sources", "green"))
          except Exception as e:
              print(colored(f"Web search error: {e}", "yellow"))

      # Multi-step exploration from each perspective
      all_insights = []
      gold_insights = []  # Key valuable findings
      cliff_warnings = []  # Potential pitfalls or caveats

      for step in range(min(depth, max_steps)):
          print(colored(f"\n--- Research Depth {step + 1}/{depth} ---", "cyan"))

          explore_prompt = f"""Research query: "{query}"

      Perspectives generated:
      {perspectives}

      {research_findings}

      Previous insights: {all_insights[-3:] if all_insights else 'None yet'}

      For depth level {step + 1}:
      1. Explore deeper implications from each perspective
      2. Identify GOLD insights (valuable, non-obvious findings) - mark with [GOLD]
      3. Identify CLIFF warnings (pitfalls, caveats, risks) - mark with [CLIFF]
      4. Connect insights across perspectives

      Exploration factor: {exploration} (higher = more diverse exploration)
      Creativity factor: {creativity} (higher = more novel connections)"""

          resp = get_llm_response(
              explore_prompt,
              model=model,
              provider=provider,
              temperature=creativity,
              npc=npc
          )

          step_insights = str(resp.get('response', ''))
          print(step_insights)

          # Extract gold and cliff markers
          if '[GOLD]' in step_insights:
              gold_insights.extend([line.strip() for line in step_insights.split('\n') if '[GOLD]' in line])
          if '[CLIFF]' in step_insights:
              cliff_warnings.extend([line.strip() for line in step_insights.split('\n') if '[CLIFF]' in line])

          all_insights.append(step_insights)

      # Generate final synthesis
      print(colored("\n--- Synthesizing Research ---", "cyan"))

      synthesis_prompt = f"""Synthesize research on: "{query}"

      All insights gathered:
      {chr(10).join(all_insights)}

      Gold insights identified:
      {chr(10).join(gold_insights) if gold_insights else 'None explicitly marked'}

      Cliff warnings identified:
      {chr(10).join(cliff_warnings) if cliff_warnings else 'None explicitly marked'}

      Generate a {output_format} that:
      1. Summarizes key findings
      2. Highlights the most valuable insights (gold)
      3. Notes important caveats and risks (cliffs)
      4. Provides actionable conclusions"""

      resp = get_llm_response(
          synthesis_prompt,
          model=model,
          provider=provider,
          npc=npc
      )

      final_report = str(resp.get('response', ''))
      print("\n" + "="*60)
      print(colored("ALICANTO RESEARCH REPORT", "green", attrs=['bold']))
      print("="*60)
      print(final_report)

      context['output'] = final_report
      context['messages'] = messages
      context['alicanto_result'] = {
          'query': query,
          'perspectives': perspectives,
          'insights': all_insights,
          'gold': gold_insights,
          'cliffs': cliff_warnings,
          'report': final_report
      }
