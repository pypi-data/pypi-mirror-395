torch
numpy
packaging>=24.2

[dev]
transformer-engine[core_cu13,pytorch]<2.10.0,>=2.9.0a0
nvidia-resiliency-ext
tqdm
einops~=0.8
tensorstore!=0.1.46,!=0.1.72,~=0.1
nvtx~=0.2
multi-storage-client~=0.27
opentelemetry-api~=1.33.1
mamba-ssm~=2.2
causal-conv1d~=1.5
nv-grouped-gemm~=1.1
megatron-energon[av_decode]~=6.0
av
flashinfer-python
wget
onnxscript
fastapi~=0.50
datasets

[dev:sys_platform != "darwin"]
nvidia-modelopt[torch]

[lts]
tqdm
einops~=0.8
tensorstore!=0.1.46,!=0.1.72,~=0.1
nvtx~=0.2
multi-storage-client~=0.27
opentelemetry-api~=1.33.1
mamba-ssm~=2.2
causal-conv1d~=1.5
nv-grouped-gemm~=1.1
megatron-energon[av_decode]~=6.0
av
flashinfer-python
wget
onnxscript
fastapi~=0.50
datasets

[mlm]
flask-restful
sentencepiece
tiktoken
wandb
transformers
