import time

import numpy as np
import jax
import jax.numpy as jnp
import scipy.linalg as la
import jax.random as jr
import cvxpy as cvx
import equinox as eqx

try:
    from nvmath.sparse.advanced import DirectSolver
except ImportError:
    DirectSolver = None

from diffqcp import DeviceQCP, QCPStructureGPU
from .helpers import (quad_data_and_soln_from_qcp_coo as quad_data_and_soln_from_qcp,
                      scsr_to_bcsr, QCPProbData, get_zeros_like_csr)

def test_least_squares(getkey):
    """
    The least squares (approximation) problem

        minimize    ||Ax - b||^2,

        <=>

        minimize    ||r||^2
        subject to  r = Ax - b,

    where A is a (m x n)-matrix with rank A = n, has
    the analytical solution

        x^star = (A^T A)^-1 A^T b.

    Considering x^star as a function of b, we know

        Dx^star(b) = (A^T A)^-1 A^T.

    This test checks the accuracy of `diffqcp`'s derivative computations by
    comparing DS(Data)dData to Dx^star(b)db.

    **Notes:**
    - `dData == (0, 0, 0, db)`, and other canonicalization considerations must be made
    (hence the `data_and_soln_from_cvxpy_problem` function call and associated data declaration.)
    """

    # TODO(quill): update the testing to follow best practices

    np.random.seed(0)

    for i in range(10):
        print(f"iteration {i}")
        np.random.seed(0)
        n = np.random.randint(low=10, high=15)
        m = n + np.random.randint(low=5, high=15)
        # n = np.random.randint(low=1_000, high=1_500)
        # m = n + np.random.randint(low=500, high=1_000)

        A = np.random.randn(m, n)
        b = np.random.randn(m)

        x = cvx.Variable(n)
        r = cvx.Variable(m)
        f0 = cvx.sum_squares(r)
        problem = cvx.Problem(cvx.Minimize(f0), [r == A@x - b])

        data = QCPProbData(problem)

        P = scsr_to_bcsr(data.Pcsr)
        A_orig = A
        A = scsr_to_bcsr(data.Acsr)
        q = jnp.array(data.q)
        b_orig = b
        b = jnp.array(data.b)
        x = jnp.array(data.x)
        y = jnp.array(data.y)
        s = jnp.array(data.s)

        qcp_struc = QCPStructureGPU(P, A, data.scs_cones)
        qcp = DeviceQCP(P, A, q, b, x, y, s, qcp_struc)

        dP = get_zeros_like_csr(data.Pcsr)
        dP = scsr_to_bcsr(dP)
        dA = get_zeros_like_csr(data.Acsr)
        dA = scsr_to_bcsr(dA)
        assert b_orig.size == b.size
        np.testing.assert_allclose(-b_orig, b) # sanity check
        db = jr.normal(getkey(), shape=jnp.size(b))
        dq = jnp.zeros_like(q)

        Dx_b = jnp.array(la.solve(A_orig.T @ A_orig, A_orig.T))
        
        true_result = Dx_b @ db

        # patdb.debug()

        # assert jnp.allclose(true_result, dx[m:], atol=1e-8)

        # assert False # DEBUG

        def is_array_and_dtype(dtype):
            def _predicate(x):
                return isinstance(x, jax.Array) and jnp.issubdtype(x.dtype, dtype)
            return _predicate

        # Partition qcp into (traced, static) components
        qcp_traced, qcp_static = eqx.partition(qcp, is_array_and_dtype(jnp.floating))

        # Partition inputs similarly
        jvp_inputs = (dP, dA, dq, -db, "jax-lsmr")
        inputs_traced, inputs_static = eqx.partition(jvp_inputs, is_array_and_dtype(jnp.floating))

        # Define a wrapper that takes only the traced inputs
        def jvp_wrapped(qcp_traced, inputs_traced):
            # Recombine with the static parts
            qcp_full = eqx.combine(qcp_traced, qcp_static)
            inputs_full = eqx.combine(inputs_traced, inputs_static)
            return qcp_full.jvp(*inputs_full)

        # Compile it
        jvp_compiled = eqx.filter_jit(jvp_wrapped)

        # print out static vs traced inputs
        
        # Call it
        start = time.perf_counter()
        dx, dy, ds = jvp_compiled(qcp_traced, inputs_traced)
        dx.block_until_ready()
        end = time.perf_counter()
        print(f"compile + solve time = {end - start}..")

        start = time.perf_counter()
        dx, dy, ds = jvp_compiled(qcp_traced, inputs_traced)
        # tol = jnp.abs(dx)
        dx.block_until_ready()
        end = time.perf_counter()
        print(f"solve only time = {end - start}..")

        true_result = Dx_b @ db

        print("true result shape: ", jnp.shape(true_result))
        print("dx shape: ", jnp.shape(dx[m:]))

        print("SMALL TRUTH: ", Dx_b @ (1e-6 * db))
        print("REAL TRUTH: ", true_result)
        print("COMPUTED: ", dx[m:])
        
        assert jnp.allclose(dx[m:], true_result, atol=1e-6)

def test_least_squares_direct_solve(getkey):
    """
    The least squares (approximation) problem

        minimize    ||Ax - b||^2,

        <=>

        minimize    ||r||^2
        subject to  r = Ax - b,

    where A is a (m x n)-matrix with rank A = n, has
    the analytical solution

        x^star = (A^T A)^-1 A^T b.

    Considering x^star as a function of b, we know

        Dx^star(b) = (A^T A)^-1 A^T.

    This test checks the accuracy of `diffqcp`'s derivative computations by
    comparing DS(Data)dData to Dx^star(b)db.

    **Notes:**
    - `dData == (0, 0, 0, db)`, and other canonicalization considerations must be made
    (hence the `data_and_soln_from_cvxpy_problem` function call and associated data declaration.)
    """

    # NOTE(quill): this is a bit sloppy; asserting first device is a
    #   gpu device.
    jax_gpu_enabled = jax.devices()[0].platform == "gpu"
    if DirectSolver is not None and jax_gpu_enabled:
        solvers = ["jax-lu", "nvmath-direct"]
    else:
        solvers = ["jax-lu"]
    
    for solve_method in solvers:
        np.random.seed(0)
        for i in range(10):
            print(f"== iteration {i} ===")
            print("!!! JAX devices: ", jax.devices())
            np.random.seed(0)
            n = np.random.randint(low=10, high=15)
            m = n + np.random.randint(low=5, high=15)
            # n = np.random.randint(low=1_000, high=1_500)
            # m = n + np.random.randint(low=500, high=1_000)

            A = np.random.randn(m, n)
            b = np.random.randn(m)

            x = cvx.Variable(n)
            r = cvx.Variable(m)
            f0 = cvx.sum_squares(r)
            problem = cvx.Problem(cvx.Minimize(f0), [r == A@x - b])

            data = QCPProbData(problem)

            P = scsr_to_bcsr(data.Pcsr)
            A_orig = A
            A = scsr_to_bcsr(data.Acsr)
            q = jnp.array(data.q)
            b_orig = b
            b = jnp.array(data.b)
            x = jnp.array(data.x)
            y = jnp.array(data.y)
            s = jnp.array(data.s)

            qcp_struc = QCPStructureGPU(P, A, data.scs_cones)
            qcp = DeviceQCP(P, A, q, b, x, y, s, qcp_struc)

            print("N = ", qcp_struc.N)
            print("n = ", qcp_struc.n)
            print("m = ", qcp_struc.m)

            dP = get_zeros_like_csr(data.Pcsr)
            dP = scsr_to_bcsr(dP)
            dA = get_zeros_like_csr(data.Acsr)
            dA = scsr_to_bcsr(dA)
            assert b_orig.size == b.size
            np.testing.assert_allclose(-b_orig, b) # sanity check
            db = jr.normal(getkey(), shape=jnp.size(b))
            dq = jnp.zeros_like(q)

            Dx_b = jnp.array(la.solve(A_orig.T @ A_orig, A_orig.T))
            
            true_result = Dx_b @ db

            dx, _, _ = qcp.jvp(dP, dA, dq, -db, solve_method=solve_method)

            print("true result shape: ", jnp.shape(true_result))
            print("dx shape: ", jnp.shape(dx[m:]))
            
            assert jnp.allclose(dx[m:], true_result, atol=1e-8)