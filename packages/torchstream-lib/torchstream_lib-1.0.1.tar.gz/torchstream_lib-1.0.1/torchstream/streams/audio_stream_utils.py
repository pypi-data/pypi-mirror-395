import math
from typing import Iterator, Optional

import numpy as np
import torch
from torch.nn import functional as F
from torchaudio.transforms import Resample


class TorchaudioResampleStream(Stream, Resample):
    """
    Audio stream that performs torchaudio's resampling to yield audio at a new sample rate.

    Perfs on a 10s audio segment:
    22050 -> 16000:
        ResamplingAudioStream:  48ms
        Librosa kaiser_best:   141ms
        Librosa kaiser_fast:    33ms
        Scipy resample_poly:     6ms
    22050 -> 44100:
        ResamplingAudioStream:  15ms
        Librosa kaiser_best:   293ms
        Librosa kaiser_fast:    65ms
        Scipy resample_poly:    11ms
    """
    def __init__(self, orig_sr: int, target_sr: int):
        Resample.__init__(
            self,
            orig_sr,
            target_sr,
            resampling_method="kaiser_window",
            lowpass_filter_width=64,
            rolloff=0.9475937167399596,
            beta=14.769656459379492
        )

        Stream.__init__(self)

        if orig_sr != target_sr:
            assert self.kernel.numel() < 1_000_000, "Absurd kernel size for resampling, change the target sample rate."
            self.win_size = self.kernel.size(2)
            self.stride = int(self.orig_freq) // self.gcd
            self.overlap = self.win_size - self.stride
            self.out_channels = int(self.new_freq) // self.gcd
            self._in_buff = np.zeros(self.width, dtype=np.float32)
        else:
            self._in_buff = np.zeros(0, dtype=np.float32)
        self._out_buff = np.empty(0, dtype=np.float32)

        self.n_samples_in = 0
        self.n_samples_out = 0

    def resampled_size(self, wav_len: int) -> Optional[int]:
        """
        Returns the exact size of the resampled audio given the length of an input audio.
        """
        if self.orig_freq == self.new_freq:
            return wav_len
        return int(math.ceil(self.out_channels * wav_len / self.stride))

    def _max_out_size(self, extra_in_size: int, with_input_close: bool) -> Optional[int]:
        # See how much samples we'd get from doing the resampling step
        in_len = len(self._in_buff) + extra_in_size
        if self.orig_freq == self.new_freq:
            from_resampling = in_len
        else:
            if with_input_close:
                in_len += self.width + self.stride
            n_steps = max(0, in_len - self.win_size + self.stride) // self.stride
            from_resampling = n_steps * self.out_channels

        # Account for the leftover we might have in the output buffer
        total = from_resampling + len(self._out_buff)

        # We don't want to excess the expected resampled size. Extra output generated by padding needs to be trimmed,
        # so we must exclude it from this computation.
        return min(total, self.resampled_size(self.n_samples_in + extra_in_size) - self.n_samples_out)

    def _feed(self, wav: np.ndarray):
        self._in_buff = np.append(self._in_buff, wav.astype(np.float32))
        self.n_samples_in += len(wav)

    def _on_input_closed(self):
        if self.orig_freq != self.new_freq:
            pad_size = self.width + self.stride
            self._in_buff = np.append(self._in_buff, np.zeros(pad_size, dtype=np.float32))

    def _step(self, out_size: Optional[int]):
        # Trivial case with no resampling
        if self.orig_freq == self.new_freq:
            out = self._in_buff[:out_size]
            self._in_buff = self._in_buff[out_size:]

            self.n_samples_out += len(out)
            return out

        # See how many samples we want to take from the input buffer
        resample_min_out_size = out_size - len(self._out_buff)
        n_steps = int(np.ceil(resample_min_out_size / self.out_channels))
        if n_steps > 0:
            in_size = (n_steps - 1) * self.stride + self.win_size
            assert in_size <= len(self._in_buff), "Internal error"

            # Take the samples from the input buffer
            conv_input = torch.from_numpy(self._in_buff[:in_size])[None, None, :]
            self._in_buff = self._in_buff[in_size - self.overlap:]

            # Resample the audio
            resampled = F.conv1d(conv_input, self.kernel, stride=self.stride)
            assert resampled.shape[2] == n_steps, "Internal error"
            resampled = resampled.transpose(1, 2).flatten().numpy()
            self._out_buff = np.append(self._out_buff, resampled)

        # Deal with the output buffer for when we're holding onto outputs
        assert len(self._out_buff) >= out_size, "Internal error"
        out = self._out_buff[:out_size]
        self._out_buff = self._out_buff[out_size:]

        # Because we have defined max_out_size to not go beyond the expected resampled size, we are guaranteed that
        # we've reached it once we are no longer running. We verify that here.
        self.n_samples_out += len(out)
        if not self.running:
            assert self.n_samples_out == self.resampled_size(self.n_samples_in), "Internal error"

        return out
