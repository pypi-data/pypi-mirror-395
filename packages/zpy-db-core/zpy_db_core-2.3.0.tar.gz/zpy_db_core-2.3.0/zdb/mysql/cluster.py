# ðŸ›¸ Generated by zPy
"""
MySQL Cluster Connection Pool for AWS Lambda
Multi-node connection pooling optimized for read/write split and multi-region clusters.

This module provides connection pooling for MySQL clusters with separate
reader and writer endpoints, optimized for Lambda's execution model.

Features:
- Separate connections for read and write operations
- Support for multiple read replicas
- Automatic node selection based on operation type
- Connection health monitoring per node
- Fallback mechanisms for high availability
- Read replica load balancing (round-robin)

Usage:
    from zdb.mysql.cluster_pool import ZMySQLClusterPool
    from zdb.mysql import DBTypes

    # Initialize cluster with reader and writer endpoints
    db_cluster = ZMySQLClusterPool.from_cluster(
        user="myuser",
        password="mypass",
        writer_host="writer.cluster.us-east-1.rds.amazonaws.com",
        reader_hosts=[
            "reader1.cluster.us-east-1.rds.amazonaws.com",
            "reader2.cluster.us-east-1.rds.amazonaws.com"
        ],
        db_name="mydb"
    )

    # Write operation - uses writer node
    db_cluster.call_write(
        "SP_INSERT_DATA",
        list_params=[1, "value"],
        ret_type=DBTypes.integer
    )

    # Read operation - uses reader node (load balanced)
    result = db_cluster.call_read(
        "SP_GET_DATA",
        list_params=[1],
        ret_type=DBTypes.cursor,
        jsonfy=True
    )

    # Explicit node selection
    writer_conn = db_cluster.get_writer_connection()
    reader_conn = db_cluster.get_reader_connection()

    # Get cluster statistics
    stats = db_cluster.get_cluster_stats()
"""
from typing import Optional, Any, List, Dict
from mysql.connector import MySQLConnection
from mysql import connector
import logging
from enum import Enum

from .pool import SingleConnectionPool

logger = logging.getLogger(__name__)


class NodeType(Enum):
    """Database node types."""
    WRITER = "writer"
    READER = "reader"


class ClusterNodePool:
    """
    Connection pool for a single cluster node.
    
    Extends SingleConnectionPool with node metadata and health tracking.
    """

    def __init__(
        self,
        node_type: NodeType,
        host: str,
        config: dict,
        max_reconnect_attempts: int = 3,
        node_id: Optional[str] = None
    ):
        """
        Initialize cluster node pool.

        Args:
            node_type: Type of node (WRITER or READER)
            host: Node hostname
            config: MySQL connection configuration
            max_reconnect_attempts: Maximum reconnection attempts
            node_id: Optional node identifier (defaults to host)
        """
        self.node_type = node_type
        self.host = host
        self.node_id = node_id or host
        
        # Add host to config
        node_config = config.copy()
        node_config['host'] = host
        
        self.pool = SingleConnectionPool(node_config, max_reconnect_attempts)
        self._is_healthy = True
        self._failed_attempts = 0
        self._max_failed_attempts = 3

    def get_connection(self) -> MySQLConnection:
        """
        Get connection from pool with health tracking.

        Returns:
            MySQLConnection: Active connection

        Raises:
            Exception: If node is unhealthy or connection fails
        """
        try:
            conn = self.pool.get_connection()
            # Reset health on successful connection
            self._failed_attempts = 0
            self._is_healthy = True
            return conn
        except Exception as e:
            self._failed_attempts += 1
            if self._failed_attempts >= self._max_failed_attempts:
                self._is_healthy = False
                logger.error(
                    f"âŒ Node {self.node_id} ({self.node_type.value}) marked as unhealthy "
                    f"after {self._failed_attempts} failed attempts"
                )
            raise

    def is_healthy(self) -> bool:
        """Check if node is healthy."""
        return self._is_healthy

    def reset_health(self):
        """Reset node health status."""
        self._is_healthy = True
        self._failed_attempts = 0

    def get_stats(self) -> dict:
        """Get node statistics."""
        stats = self.pool.get_stats()
        stats.update({
            'node_type': self.node_type.value,
            'node_id': self.node_id,
            'host': self.host,
            'is_healthy': self._is_healthy,
            'failed_attempts': self._failed_attempts
        })
        return stats

    def close(self):
        """Close node pool."""
        self.pool.close()


class ZMySQLClusterPool:
    """
    MySQL Cluster connection pool with read/write split.

    Manages multiple connection pools for cluster nodes:
    - One writer node for write operations
    - One or more reader nodes for read operations
    - Automatic load balancing across readers (round-robin)
    - Fallback to writer if all readers fail

    Example:
        # Single reader setup
        db = ZMySQLClusterPool.from_cluster(
            user="user",
            password="pass",
            writer_host="writer.cluster.rds.amazonaws.com",
            reader_hosts=["reader.cluster.rds.amazonaws.com"],
            db_name="mydb"
        )

        # Multiple readers for load balancing
        db = ZMySQLClusterPool.from_cluster(
            user="user",
            password="pass",
            writer_host="writer.cluster.rds.amazonaws.com",
            reader_hosts=[
                "reader1.cluster.rds.amazonaws.com",
                "reader2.cluster.rds.amazonaws.com",
                "reader3.cluster.rds.amazonaws.com"
            ],
            db_name="mydb"
        )
    """

    def __init__(
        self,
        zmysql_instance,
        writer_pool: ClusterNodePool,
        reader_pools: List[ClusterNodePool],
        fallback_to_writer: bool = True
    ):
        """
        Initialize cluster pool.

        Args:
            zmysql_instance: ZMySQL instance
            writer_pool: Writer node pool
            reader_pools: List of reader node pools
            fallback_to_writer: Use writer if all readers fail
        """
        self._zmysql = zmysql_instance
        self._writer_pool = writer_pool
        self._reader_pools = reader_pools
        self._fallback_to_writer = fallback_to_writer
        self._current_reader_index = 0
        self._total_reads = 0
        self._total_writes = 0
        self._reader_fallbacks = 0

    @classmethod
    def from_cluster(
        cls,
        user: str,
        password: str,
        writer_host: str,
        reader_hosts: List[str],
        db_name: str,
        verbose: bool = False,
        connect_timeout: int = 10,
        autocommit: bool = True,
        max_reconnect_attempts: int = 3,
        fallback_to_writer: bool = True
    ):
        """
        Create cluster pool from endpoints.

        Args:
            user: MySQL username
            password: MySQL password
            writer_host: Writer endpoint hostname
            reader_hosts: List of reader endpoint hostnames
            db_name: Database name
            verbose: Enable verbose logging
            connect_timeout: Connection timeout in seconds
            autocommit: Enable autocommit
            max_reconnect_attempts: Max reconnection attempts per node
            fallback_to_writer: Use writer if all readers fail

        Returns:
            ZMySQLClusterPool: Cluster pool instance
        """
        from zdb.mysql import ZMySQL

        # Base configuration (without host)
        base_config = {
            "user": user,
            "password": password,
            "database": db_name,
            "raise_on_warnings": False,
            "autocommit": autocommit,
            "connect_timeout": connect_timeout,
        }

        # Create ZMySQL instance (uses writer by default)
        writer_config = base_config.copy()
        writer_config['host'] = writer_host
        zmysql = ZMySQL.setup(writer_config, verbose=verbose)

        # Create writer pool
        writer_pool = ClusterNodePool(
            node_type=NodeType.WRITER,
            host=writer_host,
            config=base_config,
            max_reconnect_attempts=max_reconnect_attempts,
            node_id=f"writer-{writer_host}"
        )

        # Create reader pools
        reader_pools = []
        for idx, reader_host in enumerate(reader_hosts):
            reader_pool = ClusterNodePool(
                node_type=NodeType.READER,
                host=reader_host,
                config=base_config,
                max_reconnect_attempts=max_reconnect_attempts,
                node_id=f"reader-{idx}-{reader_host}"
            )
            reader_pools.append(reader_pool)

        logger.info(
            f"âœ… Cluster pool initialized - Writer: {writer_host}, "
            f"Readers: {len(reader_pools)}"
        )

        return cls(zmysql, writer_pool, reader_pools, fallback_to_writer)

    def _get_next_reader_pool(self) -> Optional[ClusterNodePool]:
        """
        Get next healthy reader pool using round-robin.

        Returns:
            ClusterNodePool: Next reader pool, or None if all unhealthy
        """
        if not self._reader_pools:
            return None

        # Try all readers starting from current index
        attempts = 0
        while attempts < len(self._reader_pools):
            pool = self._reader_pools[self._current_reader_index]
            
            # Move to next reader for next call (round-robin)
            self._current_reader_index = (
                self._current_reader_index + 1
            ) % len(self._reader_pools)
            
            if pool.is_healthy():
                return pool
            
            attempts += 1
            logger.warning(
                f"Reader {pool.node_id} is unhealthy, trying next reader"
            )

        logger.warning("All reader nodes are unhealthy")
        return None

    def get_writer_connection(self) -> MySQLConnection:
        """
        Get connection to writer node.

        Returns:
            MySQLConnection: Writer connection

        Raises:
            Exception: If writer connection fails
        """
        return self._writer_pool.get_connection()

    def get_reader_connection(
        self,
        fallback_to_writer: Optional[bool] = None
    ) -> MySQLConnection:
        """
        Get connection to a reader node with load balancing.

        Uses round-robin load balancing across healthy readers.
        Falls back to writer if all readers are unhealthy (configurable).

        Args:
            fallback_to_writer: Override instance fallback setting

        Returns:
            MySQLConnection: Reader or writer connection

        Raises:
            Exception: If no healthy readers and fallback disabled
        """
        reader_pool = self._get_next_reader_pool()
        
        if reader_pool is not None:
            try:
                return reader_pool.get_connection()
            except Exception as e:
                logger.error(f"Failed to get reader connection: {e}")
                # Will fallback below if enabled

        # No healthy readers available
        use_fallback = (
            fallback_to_writer 
            if fallback_to_writer is not None 
            else self._fallback_to_writer
        )

        if use_fallback:
            logger.warning(
                "âš ï¸ Falling back to writer for read operation "
                "(all readers unhealthy)"
            )
            self._reader_fallbacks += 1
            return self.get_writer_connection()

        raise Exception("No healthy reader nodes available and fallback disabled")

    def call_write(
        self,
        name: str,
        ret_type=None,
        params=None,
        list_params=None,
        model=None,
        jsonfy: bool = False,
        throw: bool = True,
    ) -> Any:
        """
        Execute stored procedure on writer node.

        Use for INSERT, UPDATE, DELETE operations and procedures
        that modify data.

        Args:
            name: Stored procedure name
            ret_type: Return type (DBTypes)
            params: Named parameters dict
            list_params: Positional parameters list
            model: Model class for result mapping
            jsonfy: Return as dict if True
            throw: Raise exceptions if True

        Returns:
            Any: Procedure result
        """
        self._total_writes += 1
        conn = self.get_writer_connection()
        return self._zmysql.call(
            name, ret_type, params, list_params, model, conn, jsonfy, throw
        )

    def call_read(
        self,
        name: str,
        ret_type=None,
        params=None,
        list_params=None,
        model=None,
        jsonfy: bool = False,
        throw: bool = True,
        fallback_to_writer: Optional[bool] = None
    ) -> Any:
        """
        Execute stored procedure on reader node.

        Use for SELECT operations and read-only procedures.
        Automatically load-balances across available readers.

        Args:
            name: Stored procedure name
            ret_type: Return type (DBTypes)
            params: Named parameters dict
            list_params: Positional parameters list
            model: Model class for result mapping
            jsonfy: Return as dict if True
            throw: Raise exceptions if True
            fallback_to_writer: Override fallback setting for this call

        Returns:
            Any: Procedure result
        """
        self._total_reads += 1
        conn = self.get_reader_connection(fallback_to_writer)
        return self._zmysql.call(
            name, ret_type, params, list_params, model, conn, jsonfy, throw
        )

    def exec_write(
        self,
        fn_name: str,
        ret_type=None,
        params=None,
        list_params=None,
        model=None,
        jsonfy: bool = False,
        throw: bool = True,
    ) -> Any:
        """
        Execute MySQL function on writer node.

        Args:
            fn_name: Function name
            ret_type: Return type (DBTypes)
            params: Named parameters dict
            list_params: Positional parameters list
            model: Model class for result mapping
            jsonfy: Return as dict if True
            throw: Raise exceptions if True

        Returns:
            Any: Function result
        """
        self._total_writes += 1
        conn = self.get_writer_connection()
        return self._zmysql.exec(
            fn_name, ret_type, params, list_params, model, conn, jsonfy, throw
        )

    def exec_read(
        self,
        fn_name: str,
        ret_type=None,
        params=None,
        list_params=None,
        model=None,
        jsonfy: bool = False,
        throw: bool = True,
        fallback_to_writer: Optional[bool] = None
    ) -> Any:
        """
        Execute MySQL function on reader node.

        Args:
            fn_name: Function name
            ret_type: Return type (DBTypes)
            params: Named parameters dict
            list_params: Positional parameters list
            model: Model class for result mapping
            jsonfy: Return as dict if True
            throw: Raise exceptions if True
            fallback_to_writer: Override fallback setting

        Returns:
            Any: Function result
        """
        self._total_reads += 1
        conn = self.get_reader_connection(fallback_to_writer)
        return self._zmysql.exec(
            fn_name, ret_type, params, list_params, model, conn, jsonfy, throw
        )

    def get_cluster_stats(self) -> dict:
        """
        Get comprehensive cluster statistics.

        Returns:
            dict: Statistics including:
                - writer: Writer node stats
                - readers: List of reader node stats
                - total_reads: Total read operations
                - total_writes: Total write operations
                - reader_fallbacks: Times fallen back to writer
                - read_write_ratio: Ratio of reads to writes
        """
        total_ops = self._total_reads + self._total_writes
        read_write_ratio = (
            self._total_reads / self._total_writes 
            if self._total_writes > 0 
            else 0
        )

        return {
            'writer': self._writer_pool.get_stats(),
            'readers': [pool.get_stats() for pool in self._reader_pools],
            'total_reads': self._total_reads,
            'total_writes': self._total_writes,
            'total_operations': total_ops,
            'reader_fallbacks': self._reader_fallbacks,
            'read_write_ratio': round(read_write_ratio, 2),
            'fallback_to_writer_enabled': self._fallback_to_writer
        }

    def reset_cluster_stats(self):
        """Reset all cluster statistics."""
        self._total_reads = 0
        self._total_writes = 0
        self._reader_fallbacks = 0
        self._writer_pool.pool.reset_stats()
        for reader_pool in self._reader_pools:
            reader_pool.pool.reset_stats()

    def reset_node_health(self):
        """Reset health status for all nodes."""
        self._writer_pool.reset_health()
        for reader_pool in self._reader_pools:
            reader_pool.reset_health()

    def close_cluster(self):
        """Close all cluster connections."""
        self._writer_pool.close()
        for reader_pool in self._reader_pools:
            reader_pool.close()
        logger.info("âœ… Cluster pool closed")

    # Backward compatibility methods

    def call(
        self,
        name: str,
        ret_type=None,
        params=None,
        list_params=None,
        model=None,
        jsonfy: bool = False,
        throw: bool = True,
        use_reader: bool = False,
    ) -> Any:
        """
        Generic call method for backward compatibility.

        Args:
            name: Stored procedure name
            ret_type: Return type
            params: Named parameters
            list_params: Positional parameters
            model: Model class
            jsonfy: Return as dict
            throw: Raise exceptions
            use_reader: Use reader node if True, writer if False

        Returns:
            Any: Procedure result
        """
        if use_reader:
            return self.call_read(
                name, ret_type, params, list_params, model, jsonfy, throw
            )
        return self.call_write(
            name, ret_type, params, list_params, model, jsonfy, throw
        )

    def new_connect(self, use_reader: bool = False) -> MySQLConnection:
        """
        Get connection for backward compatibility.

        Args:
            use_reader: Get reader if True, writer if False

        Returns:
            MySQLConnection: Connection from appropriate node
        """
        if use_reader:
            return self.get_reader_connection()
        return self.get_writer_connection()
    
    def close(self):
        """Close cluster pool for backward compatibility."""
        self.close_cluster()