# GitLab CI/CD Pipeline for n8n-deploy
# Python CLI tool for n8n workflow management
# Optimized for parallel stage execution

stages:
  - security
  - quality
  - test
  - build-matrix

# Docker services for caching (only used by Docker-specific jobs)
# Uncomment and configure for jobs that need Docker-in-Docker:
# services:
#   - name: docker:20.10.16-dind
#     command: [
#       "--mtu=1300",  # Fix TLS handshake timeout issues
#       "--registry-mirror", "http://registry-mirror.pirouter.dev:5000"  # Use local mirror (when available)
#     ]

variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  PYTHON_VERSION: "3.9"
  # Docker caching configuration
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"
  DOCKER_BUILDKIT: 1
  # Docker Registry Configuration:
  # - pull_policy: if-not-present (configured in GitLab Runner config.toml)
  # - registry_mirror: http://registry-mirror.pirouter.dev:5000 (configured in GitLab Runner config.toml)
  # - MTU: 1300 for DinD (see services comment above)
  # APT proxy for faster package installation
  APT_PROXY: "192.168.76.5:3142"
  # PyPI deployment configuration (set in CI/CD variables)
  # PYPI_TOKEN: <set in GitLab CI/CD settings>
  # TEST_PYPI_TOKEN: <set in GitLab CI/CD settings>
  # Git configuration for proper versioning
  GIT_DEPTH: 0  # Full clone with all tags for setuptools_scm version detection

# Workflow rules - define when pipeline runs
# Push to protected branches (master/develop): full pipeline
# MR targeting protected branches: full pipeline
# Feature branch push: NO pipeline (run locally with ./scripts/run-like-ci.sh)
workflow:
  rules:
    # Run on master/develop (protected branches)
    - if: '$CI_COMMIT_BRANCH == "master" || $CI_COMMIT_BRANCH == "develop"'
      when: always
    # Run on all tags
    - if: '$CI_COMMIT_TAG'
      when: always
    # Run on merge requests targeting master or develop
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && ($CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master" || $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "develop")'
      when: always
    # Manual workflow dispatch
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: always
    # Skip for all other cases (including feature branch pushes)
    - when: never

# Cache for pip dependencies (default: pull-push)
cache:
  key:
    files:
      - requirements.txt
    prefix: ${CI_COMMIT_REF_SLUG}
  fallback_keys:
    - develop
    - master
  paths:
    - .cache/pip/
    - .venv/

# Cache template for read-only jobs (policy: pull)
.cache_pull: &cache_pull
  key:
    files:
      - requirements.txt
    prefix: ${CI_COMMIT_REF_SLUG}
  fallback_keys:
    - develop
    - master
  paths:
    - .cache/pip/
    - .venv/
  policy: pull

# Template for Python environment setup (uses cached venv from warm-cache job)
.python_setup: &python_setup
  before_script:
    - source .venv/bin/activate

# ============================================
# PRE STAGE - Cache warming
# ============================================

warm-cache:
  stage: .pre
  image: python:3.9-slim
  # Use dualbuntu image for better performance
  tags:
    - python
    - linux
    - heavy
  interruptible: true
  rules:
    - if: '$CI_COMMIT_TAG'
      when: never
    - when: on_success
  cache:
    key:
      files:
        - requirements.txt
      prefix: ${CI_COMMIT_REF_SLUG}
    fallback_keys:
      - develop
      - master
    paths:
      - .cache/pip/
      - .venv/
    policy: pull-push
  before_script:
    - echo "Acquire::http::Proxy \"http://${APT_PROXY}\";" > /etc/apt/apt.conf.d/01proxy
    - apt-get -q update && apt-get -qy install git
    - python -m pip install --quiet --upgrade pip
    - pip install --quiet uv
  script:
    - echo "Warming cache..."
    - uv venv --python python3 .venv
    - source .venv/bin/activate
    - uv pip install --quiet -e ".[test,dev]"
    - echo "Cache populated successfully"

# ============================================
# SECURITY STAGE
# ============================================

# Secret detection with gitleaks
secret_detection:
  stage: security
  image: python:3.9-slim
  tags:
    - python
    - alpine
    - linux
  interruptible: true
  rules:
    - if: '$CI_COMMIT_TAG'
      when: never
    - when: on_success
  cache:
    <<: *cache_pull
  variables:
    SECRET_DETECTION_EXCLUDED_PATHS: "tests/"
  before_script:
    - echo "Acquire::http::Proxy \"http://${APT_PROXY}\";" > /etc/apt/apt.conf.d/01proxy
    - apt-get -q update && apt-get -qy install git wget
    - wget -qO- https://github.com/gitleaks/gitleaks/releases/download/v8.29.1/gitleaks_8.29.1_linux_x64.tar.gz | tar xz -C /usr/local/bin
  script:
    - echo "üîç Running secret detection with gitleaks..."
    - gitleaks git . --verbose --redact --config .gitleaks.toml
    - echo "‚úÖ Secret detection completed"

# Dependency vulnerability scanning
dependency_scanning:
  stage: security
  image: python:3.9-slim
  tags:
    - python
    - alpine
    - linux
  interruptible: true
  rules:
    - if: '$CI_COMMIT_TAG'
      when: never
    - when: on_success
  cache:
    <<: *cache_pull
  before_script:
    - echo "Acquire::http::Proxy \"http://${APT_PROXY}\";" > /etc/apt/apt.conf.d/01proxy
    - apt-get -q update
    - python -m pip install --quiet --upgrade pip
    - pip install --quiet pip-audit
  script:
    - echo "üîç Running dependency vulnerability scanning..."
    - pip-audit -r requirements.txt
    - echo "‚úÖ Dependency scanning completed"

# Python security scanning with Bandit
security:bandit:
  stage: security
  image: python:3.9-slim
  tags:
    - python
    - alpine
    - linux
  interruptible: true
  rules:
    - if: '$CI_COMMIT_TAG'
      when: never
    - when: on_success
  cache:
    <<: *cache_pull
  variables:
    SAST_EXCLUDED_PATHS: "tests/, .venv/"
  before_script:
    - echo "Acquire::http::Proxy \"http://${APT_PROXY}\";" > /etc/apt/apt.conf.d/01proxy
    - apt-get -q update && apt-get -qy install git
    - python -m pip install --quiet --upgrade pip
    - pip install --quiet bandit
    - pip install -e .
  script:
    - echo "üîç Running Python security analysis with Bandit..."
    - bandit -r api/ -f json --exclude tests/
    - echo "‚úÖ Bandit analysis completed"

# Pattern-based security scanning with Semgrep
security:semgrep:
  stage: security
  image: python:3.9-slim
  tags:
    - python
    - alpine
    - linux
  interruptible: true
  rules:
    - if: '$CI_COMMIT_TAG'
      when: never
    - when: on_success
  cache:
    <<: *cache_pull
  variables:
    SAST_EXCLUDED_PATHS: "tests/, .venv/"
  before_script:
    - echo "Acquire::http::Proxy \"http://${APT_PROXY}\";" > /etc/apt/apt.conf.d/01proxy
    - apt-get -q update && apt-get -qy install git
    - python -m pip install --quiet --upgrade pip
    - pip install --quiet semgrep
    - pip install -e .
  script:
    - echo "üîç Running pattern-based security analysis with Semgrep..."
    - semgrep --config=auto api/ --json --error
    - echo "‚úÖ Semgrep analysis completed"

# ============================================
# QUALITY STAGE
# ============================================

# Type checking with mypy
quality:mypy:
  stage: quality
  image: python:3.9-slim
  tags:
    - python
    - alpine
    - linux
  interruptible: true
  rules:
    - if: '$CI_COMMIT_TAG'
      when: never
    - when: on_success
  <<: *python_setup
  cache:
    <<: *cache_pull
  needs:
    - warm-cache
  script:
    - mypy api/ --strict --show-error-codes
    - echo "‚úÖ Type checking passed"

# Code formatting check with black
quality:black:
  stage: quality
  image: python:3.9-slim
  tags:
    - python
    - alpine
    - linux
  interruptible: true
  rules:
    - if: '$CI_COMMIT_TAG'
      when: never
    - when: on_success
  <<: *python_setup
  cache:
    <<: *cache_pull
  needs:
    - warm-cache
  script:
    - black --check api/
    - echo "‚úÖ Code formatting check passed"

# ============================================
# TEST STAGE (runs on merge/push to protected branches)
# ============================================

# Unit tests
test:unit:
  stage: test
  image: python:3.9-slim
  tags:
    - python
    - alpine
    - linux
  interruptible: true
  cache:
    <<: *cache_pull
  needs:
    - warm-cache
  rules:
    - if: '$CI_COMMIT_TAG'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: never
    - if: '$CI_COMMIT_BRANCH == "master" || $CI_COMMIT_BRANCH == "develop"'
      when: on_success
  before_script:
    - echo "Acquire::http::Proxy \"http://${APT_PROXY}\";" > /etc/apt/apt.conf.d/01proxy
    - apt-get -q update && apt-get -qy install git
    - source .venv/bin/activate
  script:
    - export N8N_DEPLOY_TESTING=1
    - python -m pytest tests/unit/ -rs --tb=short -q
    - echo "Unit tests passed"

# Integration tests
test:integration:
  stage: test
  image: python:3.9-slim
  tags:
    - python
    - alpine
    - linux
  interruptible: true
  <<: *python_setup
  cache:
    <<: *cache_pull
  needs:
    - warm-cache
  rules:
    - if: '$CI_COMMIT_TAG'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: never
    - if: '$CI_COMMIT_BRANCH == "master" || $CI_COMMIT_BRANCH == "develop"'
      when: on_success
  script:
    - export N8N_DEPLOY_TESTING=1
    - python -m pytest tests/integration/ -rs --tb=short -q
    - echo "Integration tests passed"

# Property-based tests with Hypothesis
test:hypothesis:
  stage: test
  image: python:3.9-slim
  tags:
    - python
    - heavy
    - linux
  interruptible: true
  <<: *python_setup
  cache:
    <<: *cache_pull
  needs:
    - warm-cache
  rules:
    - if: '$CI_COMMIT_TAG'
      when: never
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: never
    - if: '$CI_COMMIT_BRANCH == "master" || $CI_COMMIT_BRANCH == "develop"'
      when: on_success
  script:
    - export N8N_DEPLOY_TESTING=1
    - echo "Running property-based tests with Hypothesis..."
    - python run_tests.py --hypothesis --no-deps-check
    - echo "Property-based tests passed"
  artifacts:
    when: always
    paths:
      - .hypothesis/
    expire_in: 7 days

# ============================================
# BUILD-MATRIX STAGE (runs on merge/push to protected branches)
# ============================================

# Multi-version package builds (Python 3.9-3.13)
build:python-matrix:
  stage: build-matrix
  image: python:${PYTHON_VERSION}-slim
  tags:
    - python
    - alpine
    - linux
  interruptible: true
  cache:
    key:
      files:
        - requirements.txt
      prefix: py${PYTHON_VERSION}-${CI_COMMIT_REF_SLUG}
    paths:
      - .cache/pip/
      - .venv/
  needs:
    - job: test:unit
      optional: true
    - job: test:integration
      optional: true
  rules:
    - if: '$CI_COMMIT_TAG'
      when: on_success
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: never
    - if: '$CI_COMMIT_BRANCH == "master" || $CI_COMMIT_BRANCH == "develop"'
      when: on_success
  parallel:
    matrix:
      - PYTHON_VERSION: ["3.9", "3.10", "3.11", "3.12", "3.13"]
  before_script:
    - echo "Acquire::http::Proxy \"http://${APT_PROXY}\";" > /etc/apt/apt.conf.d/01proxy
    - apt-get -q update && apt-get -qy install git
    - python -m pip install --quiet --upgrade pip
    - pip install --quiet uv
  script:
    - uv venv --python python3 .venv
    - source .venv/bin/activate
    - uv pip install --quiet -e ".[test,dev]"
    - uv pip install --quiet build
    - echo "Building package for Python ${PYTHON_VERSION}..."
    - python -m build --wheel --sdist
    - pip install dist/*.whl
    - n8n-deploy --version
    - echo "Build successful for Python ${PYTHON_VERSION}"
  artifacts:
    paths:
      - dist/
    expire_in: 1 hour
