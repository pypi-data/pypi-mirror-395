#!/usr/bin/env python
# ///script
# requires-python = ">=3.11"
# dependencies = ["black", "textcase"]
# ///
# SPDX-FileCopyrightText: 2025 Knitli Inc.
# SPDX-FileContributor: Adam Poulemanos <adam@knit.li>
#
# SPDX-License-Identifier: MIT OR Apache-2.0
"""Generate the list of supported languages for the build system and documentation."""

from __future__ import annotations

from pathlib import Path
from textwrap import dedent

import black
import textcase

from codeweaver.core.file_extensions import ALL_LANGUAGES
from codeweaver.core.language import SemanticSearchLanguage, ConfigLanguage
from codeweaver.core.types.aliases import LanguageNameT, LanguageName


ALL_LANGUAGES = frozenset(ALL_LANGUAGES)

CW_ROOT = Path(__file__).parent.parent.parent

MARKDOWN_PATH = CW_ROOT / "overrides" / "partials" / "languages.md"

LITERAL_TYPE_PATH = CW_ROOT / "src" / "codeweaver" / "core" / "secondary_languages.py"


def generate_literal_type(languages: list[LanguageNameT]) -> str:
    """Generate a Python Literal type definition for the supported languages."""
    languages = sorted(set(languages) | {LanguageName(lang.variable) for lang in ConfigLanguage if not lang.is_semantic_search_language})
    literals = ", ".join(f'"{lang}"' for lang in languages)
    return f"type SecondarySupportedLanguage = Literal[{literals}]"


def generate_literal_type_file(languages: list[LanguageNameT], path: Path) -> None:
    """Generate the supported languages literal type file."""
    intro = dedent("""
        # SPDX-FileCopyrightText: 2025 Knitli Inc.
        # SPDX-FileContributor: Adam Poulemanos <adam@knit.li>
        # SPDX-License-Identifier: MIT OR Apache-2.0
        \"\"\"Supported languages for CodeWeaver. These are languages that have smart delimiter-based parsing support.

        This file is auto-generated by scripts/build/generate_supported_languages.py
        Do not edit this file directly. (unless you really like Sisyphean tasks, then go for it)
        \"\"\"""")
    content = black.format_str(
        dedent(
            f"""
        from typing import Literal


        {generate_literal_type(languages)}
        \"\"\"Literal type for supported secondary languages. These languages have pseudo-semantic parsing support using our smart delimiter-based approach.
        Level of support varies by language.
        \"\"\"

        __all__ = ("SecondarySupportedLanguage",)
        """
        ),
        mode=black.FileMode(
            target_versions={
                black.TargetVersion.PY312,
                black.TargetVersion.PY313,
                black.TargetVersion.PY314,
            }
        ),
    )
    path.parent.mkdir(parents=True, exist_ok=True)
    if not path.exists():
        path.touch()
    outcome = path.write_text(f"{intro}\n\n{content}")  # type: ignore
    print(f"Wrote literal type file to {path} ({outcome} characters).")


def generate_markdown_list(languages: list[LanguageNameT]) -> str:
    """Generate a markdown list of supported languages."""

    def list_item(lang: str) -> str:
        return f"- {lang}"

    semantic_languages = [list_item(language.as_title) for language in SemanticSearchLanguage]
    semantic_markdown = (
        f"### Languages with Semantic Search Support\n\n{'\n'.join(semantic_languages)}\n"
    )
    other_languages = {
        list_item(textcase.title(language))
        for language in languages
        if language not in SemanticSearchLanguage
    }
    other_languages |= {list_item(language.as_title) for language in ConfigLanguage if not language.is_semantic_search_language}
    other_languages |= set(semantic_languages)  # we also support these with the delimiter chunker for fallback
    other_languages = sorted(other_languages)
    other_markdown = f"### Languages with Smart Delimiter Support\n\nThese languages are parsed with our delimiter-based approach. We identify patterns common to families of languages to extract meaningful semantic-like structures and data:\n\n{'\n'.join(other_languages)}\n\n"
    return f"## Supported Languages\n\n{semantic_markdown}\n{other_markdown}"


def generate_markdown_file(languages: list[LanguageNameT], path: Path) -> None:
    """Generate the supported languages markdown file."""
    # These license headers are intended for the generated code, not for this generator script.
    # We use REUSE-IgnoreStart/End markers to prevent REUSE from treating these as duplicate license statements.
    # REUSE-IgnoreStart
    content = dedent(f"""<!--
        SPDX-FileCopyrightText: 2025 Knitli Inc.
        SPDX-FileContributor: Adam Poulemanos <adam@knit.li>
        SPDX-License-Identifier: MIT OR Apache-2.0 -->
        <!-- This file is auto-generated by scripts/generate_supported_languages.py -->
        <!-- Do not edit this file directly. (unless you really like Sisyphean tasks, then go for it) -->

        {generate_markdown_list(languages)}
        """)
    # REUSE-IgnoreEnd
    path.parent.mkdir(parents=True, exist_ok=True)
    if not path.exists():
        path.touch()
    outcome = path.write_text(content)  # type: ignore
    print(f"Wrote markdown file to {path} ({outcome} characters).")


def main() -> None:
    """Generate the supported languages files."""
    languages = sorted(ALL_LANGUAGES)
    print(f"Generating supported languages files with {len(languages)} languages...")
    generate_literal_type_file(languages, LITERAL_TYPE_PATH)
    print(f"Generating markdown file at {MARKDOWN_PATH}...")
    generate_markdown_file(languages, MARKDOWN_PATH)
    print(f"Generated supported languages files with {len(languages)} languages.")


if __name__ == "__main__":
    main()
