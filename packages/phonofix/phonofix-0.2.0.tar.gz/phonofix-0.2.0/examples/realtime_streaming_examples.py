"""
ASR/LLM ä¸²æµä¿®æ­£ç¯„ä¾‹

æœ¬ç¯„ä¾‹å±•ç¤ºå¦‚ä½•åœ¨å³æ™‚ä¸²æµå ´æ™¯ä¸­ä½¿ç”¨ phonofixï¼š
1. ASR æ¨¡å¼ï¼šç´¯ç©æ–‡æœ¬æŒçºŒæ›´æ–°ï¼ˆRealtime ASRï¼‰
2. LLM æ¨¡å¼ï¼šå¢é‡ chunk æŒçºŒé€²ä¾†ï¼ˆLLM Streamingï¼‰

æ ¸å¿ƒæ¦‚å¿µï¼š
- å¿«å–å·²ç¢ºèªçš„ä¿®æ­£çµæœï¼Œé¿å…é‡è¤‡è¨ˆç®—
- æ»‘å‹•è¦–çª—ä¿ç•™é‡ç–Šå€åŸŸï¼Œé˜²æ­¢è©å½™è¢«åˆ‡æ–·èª¤åˆ¤
- è‡ªå‹•åµæ¸¬æ–°æ®µè½ï¼Œé‡ç½®å¿«å–ç‹€æ…‹
- **å‹•æ…‹ overlap**ï¼šæ ¹æ“š terms/keywords é•·åº¦è‡ªå‹•è¨ˆç®—å®‰å…¨çš„ç·©è¡å€å¤§å°
"""

import time
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from phonofix import (
    ChineseEngine, 
    StreamingCorrector, 
    ChunkStreamingCorrector,
    calculate_safe_overlap,
)


# å…¨åŸŸ Engine (ä¸é¡¯ç¤º verbose è¨Šæ¯)
engine = ChineseEngine(verbose=False)


def demo_asr_streaming():
    """
    æ¨¡æ“¬ Realtime ASR å ´æ™¯
    
    ASR ç‰¹æ€§ï¼š
    - æ¯æ¬¡å›å‚³ç´¯ç©çš„å®Œæ•´è­˜åˆ¥çµæœ
    - ä¹‹å‰çš„è­˜åˆ¥å¯èƒ½æœƒè¢«ä¿®æ­£
    - ä½¿ç”¨ StreamingCorrector (accumulated æ¨¡å¼)
    - **è‡ªå‹•è¨ˆç®— overlap_size**ï¼šæ ¹æ“š terms é•·åº¦å‹•æ…‹èª¿æ•´
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 1: ASR Realtime Streaming")
    print("=" * 60)
    print()
    
    # å»ºç«‹ä¿®æ­£å™¨
    corrector = engine.create_corrector([
        "å°åŒ—è»Šç«™", "ç‰›å¥¶", "ç™¼æ®", "ç„¶å¾Œ", "TensorFlow"
    ])
    
    # æŸ¥çœ‹è‡ªå‹•è¨ˆç®—çš„ overlap (æ ¹æ“š terms é•·åº¦)
    auto_overlap = calculate_safe_overlap(corrector)
    print(f"è‡ªå‹•è¨ˆç®—çš„ overlap_size: {auto_overlap}")
    print(f"(åŸºæ–¼æœ€é•· term 'TensorFlow' = 10 å­—æ¯ + margin 5 = 15ï¼Œå– max(15, 20) = 20)")
    print()
    
    # å»ºç«‹ä¸²æµè™•ç†å™¨ - ä¸æŒ‡å®š overlap_sizeï¼Œè®“å®ƒè‡ªå‹•è¨ˆç®—
    streamer = StreamingCorrector(corrector)
    print(f"StreamingCorrector å¯¦éš›ä½¿ç”¨çš„ overlap_size: {streamer.overlap_size}")
    print()
    
    # æ¨¡æ“¬ ASR è¼¸å‡ºï¼ˆæ¯æ¬¡æ˜¯ç´¯ç©çš„å®Œæ•´æ–‡æœ¬ï¼‰
    asr_outputs = [
        "æˆ‘åœ¨",
        "æˆ‘åœ¨èƒ",
        "æˆ‘åœ¨èƒåŒ—",
        "æˆ‘åœ¨èƒåŒ—è»Š",
        "æˆ‘åœ¨èƒåŒ—è»Šç«™",
        "æˆ‘åœ¨èƒåŒ—è»Šç«™è²·äº†",
        "æˆ‘åœ¨èƒåŒ—è»Šç«™è²·äº†æµ",
        "æˆ‘åœ¨èƒåŒ—è»Šç«™è²·äº†æµå¥¶",
        "æˆ‘åœ¨èƒåŒ—è»Šç«™è²·äº†æµå¥¶è˜­",
        "æˆ‘åœ¨èƒåŒ—è»Šç«™è²·äº†æµå¥¶è˜­å¾Œ",
        "æˆ‘åœ¨èƒåŒ—è»Šç«™è²·äº†æµå¥¶è˜­å¾Œå›å®¶",
    ]
    
    print("ğŸ“¡ æ¨¡æ“¬ ASR ä¸²æµè¼¸å…¥:")
    print("-" * 60)
    
    for i, asr_text in enumerate(asr_outputs):
        result = streamer.feed(asr_text)
        
        # é¡¯ç¤ºç‹€æ…‹
        confirmed_display = result.confirmed if result.confirmed else "(ç©º)"
        pending_display = result.pending if result.pending else "(ç©º)"
        
        print(f"[{i+1:02d}] ASR: {asr_text}")
        print(f"     âœ… å·²ç¢ºèª: {confirmed_display}")
        print(f"     â³ å¾…ç¢ºèª: {pending_display}")
        print()
        
        time.sleep(0.1)  # æ¨¡æ“¬å»¶é²
    
    # æœ€å¾Œç¢ºèª
    final = streamer.finalize()
    print("-" * 60)
    print(f"ğŸ æœ€çµ‚çµæœ: {final}")
    print()


def demo_llm_streaming():
    """
    æ¨¡æ“¬ LLM Streaming å ´æ™¯
    
    LLM ç‰¹æ€§ï¼š
    - æ¯æ¬¡æ”¶åˆ°æ–°çš„ token/chunkï¼ˆå¢é‡ï¼‰
    - ä¹‹å‰çš„è¼¸å‡ºä¸æœƒæ”¹è®Š
    - ä½¿ç”¨ ChunkStreamingCorrector (chunk æ¨¡å¼)
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 2: LLM Streaming Output")
    print("=" * 60)
    print()
    
    # å»ºç«‹ä¿®æ­£å™¨
    corrector = engine.create_corrector([
        "è–éˆ", "æ©å…¸", "é“æˆè‚‰èº«", "è–ç¶“", "PyTorch", "NumPy"
    ])
    
    # å»ºç«‹ chunk æ¨¡å¼ä¸²æµè™•ç†å™¨
    streamer = ChunkStreamingCorrector(corrector, overlap_size=6)
    
    # æ¨¡æ“¬ LLM è¼¸å‡ºï¼ˆæ¯æ¬¡æ˜¯å¢é‡çš„ chunkï¼‰
    llm_chunks = [
        "è–æ—",
        "å€Ÿè‘—é»˜æ°",
        "å¯«äº†é€™æœ¬",
        "ç”Ÿç¶“ï¼Œ",
        "é“æˆçš„è·¯ç”Ÿ",
        "æ˜¯å®‰é»ã€‚",
        "æˆ‘ç”¨æ’ç‚¬",
        "å’Œå—æ´¾",
        "åšæ©Ÿå™¨å­¸ç¿’ã€‚",
    ]
    
    print("ğŸ¤– æ¨¡æ“¬ LLM ä¸²æµè¼¸å‡º:")
    print("-" * 60)
    print("å³æ™‚è¼¸å‡º: ", end="", flush=True)
    
    full_output = ""
    for chunk in llm_chunks:
        result = streamer.feed_chunk(chunk)
        
        # å³æ™‚è¼¸å‡ºå·²ç¢ºèªçš„éƒ¨åˆ†
        if result.confirmed:
            print(result.confirmed, end="", flush=True)
            full_output += result.confirmed
        
        time.sleep(0.15)  # æ¨¡æ“¬ LLM ç”Ÿæˆå»¶é²
    
    # çµæŸæ™‚è¼¸å‡ºå‰©é¤˜éƒ¨åˆ†
    remaining = streamer.finalize()
    if remaining:
        print(remaining, end="", flush=True)
        full_output += remaining
    
    print()  # æ›è¡Œ
    print("-" * 60)
    print(f"ğŸ å®Œæ•´çµæœ: {full_output}")
    print()


def demo_new_segment_detection():
    """
    å±•ç¤ºæ–°æ®µè½åµæ¸¬
    
    ç•¶è¼¸å…¥æ–‡æœ¬èˆ‡å¿«å–ä¸åŒ¹é…æ™‚ï¼Œè‡ªå‹•è¦–ç‚ºæ–°æ®µè½ä¸¦é‡ç½®å¿«å–ã€‚
    é€™é©ç”¨æ–¼ï¼š
    - ASR éœéŸ³å¾Œé‡æ–°é–‹å§‹
    - ä½¿ç”¨è€…åˆ‡æ›è©±é¡Œ
    - ç¶²è·¯æ–·ç·šé‡é€£
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 3: æ–°æ®µè½åµæ¸¬")
    print("=" * 60)
    print()
    
    corrector = engine.create_corrector(["å°åŒ—è»Šç«™", "é«˜é›„è»Šç«™"])
    streamer = StreamingCorrector(corrector, overlap_size=5)
    
    # æ¨¡æ“¬å…©å€‹ä¸é€£çºŒçš„æ®µè½
    segments = [
        # ç¬¬ä¸€æ®µ
        ["æˆ‘åœ¨", "æˆ‘åœ¨èƒåŒ—", "æˆ‘åœ¨èƒåŒ—è»Šç«™"],
        # ç¬¬äºŒæ®µï¼ˆå®Œå…¨ä¸åŒçš„é–‹é ­ï¼‰
        ["ä»Šå¤©å»", "ä»Šå¤©å»é«˜é›„", "ä»Šå¤©å»é«˜é›„è»Šç«™"],
    ]
    
    print("ğŸ“ æ¨¡æ“¬å¤šæ®µè½è¼¸å…¥:")
    print("-" * 60)
    
    for seg_idx, segment in enumerate(segments):
        print(f"\n--- æ®µè½ {seg_idx + 1} ---")
        for text in segment:
            result = streamer.feed(text)
            
            status = "ğŸ†• æ–°æ®µè½!" if result.is_new_segment else "   å»¶çºŒ"
            print(f"{status} è¼¸å…¥: {text}")
            print(f"         ç¢ºèª: {result.confirmed} | å¾…ç¢ºèª: {result.pending}")
    
    print()


def demo_performance_comparison():
    """
    æ•ˆèƒ½æ¯”è¼ƒï¼šä¸²æµ vs æ¯æ¬¡å…¨æ–‡ä¿®æ­£
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 4: æ•ˆèƒ½æ¯”è¼ƒ")
    print("=" * 60)
    print()
    
    corrector = engine.create_corrector([
        "è–éˆ", "æ©å…¸", "é“æˆè‚‰èº«", "è–ç¶“", "ç¦éŸ³", "ä½¿å¾’",
        "å°åŒ—è»Šç«™", "é«˜é›„è»Šç«™", "TensorFlow", "PyTorch"
    ])
    
    # ç”Ÿæˆé•·æ–‡æœ¬åºåˆ—
    base_text = "æˆ‘åœ¨èƒåŒ—è»Šç«™è½åˆ°äº†è–æ—çš„ç”ŸéŸ³ï¼Œé“æˆçš„è·¯ç”Ÿæ˜¯å®‰é»çš„æ©é»"
    asr_sequence = [base_text[:i] for i in range(5, len(base_text) + 1, 3)]
    
    print(f"æ¸¬è©¦åºåˆ—é•·åº¦: {len(asr_sequence)} æ¬¡è¼¸å…¥")
    print(f"æœ€çµ‚æ–‡æœ¬é•·åº¦: {len(base_text)} å­—ç¬¦")
    print()
    
    # æ–¹å¼ 1: æ¯æ¬¡å…¨æ–‡ä¿®æ­£
    start = time.perf_counter()
    for text in asr_sequence:
        _ = corrector.correct(text)
    time_full = time.perf_counter() - start
    
    # æ–¹å¼ 2: ä¸²æµä¿®æ­£ï¼ˆå¸¶å¿«å–ï¼‰
    streamer = StreamingCorrector(corrector, overlap_size=8)
    start = time.perf_counter()
    for text in asr_sequence:
        _ = streamer.feed(text)
    _ = streamer.finalize()
    time_stream = time.perf_counter() - start
    
    print(f"â±ï¸ æ¯æ¬¡å…¨æ–‡ä¿®æ­£: {time_full:.4f} ç§’")
    print(f"â±ï¸ ä¸²æµä¿®æ­£:     {time_stream:.4f} ç§’")
    print(f"ğŸ“ˆ æ•ˆèƒ½æå‡:     {time_full/time_stream:.2f}x")
    print()
    
    # æ³¨æ„ï¼šç”±æ–¼ overlap æ©Ÿåˆ¶ï¼Œä¸²æµæ¨¡å¼ä»éœ€é‡ç®—éƒ¨åˆ†å…§å®¹
    # ä¸»è¦å„ªå‹¢åœ¨æ–¼å·²ç¢ºèªéƒ¨åˆ†ä¸å†é‡ç®—


def demo_practical_usage():
    """
    å¯¦éš›æ‡‰ç”¨ç¯„ä¾‹ï¼šWebSocket ASR è™•ç†
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 5: å¯¦éš›æ‡‰ç”¨ - WebSocket ASR")  
    print("=" * 60)
    print()
    
    code = '''
# å¯¦éš›æ‡‰ç”¨ç¯„ä¾‹ (è™›æ“¬ç¢¼)

from phonofix import ChineseEngine, StreamingCorrector

# æ‡‰ç”¨å•Ÿå‹•æ™‚åˆå§‹åŒ–
engine = ChineseEngine()
corrector = engine.create_corrector(my_terms)

# WebSocket è™•ç† - overlap_size è‡ªå‹•æ ¹æ“š terms è¨ˆç®—
async def handle_asr_websocket(websocket):
    streamer = StreamingCorrector(corrector)  # è‡ªå‹•è¨ˆç®— overlap
    
    async for message in websocket:
        asr_result = json.loads(message)
        
        if asr_result["type"] == "partial":
            # éƒ¨åˆ†è­˜åˆ¥çµæœ
            result = streamer.feed(asr_result["text"])
            await websocket.send(json.dumps({
                "confirmed": result.confirmed,
                "pending": result.pending,
            }))
            
        elif asr_result["type"] == "final":
            # æœ€çµ‚è­˜åˆ¥çµæœ
            final = streamer.finalize()
            await websocket.send(json.dumps({
                "final": final,
            }))
            streamer.reset()  # é‡ç½®ï¼Œæº–å‚™ä¸‹ä¸€æ®µ
'''
    print(code)
    print()


def demo_dynamic_overlap():
    """
    å±•ç¤ºå‹•æ…‹ overlap è¨ˆç®—
    
    æ ¹æ“š terms/keywords/exclusions çš„é•·åº¦è‡ªå‹•èª¿æ•´ overlapï¼Œ
    ç¢ºä¿é•·è©å½™ä¸æœƒè¢«æˆªæ–·å°è‡´ç„¡æ³•ä¿®æ­£ã€‚
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 5: å‹•æ…‹ Overlap è¨ˆç®—")
    print("=" * 60)
    print()
    
    # Case 1: ä¸€èˆ¬è©å½™
    terms1 = ["å°åŒ—è»Šç«™", "é«˜é›„æ¸¯"]  # æœ€é•· 4 å­—
    corrector1 = engine.create_corrector(terms1)
    overlap1 = calculate_safe_overlap(corrector1)
    print(f"ä¸€èˆ¬è©å½™ (å°åŒ—è»Šç«™ 4å­—):")
    print(f"  è‡ªå‹• overlap = {overlap1} (ä½¿ç”¨é è¨­å€¼ 20)")
    print()
    
    # Case 2: é•·è‹±æ–‡è©å½™
    terms2 = {
        "TensorFlow": {},           # 10 å­—æ¯
        "Kubernetes": {},           # 10 å­—æ¯  
        "ElasticSearch": {},        # 13 å­—æ¯
    }
    corrector2 = engine.create_corrector(terms2)
    overlap2 = calculate_safe_overlap(corrector2)
    print(f"é•·è‹±æ–‡è©å½™ (ElasticSearch 13å­—æ¯):")
    print(f"  è‡ªå‹• overlap = {overlap2} (13 + margin 5 = 18ï¼Œå– max(18, 20) = 20)")
    print()
    
    # Case 3: è¶…é•· keyword
    terms3 = {
        "API": {"keywords": ["ApplicationProgrammingInterface"]},  # 31 å­—æ¯!
    }
    corrector3 = engine.create_corrector(terms3)
    overlap3 = calculate_safe_overlap(corrector3)
    print(f"è¶…é•· keyword (ApplicationProgrammingInterface 31å­—æ¯):")
    print(f"  è‡ªå‹• overlap = {overlap3} (31 + margin 5 = 36)")
    print()
    
    # Case 4: é•· exclusion
    terms4 = {
        "React": {"exclusions": ["ReactNativeFramework"]},  # 20 å­—æ¯
    }
    corrector4 = engine.create_corrector(terms4)
    overlap4 = calculate_safe_overlap(corrector4)
    print(f"é•· exclusion (ReactNativeFramework 20å­—æ¯):")
    print(f"  è‡ªå‹• overlap = {overlap4} (20 + margin 5 = 25)")
    print()
    
    # å¯¦éš›ä½¿ç”¨
    print("å¯¦éš›ä½¿ç”¨:")
    streamer = StreamingCorrector(corrector3)  # ä½¿ç”¨æœ‰è¶…é•· keyword çš„ corrector
    print(f"  StreamingCorrector.overlap_size = {streamer.overlap_size}")
    print(f"  StreamingCorrector.min_confirm_size = {streamer.min_confirm_size}")
    print()
    
    # ä¹Ÿå¯ä»¥æ‰‹å‹•è¦†è“‹
    streamer_manual = StreamingCorrector(corrector3, overlap_size=50)
    print(f"æ‰‹å‹•è¦†è“‹ overlap_size=50:")
    print(f"  StreamingCorrector.overlap_size = {streamer_manual.overlap_size}")
    print()


if __name__ == "__main__":
    print("\n" + "ğŸŒŠ" * 30)
    print("  ASR/LLM ä¸²æµä¿®æ­£ç¯„ä¾‹")
    print("ğŸŒŠ" * 30 + "\n")
    
    demo_asr_streaming()
    demo_llm_streaming()
    demo_new_segment_detection()
    demo_dynamic_overlap()  # æ–°å¢ï¼šå‹•æ…‹ overlap è¨ˆç®—ç¯„ä¾‹
    demo_performance_comparison()
    demo_practical_usage()
    
    print("=" * 60)
    print("âœ… æ‰€æœ‰ç¯„ä¾‹åŸ·è¡Œå®Œæˆ!")
    print("=" * 60)
