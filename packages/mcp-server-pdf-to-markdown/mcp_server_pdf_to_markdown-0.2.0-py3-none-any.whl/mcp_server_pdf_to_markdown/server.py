"""
PDF to Markdown MCP Server
ä½¿ç”¨ DeepSeek-OCR å°† PDF è½¬æ¢ä¸º Markdownï¼Œå¹¶å¯¹å›¾ç‰‡è¿›è¡Œè§£æå¢å¼º

åŠŸèƒ½ï¼š
1. pdf_to_markdown: å°† PDF è½¬æ¢ä¸º Markdownï¼ˆå›¾ç‰‡åªä¿ç•™é“¾æ¥ï¼‰
2. augment_markdown_images: å¯¹ Markdown ä¸­çš„å›¾ç‰‡é“¾æ¥æ·»åŠ è§£æå†…å®¹
3. pdf_to_markdown_full: ä¸€ç«™å¼å®Œæˆ PDF è½¬ Markdown å¹¶å¢å¼ºå›¾ç‰‡è§£æ
"""

import os
import sys
import argparse
import re
import io
import json
from typing import Any, Dict, Optional
from concurrent.futures import ThreadPoolExecutor

# ============================================
# ç¯å¢ƒå˜é‡è®¾ç½®ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ torch ä¹‹å‰ï¼‰
# ============================================
os.environ['VLLM_USE_V1'] = '0'

import torch
if torch.version.cuda == '11.8':
    os.environ["TRITON_PTXAS_PATH"] = "/usr/local/cuda-11.8/bin/ptxas"

# ============================================
# æ·»åŠ  DeepSeek-OCR-vllm è·¯å¾„åˆ° sys.path
# è¿™å¿…é¡»åœ¨å¯¼å…¥ DeepSeek-OCR ç›¸å…³æ¨¡å—ä¹‹å‰å®Œæˆ
# ============================================
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
DEEPSEEK_OCR_PATH = os.path.join(os.path.dirname(SCRIPT_DIR), 'DeepSeek-OCR-vllm')
if DEEPSEEK_OCR_PATH not in sys.path:
    sys.path.insert(0, DEEPSEEK_OCR_PATH)

# ============================================
# æ ‡å‡†åº“å’Œç¬¬ä¸‰æ–¹åº“å¯¼å…¥
# ============================================
import fitz  # PyMuPDF
import img2pdf
from PIL import Image, ImageDraw, ImageFont
import numpy as np
from tqdm import tqdm
from mcp.server.fastmcp import FastMCP

# ============================================
# å…¨å±€å˜é‡
# ============================================
_llm = None
_sampling_params = None
_sampling_params_image = None
_model_initialized = False
_deepseek_processor = None

# ============================================
# é…ç½®å‚æ•°ï¼ˆä» config.py ä¸­æå–ï¼Œé¿å…å¯¼å…¥æ—¶åŠ è½½ TOKENIZERï¼‰
# ============================================
MODEL_PATH = '/home/ad/tianhaoyang/vllm_model/deepseek-ai/DeepSeek-OCR'
CROP_MODE = True
MAX_CONCURRENCY = 100
NUM_WORKERS = 64
SKIP_REPEAT = True
BASE_SIZE = 1024
IMAGE_SIZE = 640
MIN_CROPS = 2
MAX_CROPS = 6

# ============================================
# é»˜è®¤æç¤ºè¯
# ============================================
PDF_PROMPT = '<image>\n<|grounding|>Convert the document to markdown.'
IMAGE_PROMPT = (
    "You are an OCR & document understanding assistant.\n"
    "Analyze this image region and produce:\n"
    "1) ALT: a very short alt text (<=12 words).\n"
    "2) CAPTION: a 1-2 sentence concise caption.\n"
    "3) CONTENT_MD: if the image contains a table, output a clean Markdown table;"
    "   if it contains a formula, output LaTeX ($...$ or $$...$$);"
    "   otherwise provide 3-6 bullet points summarizing key content, in Markdown.\n"
    "Return strictly in the following format:\n"
    "ALT: <short alt>\n"
    "CAPTION: <one or two sentences>\n"
    "CONTENT_MD:\n"
    "<markdown content here>\n"
)

# ============================================
# æ­£åˆ™è¡¨è¾¾å¼
# ============================================
IMG_PATTERN = re.compile(r'!\[[^\]]*\]\(([^)]+)\)')
REF_PATTERN = r'(<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>)'

# ============================================
# åˆ›å»º MCP æœåŠ¡å™¨
# ============================================
mcp = FastMCP("pdf-to-markdown")


def init_vllm(gpu_id: str = '0'):
    """åˆå§‹åŒ– vLLM æ¨¡å‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
    global _llm, _sampling_params, _sampling_params_image, _model_initialized, _deepseek_processor
    
    if _model_initialized:
        return
    
    os.environ["CUDA_VISIBLE_DEVICES"] = gpu_id
    
    sys.stderr.write("ğŸ”„ æ­£åœ¨åŠ è½½ DeepSeek-OCR æ¨¡å‹...\n")
    
    # ============================================
    # å¯¼å…¥ vLLM å’Œ DeepSeek-OCR ç›¸å…³æ¨¡å—
    # è¿™äº›å¯¼å…¥ä¼šè§¦å‘ config.py çš„åŠ è½½ï¼Œæ‰€ä»¥å¿…é¡»ç¡®ä¿è·¯å¾„å·²è®¾ç½®
    # ============================================
    from vllm import LLM, SamplingParams
    from vllm.model_executor.models.registry import ModelRegistry
    from deepseek_ocr import DeepseekOCRForCausalLM
    from process.ngram_norepeat import NoRepeatNGramLogitsProcessor
    from process.image_process import DeepseekOCRProcessor
    
    # ä¿å­˜å¤„ç†å™¨å¼•ç”¨
    _deepseek_processor = DeepseekOCRProcessor
    
    # æ³¨å†Œæ¨¡å‹
    ModelRegistry.register_model("DeepseekOCRForCausalLM", DeepseekOCRForCausalLM)
    
    # åˆå§‹åŒ– LLM
    _llm = LLM(
        model=MODEL_PATH,
        hf_overrides={"architectures": ["DeepseekOCRForCausalLM"]},
        block_size=256,
        enforce_eager=False,
        trust_remote_code=True,
        max_model_len=8192,
        swap_space=0,
        max_num_seqs=MAX_CONCURRENCY,
        tensor_parallel_size=1,
        gpu_memory_utilization=0.9,
        disable_mm_preprocessor_cache=True
    )
    
    # PDF è½¬æ¢çš„é‡‡æ ·å‚æ•°ï¼ˆtemperature=0.0ï¼‰
    logits_processors = [
        NoRepeatNGramLogitsProcessor(
            ngram_size=20,
            window_size=50,
            whitelist_token_ids={128821, 128822}
        )
    ]
    
    _sampling_params = SamplingParams(
        temperature=0.0,
        max_tokens=8192,
        logits_processors=logits_processors,
        skip_special_tokens=False,
        include_stop_str_in_output=True,
    )
    
    # å›¾ç‰‡è§£æçš„é‡‡æ ·å‚æ•°ï¼ˆtemperature=0.2ï¼‰
    _sampling_params_image = SamplingParams(
        temperature=0.2,
        max_tokens=2048,
        logits_processors=logits_processors,
        skip_special_tokens=False,
        include_stop_str_in_output=True,
    )
    
    _model_initialized = True
    sys.stderr.write("âœ… DeepSeek-OCR æ¨¡å‹åŠ è½½å®Œæˆï¼\n")


def get_deepseek_processor():
    """è·å– DeepseekOCRProcessorï¼ˆå»¶è¿Ÿå¯¼å…¥ï¼‰"""
    global _deepseek_processor
    
    if _deepseek_processor is None:
        from process.image_process import DeepseekOCRProcessor
        _deepseek_processor = DeepseekOCRProcessor
    
    return _deepseek_processor


def pdf_to_images_high_quality(pdf_path: str, dpi: int = 144) -> list:
    """å°† PDF è½¬æ¢ä¸ºé«˜è´¨é‡å›¾ç‰‡åˆ—è¡¨"""
    images = []
    pdf_document = fitz.open(pdf_path)
    
    zoom = dpi / 72.0
    matrix = fitz.Matrix(zoom, zoom)
    
    for page_num in range(pdf_document.page_count):
        page = pdf_document[page_num]
        pixmap = page.get_pixmap(matrix=matrix, alpha=False)
        Image.MAX_IMAGE_PIXELS = None
        
        img_data = pixmap.tobytes("png")
        img = Image.open(io.BytesIO(img_data))
        images.append(img)
    
    pdf_document.close()
    return images


def re_match(text: str):
    """åŒ¹é…æ–‡æœ¬ä¸­çš„ ref/det æ ‡ç­¾"""
    matches = re.findall(REF_PATTERN, text, re.DOTALL)
    
    matches_image = []
    matches_other = []
    for a_match in matches:
        if '<|ref|>image<|/ref|>' in a_match[0]:
            matches_image.append(a_match[0])
        else:
            matches_other.append(a_match[0])
    return matches, matches_image, matches_other


def extract_coordinates_and_label(ref_text, image_width: int, image_height: int):
    """ä» ref æ–‡æœ¬ä¸­æå–åæ ‡å’Œæ ‡ç­¾"""
    try:
        label_type = ref_text[1]
        cor_list = eval(ref_text[2])
    except Exception as e:
        sys.stderr.write(f"åæ ‡æå–é”™è¯¯: {e}\n")
        return None
    return (label_type, cor_list)


def save_cropped_images(image: Image.Image, refs: list, output_path: str, page_idx: int):
    """ä¿å­˜è£å‰ªçš„å›¾ç‰‡"""
    image_width, image_height = image.size
    img_idx = 0
    
    for ref in refs:
        try:
            result = extract_coordinates_and_label(ref, image_width, image_height)
            if result:
                label_type, points_list = result
                
                for points in points_list:
                    x1, y1, x2, y2 = points
                    x1 = int(x1 / 999 * image_width)
                    y1 = int(y1 / 999 * image_height)
                    x2 = int(x2 / 999 * image_width)
                    y2 = int(y2 / 999 * image_height)
                    
                    if label_type == 'image':
                        try:
                            cropped = image.crop((x1, y1, x2, y2))
                            cropped.save(f"{output_path}/images/{page_idx}_{img_idx}.jpg")
                        except Exception as e:
                            sys.stderr.write(f"å›¾ç‰‡ä¿å­˜é”™è¯¯: {e}\n")
                        img_idx += 1
        except:
            continue


def process_single_image_for_pdf(image: Image.Image, prompt: str):
    """å¤„ç†å•å¼ å›¾ç‰‡ç”¨äº PDF è½¬æ¢"""
    DeepseekOCRProcessor = get_deepseek_processor()
    
    cache_item = {
        "prompt": prompt,
        "multi_modal_data": {
            "image": DeepseekOCRProcessor().tokenize_with_images(
                images=[image], bos=True, eos=True, cropping=CROP_MODE
            )
        },
    }
    return cache_item


def call_deepseek_ocr_image(img_path: str, prompt: str = IMAGE_PROMPT) -> Dict[str, str]:
    """è°ƒç”¨ DeepSeek-OCR è§£æå•å¼ å›¾ç‰‡"""
    global _llm, _sampling_params_image
    
    if _llm is None:
        init_vllm()
    
    DeepseekOCRProcessor = get_deepseek_processor()
    
    # è¯»å–å›¾ç‰‡
    with Image.open(img_path) as im:
        image = im.convert('RGB')
    
    # å‡†å¤‡è¾“å…¥
    full_prompt = f"<image>\n{prompt}"
    image_features = DeepseekOCRProcessor().tokenize_with_images(
        images=[image],
        bos=True,
        eos=True,
        cropping=CROP_MODE
    )
    
    request = {
        "prompt": full_prompt,
        "multi_modal_data": {"image": image_features}
    }
    
    # ç”Ÿæˆ
    outputs = _llm.generate([request], sampling_params=_sampling_params_image)
    text = outputs[0].outputs[0].text.strip()
    
    # æ¸…ç†ç»“æŸæ ‡è®°
    if '<ï½œendâ–ofâ–sentenceï½œ>' in text:
        text = text.replace('<ï½œendâ–ofâ–sentenceï½œ>', '')
    
    # è§£æ DeepSeek-OCR åŸç”Ÿæ ¼å¼
    lines = []
    for line in text.splitlines():
        line = line.strip()
        if line.startswith('<|ref|>') or line.startswith('<|det|>'):
            continue
        line = re.sub(r'<\|ref\|>.*?</\|ref\|>', '', line)
        line = re.sub(r'<\|det\|>.*?</\|det\|>', '', line)
        line = line.strip()
        if line:
            lines.append(line)
    
    content_md = "\n\n".join(lines)
    caption = lines[0][:50] if lines else ""
            
    return {
        "alt": "Figure",
        "caption": caption,
        "content_md": content_md
    }


@mcp.tool()
def pdf_to_markdown(
    pdf_path: str,
    output_dir: str,
    gpu_id: str = "0"
) -> Dict[str, Any]:
    """å°† PDF æ–‡ä»¶è½¬æ¢ä¸º Markdown æ ¼å¼ï¼ˆå›¾ç‰‡åªä¿ç•™é“¾æ¥ï¼Œä¸è§£æå†…å®¹ï¼‰
    
    Args:
        pdf_path (str): PDF æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ (ä¾‹å¦‚: "/path/to/document.pdf")
        output_dir (str): è¾“å‡ºç›®å½•çš„å®Œæ•´è·¯å¾„ (ä¾‹å¦‚: "/path/to/output")
        gpu_id (str): ä½¿ç”¨çš„ GPU ID (é»˜è®¤: "0")
        
    Returns:
        Dict[str, Any]: åŒ…å«è½¬æ¢ç»“æœçš„å­—å…¸
            - success: æ˜¯å¦æˆåŠŸ
            - markdown_path: ç”Ÿæˆçš„ Markdown æ–‡ä»¶è·¯å¾„
            - images_dir: å›¾ç‰‡ä¿å­˜ç›®å½•
            - page_count: å¤„ç†çš„é¡µæ•°
            - error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
    """
    try:
        # éªŒè¯è¾“å…¥æ–‡ä»¶
        if not os.path.exists(pdf_path):
            return {"success": False, "error": f"PDF æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}"}
        
        if not pdf_path.lower().endswith('.pdf'):
            return {"success": False, "error": "è¾“å…¥æ–‡ä»¶å¿…é¡»æ˜¯ PDF æ ¼å¼"}
        
        # åˆå§‹åŒ–æ¨¡å‹
        init_vllm(gpu_id)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        images_dir = os.path.join(output_dir, 'images')
        os.makedirs(images_dir, exist_ok=True)
        
        sys.stderr.write(f"ğŸ”„ æ­£åœ¨åŠ è½½ PDF: {pdf_path}\n")
        
        # å°† PDF è½¬æ¢ä¸ºå›¾ç‰‡
        images = pdf_to_images_high_quality(pdf_path)
        
        # å‡†å¤‡æ‰¹é‡è¾“å…¥
        prompt = PDF_PROMPT
        
        def process_image(img):
            return process_single_image_for_pdf(img, prompt)
        
        with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:
            batch_inputs = list(tqdm(
                executor.map(process_image, images),
                total=len(images),
                desc="é¢„å¤„ç†å›¾ç‰‡"
            ))
        
        # æ‰¹é‡ç”Ÿæˆ
        sys.stderr.write("ğŸ”„ æ­£åœ¨è¿›è¡Œ OCR è¯†åˆ«...\n")
        outputs_list = _llm.generate(batch_inputs, sampling_params=_sampling_params)
        
        # å¤„ç†è¾“å‡º
        pdf_name = os.path.basename(pdf_path).replace('.pdf', '')
        mmd_path = os.path.join(output_dir, f'{pdf_name}.md')
        
        contents = ''
        page_idx = 0
        
        for output, img in zip(outputs_list, images):
            content = output.outputs[0].text
            
            # æ¸…ç†ç»“æŸæ ‡è®°
            if '<ï½œendâ–ofâ–sentenceï½œ>' in content:
                content = content.replace('<ï½œendâ–ofâ–sentenceï½œ>', '')
            else:
                if SKIP_REPEAT:
                    continue
            
            # æå–å¹¶ä¿å­˜å›¾ç‰‡
            matches_ref, matches_images, matches_other = re_match(content)
            save_cropped_images(img, matches_ref, output_dir, page_idx)
            
            # æ›¿æ¢å›¾ç‰‡æ ‡è®°ä¸º Markdown å›¾ç‰‡é“¾æ¥
            for idx, a_match_image in enumerate(matches_images):
                content = content.replace(
                    a_match_image, 
                    f'![](images/{page_idx}_{idx}.jpg)\n'
                )
            
            # æ¸…ç†å…¶ä»–æ ‡è®°
            for a_match_other in matches_other:
                content = content.replace(a_match_other, '')
            
            content = content.replace('\\coloneqq', ':=')
            content = content.replace('\\eqqcolon', '=:')
            content = content.replace('\n\n\n\n', '\n\n')
            content = content.replace('\n\n\n', '\n\n')
            
            # æ·»åŠ é¡µé¢åˆ†éš”ç¬¦
            page_split = f'\n<--- Page {page_idx + 1} --->\n'
            contents += content + page_split
            
            page_idx += 1
        
        # ä¿å­˜ Markdown æ–‡ä»¶
        with open(mmd_path, 'w', encoding='utf-8') as f:
            f.write(contents)
        
        sys.stderr.write(f"âœ… Markdown æ–‡ä»¶å·²ä¿å­˜: {mmd_path}\n")
        
        return {
            "success": True,
            "markdown_path": mmd_path,
            "images_dir": images_dir,
            "page_count": page_idx,
            "message": f"æˆåŠŸå°† PDF è½¬æ¢ä¸º Markdownï¼Œå…±å¤„ç† {page_idx} é¡µ"
            }
        
    except Exception as e:
        import traceback
        traceback.print_exc(file=sys.stderr)
        return {"success": False, "error": f"è½¬æ¢å¤±è´¥: {str(e)}"}


@mcp.tool()
def augment_markdown_images(
    markdown_path: str,
    output_path: Optional[str] = None,
    image_root: Optional[str] = None,
    cache_json: Optional[str] = None,
    gpu_id: str = "0"
) -> Dict[str, Any]:
    """ä¸º Markdown æ–‡ä»¶ä¸­çš„å›¾ç‰‡é“¾æ¥æ·»åŠ è§£æå†…å®¹
    
    Args:
        markdown_path (str): è¾“å…¥çš„ Markdown æ–‡ä»¶è·¯å¾„
        output_path (str, optional): è¾“å‡ºæ–‡ä»¶è·¯å¾„ã€‚å¦‚æœä¸æŒ‡å®šï¼Œä¼šåœ¨åŸæ–‡ä»¶åååŠ  _augmented
        image_root (str, optional): å›¾ç‰‡æ ¹ç›®å½•ã€‚å¦‚æœä¸æŒ‡å®šï¼Œä½¿ç”¨ Markdown æ–‡ä»¶æ‰€åœ¨ç›®å½•
        cache_json (str, optional): ç¼“å­˜æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºé¿å…é‡å¤è§£æç›¸åŒå›¾ç‰‡
        gpu_id (str): ä½¿ç”¨çš„ GPU ID (é»˜è®¤: "0")
        
    Returns:
        Dict[str, Any]: åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸
            - success: æ˜¯å¦æˆåŠŸ
            - output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            - images_processed: å¤„ç†çš„å›¾ç‰‡æ•°é‡
            - error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
    """
    try:
        # éªŒè¯è¾“å…¥æ–‡ä»¶
        if not os.path.exists(markdown_path):
            return {"success": False, "error": f"Markdown æ–‡ä»¶ä¸å­˜åœ¨: {markdown_path}"}
        
        # åˆå§‹åŒ–æ¨¡å‹
        init_vllm(gpu_id)
        
        # è®¾ç½®é»˜è®¤è·¯å¾„
        md_dir = os.path.dirname(markdown_path)
        md_name = os.path.basename(markdown_path)
        
        if output_path is None:
            name_without_ext = os.path.splitext(md_name)[0]
            output_path = os.path.join(md_dir, f"{name_without_ext}_augmented.md")
        
        if image_root is None:
            image_root = md_dir
        
        # è¯»å– Markdown æ–‡ä»¶
        with open(markdown_path, 'r', encoding='utf-8') as f:
            md_lines = f.read().splitlines()
        
        # åŠ è½½ç¼“å­˜
        cache = {}
        if cache_json and os.path.exists(cache_json):
            try:
                with open(cache_json, 'r', encoding='utf-8') as f:
                    cache = json.load(f)
            except Exception:
                cache = {}
        
        # å¤„ç†æ¯ä¸€è¡Œ
        out_lines = []
        images_processed = 0
        
        for line in md_lines:
            out_lines.append(line)
            
            # æŸ¥æ‰¾å›¾ç‰‡é“¾æ¥
            m = IMG_PATTERN.search(line)
            if not m:
                continue
            
            img_rel = m.group(1).strip().split("?")[0]
            img_path = img_rel if os.path.isabs(img_rel) else os.path.join(image_root, img_rel)
                
            if not os.path.exists(img_path):
                out_lines.append(f"<!-- WARN: image not found: {img_rel} -->")
                continue
                            
            # æ£€æŸ¥ç¼“å­˜æˆ–è§£æå›¾ç‰‡
            if cache_json and img_path in cache:
                result = cache[img_path]
            else:
                sys.stderr.write(f"ğŸ”„ æ­£åœ¨è§£æå›¾ç‰‡: {os.path.basename(img_path)}\n")
                result = call_deepseek_ocr_image(img_path)
                if cache_json:
                    cache[img_path] = result
            
            # æ·»åŠ è§£æå†…å®¹
            alt, cap, body = result["alt"], result["caption"], result["content_md"]
            
            if cap:
                out_lines.append(f"*{cap}*")
            if body:
                out_lines.append("<details><summary>å›¾ç‰‡è§£æ</summary>\n")
                out_lines.append(body)
                out_lines.append("\n</details>")
            
            images_processed += 1
        
        # ä¿å­˜è¾“å‡ºæ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(out_lines))
                        
        # ä¿å­˜ç¼“å­˜
        if cache_json:
            cache_dir = os.path.dirname(cache_json)
            if cache_dir:
                os.makedirs(cache_dir, exist_ok=True)
            with open(cache_json, 'w', encoding='utf-8') as f:
                json.dump(cache, f, ensure_ascii=False, indent=2)
        
        sys.stderr.write(f"âœ… å¢å¼ºåçš„ Markdown å·²ä¿å­˜: {output_path}\n")
        
        return {
            "success": True,
            "output_path": output_path,
            "images_processed": images_processed,
            "message": f"æˆåŠŸå¤„ç† {images_processed} å¼ å›¾ç‰‡"
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc(file=sys.stderr)
        return {"success": False, "error": f"å¤„ç†å¤±è´¥: {str(e)}"}


@mcp.tool()
def pdf_to_markdown_full(
    pdf_path: str,
    output_dir: str,
    augment_images: bool = True,
    cache_json: Optional[str] = None,
    gpu_id: str = "0"
) -> Dict[str, Any]:
    """ä¸€ç«™å¼å°† PDF è½¬æ¢ä¸º Markdown å¹¶è§£æå›¾ç‰‡å†…å®¹
    
    è¿™ä¸ªå·¥å…·ä¼šï¼š
    1. å°† PDF è½¬æ¢ä¸º Markdownï¼ˆæå–æ–‡æœ¬å’Œå›¾ç‰‡ï¼‰
    2. å¦‚æœ augment_images=Trueï¼Œå¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œ OCR è§£æå¹¶æ·»åŠ åˆ° Markdown ä¸­
    
    Args:
        pdf_path (str): PDF æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ (ä¾‹å¦‚: "/path/to/document.pdf")
        output_dir (str): è¾“å‡ºç›®å½•çš„å®Œæ•´è·¯å¾„ (ä¾‹å¦‚: "/path/to/output")
        augment_images (bool): æ˜¯å¦è§£æå›¾ç‰‡å†…å®¹ (é»˜è®¤: True)
        cache_json (str, optional): å›¾ç‰‡è§£æç¼“å­˜æ–‡ä»¶è·¯å¾„
        gpu_id (str): ä½¿ç”¨çš„ GPU ID (é»˜è®¤: "0")
    
    Returns:
        Dict[str, Any]: åŒ…å«è½¬æ¢ç»“æœçš„å­—å…¸
            - success: æ˜¯å¦æˆåŠŸ
            - markdown_path: åŸºç¡€ Markdown æ–‡ä»¶è·¯å¾„
            - augmented_path: å¢å¼ºåçš„ Markdown æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœ augment_images=Trueï¼‰
            - images_dir: å›¾ç‰‡ä¿å­˜ç›®å½•
            - page_count: å¤„ç†çš„é¡µæ•°
            - images_processed: è§£æçš„å›¾ç‰‡æ•°é‡
            - error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
    """
    try:
        # æ­¥éª¤1ï¼šå°† PDF è½¬æ¢ä¸º Markdown
        sys.stderr.write("=" * 50 + "\n")
        sys.stderr.write("ğŸ“„ æ­¥éª¤ 1/2: å°† PDF è½¬æ¢ä¸º Markdown\n")
        sys.stderr.write("=" * 50 + "\n")
        
        step1_result = pdf_to_markdown(pdf_path, output_dir, gpu_id)
        
        if not step1_result.get("success"):
            return step1_result
        
        result = {
            "success": True,
            "markdown_path": step1_result["markdown_path"],
            "images_dir": step1_result["images_dir"],
            "page_count": step1_result["page_count"],
        }
        
        # æ­¥éª¤2ï¼šè§£æå›¾ç‰‡å†…å®¹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if augment_images:
            sys.stderr.write("\n" + "=" * 50 + "\n")
            sys.stderr.write("ğŸ–¼ï¸ æ­¥éª¤ 2/2: è§£æå›¾ç‰‡å†…å®¹\n")
            sys.stderr.write("=" * 50 + "\n")
            
            # è®¾ç½®é»˜è®¤ç¼“å­˜è·¯å¾„
            if cache_json is None:
                cache_json = os.path.join(output_dir, "image_cache.json")
            
            step2_result = augment_markdown_images(
                markdown_path=step1_result["markdown_path"],
                output_path=None,  # ä½¿ç”¨é»˜è®¤è·¯å¾„
                image_root=output_dir,
                cache_json=cache_json,
                gpu_id=gpu_id
            )
            
            if step2_result.get("success"):
                result["augmented_path"] = step2_result["output_path"]
                result["images_processed"] = step2_result["images_processed"]
            else:
                result["augment_warning"] = step2_result.get("error", "å›¾ç‰‡è§£æå¤±è´¥")
        
        result["message"] = f"PDF è½¬æ¢å®Œæˆï¼å…± {result['page_count']} é¡µ"
        if augment_images and "images_processed" in result:
            result["message"] += f"ï¼Œè§£æäº† {result['images_processed']} å¼ å›¾ç‰‡"
        
        sys.stderr.write("\n" + "=" * 50 + "\n")
        sys.stderr.write("âœ… å…¨éƒ¨å¤„ç†å®Œæˆï¼\n")
        sys.stderr.write("=" * 50 + "\n")
            
        return result
        
    except Exception as e:
        import traceback
        traceback.print_exc(file=sys.stderr)
        return {"success": False, "error": f"å¤„ç†å¤±è´¥: {str(e)}"}


def log_stderr(msg: str):
    """å°†æ—¥å¿—è¾“å‡ºåˆ° stderrï¼ˆé¿å…å¹²æ‰° MCP stdio é€šä¿¡ï¼‰"""
    sys.stderr.write(f"{msg}\n")
    sys.stderr.flush()


def main():
    """MCP æœåŠ¡å™¨å…¥å£ç‚¹"""
    import warnings
    warnings.filterwarnings("ignore")
    
    parser = argparse.ArgumentParser(
        description="PDF to Markdown MCP Server",
        add_help=False
    )
    
    parser.add_argument(
        '--transport', 
        default='stdio', 
        choices=['stdio', 'sse', 'streamable-http'],
        help='ä¼ è¾“ç±»å‹ (stdio, sse, æˆ– streamable-http)'
    )
    
    parser.add_argument(
        '--model_path',
        type=str,
        default=None,
        help='DeepSeek-OCR æ¨¡å‹è·¯å¾„'
    )
    
    parser.add_argument(
        '--gpu_id',
        type=str, 
        default='0',
        help='ä½¿ç”¨çš„ GPU ID'
    )
    
    try:
        args = parser.parse_args()
        
        # æ›´æ–°å…¨å±€é…ç½®
        global MODEL_PATH
        if args.model_path:
            MODEL_PATH = args.model_path
        
        # ä½¿ç”¨ stderr è¾“å‡ºæ—¥å¿—ï¼Œé¿å…å¹²æ‰° MCP stdio é€šä¿¡
        log_stderr(f"ğŸš€ PDF to Markdown MCP Server å¯åŠ¨ä¸­...")
        log_stderr(f"   æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
        log_stderr(f"   GPU ID: {args.gpu_id}")
        log_stderr(f"   DeepSeek-OCR è·¯å¾„: {DEEPSEEK_OCR_PATH}")
        
        # è¿è¡Œ MCP æœåŠ¡å™¨
        mcp.run(transport=args.transport)
        
    except Exception as e:
        import traceback
        traceback.print_exc(file=sys.stderr)
        sys.stderr.write(f"å¯åŠ¨å¤±è´¥: {str(e)}\n")
        sys.exit(1)


if __name__ == "__main__":
    main()
