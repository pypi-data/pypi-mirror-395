# ğŸ¦œï¸ğŸ§° langchain-dev-utils

<p align="center">
    <em>ç”¨äº LangChain å’Œ LangGraph å¼€å‘çš„å®ç”¨å·¥å…·åº“ã€‚</em>
</p>

<p align="center">
  ğŸ“š <a href="https://tbice123123.github.io/langchain-dev-utils/">English</a> â€¢ 
  <a href="https://tbice123123.github.io/langchain-dev-utils/zh/">ä¸­æ–‡</a>
</p>

[![PyPI](https://img.shields.io/pypi/v/langchain-dev-utils.svg?color=%2334D058&label=pypi%20package)](https://pypi.org/project/langchain-dev-utils/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/python-3.11|3.12|3.13|3.14-%2334D058)](https://www.python.org/downloads)
[![Downloads](https://static.pepy.tech/badge/langchain-dev-utils/month)](https://pepy.tech/project/langchain-dev-utils)
[![Documentation](https://img.shields.io/badge/docs-latest-blue)](https://tbice123123.github.io/langchain-dev-utils/zh/)

> å½“å‰ä¸ºä¸­æ–‡ç‰ˆï¼Œè‹±æ–‡ç‰ˆè¯·è®¿é—®[English Documentation](https://github.com/TBice123123/langchain-dev-utils/blob/master/README.md)

**langchain-dev-utils** æ˜¯ä¸€ä¸ªä¸“æ³¨äºæå‡ LangChain å’Œ LangGraph å¼€å‘ä½“éªŒçš„å®ç”¨å·¥å…·åº“ã€‚å®ƒæä¾›äº†ä¸€ç³»åˆ—å¼€ç®±å³ç”¨çš„å·¥å…·å‡½æ•°ï¼Œæ—¢èƒ½å‡å°‘é‡å¤ä»£ç ç¼–å†™ï¼Œåˆèƒ½æé«˜ä»£ç çš„ä¸€è‡´æ€§å’Œå¯è¯»æ€§ã€‚é€šè¿‡ç®€åŒ–å¼€å‘å·¥ä½œæµç¨‹ï¼Œè¿™ä¸ªåº“å¯ä»¥å¸®åŠ©ä½ æ›´å¿«åœ°æ„å»ºåŸå‹ã€æ›´é¡ºç•…åœ°è¿›è¡Œè¿­ä»£ï¼Œå¹¶åˆ›å»ºæ›´æ¸…æ™°ã€æ›´å¯é çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ AI åº”ç”¨ã€‚

## ğŸš€ å®‰è£…

```bash
pip install -U langchain-dev-utils

# å®‰è£…å®Œæ•´åŠŸèƒ½ç‰ˆï¼š
pip install -U langchain-dev-utils[standard]
```

## ğŸ“¦ æ ¸å¿ƒåŠŸèƒ½

### 1. **æ¨¡å‹ç®¡ç†**

åœ¨ `langchain` ä¸­ï¼Œ`init_chat_model`/`init_embeddings` å‡½æ•°å¯ç”¨äºåˆå§‹åŒ–å¯¹è¯æ¨¡å‹å®ä¾‹/åµŒå…¥æ¨¡å‹å®ä¾‹ï¼Œä½†å…¶æ”¯æŒçš„æ¨¡å‹æä¾›å•†è¾ƒä¸ºæœ‰é™ã€‚æœ¬æ¨¡å—æä¾›äº†ä¸€ä¸ªæ³¨å†Œå‡½æ•°ï¼ˆ`register_model_provider`/`register_embeddings_provider`ï¼‰ï¼Œæ–¹ä¾¿æ³¨å†Œä»»æ„æ¨¡å‹æä¾›å•†ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨ `load_chat_model` / `load_embeddings` è¿›è¡Œæ¨¡å‹åŠ è½½ã€‚

#### 1.1 å¯¹è¯æ¨¡å‹ç®¡ç†

ä¸»è¦æœ‰ä»¥ä¸‹ä¸¤ä¸ªå‡½æ•°ï¼š

- `register_model_provider`ï¼šæ³¨å†Œå¯¹è¯æ¨¡å‹æä¾›å•†
- `load_chat_model`ï¼šåŠ è½½å¯¹è¯æ¨¡å‹

å‡è®¾æ¥å…¥ä½¿ç”¨`vllm`éƒ¨ç½²çš„ qwen3-4b æ¨¡å‹ï¼Œåˆ™å‚è€ƒä»£ç å¦‚ä¸‹ï¼š

```python
from langchain_dev_utils.chat_models import (
    register_model_provider,
    load_chat_model,
)

# æ³¨å†Œæ¨¡å‹æä¾›å•†
register_model_provider(
    provider_name="vllm",
    chat_model="openai-compatible",
    base_url="http://localhost:8000/v1",
)

# åŠ è½½æ¨¡å‹
model = load_chat_model("vllm:qwen3-4b")
print(model.invoke("Hello"))
```

#### 1.2 åµŒå…¥æ¨¡å‹ç®¡ç†

ä¸»è¦æœ‰ä»¥ä¸‹ä¸¤ä¸ªå‡½æ•°ï¼š

- `register_embeddings_provider`ï¼šæ³¨å†ŒåµŒå…¥æ¨¡å‹æä¾›å•†
- `load_embeddings`ï¼šåŠ è½½åµŒå…¥æ¨¡å‹

å‡è®¾æ¥å…¥ä½¿ç”¨`vllm`éƒ¨ç½²çš„ qwen3-embedding-4b æ¨¡å‹ï¼Œåˆ™å‚è€ƒä»£ç å¦‚ä¸‹ï¼š

```python
from langchain_dev_utils.embeddings import register_embeddings_provider, load_embeddings

# æ³¨å†ŒåµŒå…¥æ¨¡å‹æä¾›å•†
register_embeddings_provider(
    provider_name="vllm",
    embeddings_model="openai-compatible",
    base_url="http://localhost:8000/v1",
)

# åŠ è½½åµŒå…¥æ¨¡å‹
embeddings = load_embeddings("vllm:qwen3-embedding-4b")
emb = embeddings.embed_query("Hello")
print(emb)
```


### 2. **æ¶ˆæ¯è½¬æ¢**

åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

- å°†æ€ç»´é“¾å†…å®¹åˆå¹¶åˆ°æœ€ç»ˆå“åº”ä¸­
- æµå¼å†…å®¹åˆå¹¶
- å†…å®¹æ ¼å¼åŒ–å·¥å…·

#### 2.1 æµå¼å†…å®¹åˆå¹¶

å¯¹äºä½¿ç”¨`stream()`å’Œ`astream()`æ‰€è·å¾—çš„æµå¼å“åº”ï¼Œå¯ä»¥ä½¿ç”¨`merge_ai_message_chunk`è¿›è¡Œåˆå¹¶ä¸ºä¸€ä¸ªæœ€ç»ˆçš„ AIMessageã€‚

```python
from langchain_dev_utils.message_convert import merge_ai_message_chunk
chunks = list(model.stream("Hello"))
merged = merge_ai_message_chunk(chunks)
```

#### 2.2 æ ¼å¼åŒ–åˆ—è¡¨å†…å®¹

å¯¹äºä¸€ä¸ªåˆ—è¡¨ï¼Œå¯ä»¥ä½¿ç”¨`format_sequence`è¿›è¡Œæ ¼å¼åŒ–ã€‚

```python
from langchain_dev_utils.message_convert import format_sequence
text = format_sequence([
    "str1",
    "str2",
    "str3"
], separator="\n", with_num=True)
```


### 3. **å·¥å…·è°ƒç”¨**

åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

- æ£€æŸ¥å’Œè§£æå·¥å…·è°ƒç”¨
- æ·»åŠ äººæœºäº¤äº’åŠŸèƒ½

#### 3.1 æ£€æŸ¥å’Œè§£æå·¥å…·è°ƒç”¨

`has_tool_calling`å’Œ`parse_tool_calling`ç”¨äºæ£€æŸ¥å’Œè§£æå·¥å…·è°ƒç”¨ã€‚

```python
import datetime
from langchain_core.tools import tool
from langchain_dev_utils.tool_calling import has_tool_calling, parse_tool_calling

@tool
def get_current_time() -> str:
    """è·å–å½“å‰æ—¶é—´æˆ³"""
    return str(datetime.datetime.now().timestamp())

response = model.bind_tools([get_current_time]).invoke("ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ")

if has_tool_calling(response):
    name, args = parse_tool_calling(
        response, first_tool_call_only=True
    )
    print(name, args)
```

#### 3.2 æ·»åŠ äººæœºäº¤äº’åŠŸèƒ½

- `human_in_the_loop`ï¼šç”¨äºåŒæ­¥å·¥å…·å‡½æ•°
- `human_in_the_loop_async`ï¼šç”¨äºå¼‚æ­¥å·¥å…·å‡½æ•°

å…¶ä¸­éƒ½å¯ä»¥ä¼ é€’`handler`å‚æ•°ï¼Œç”¨äºè‡ªå®šä¹‰æ–­ç‚¹è¿”å›å’Œå“åº”å¤„ç†é€»è¾‘ã€‚

```python
from langchain_dev_utils.tool_calling import human_in_the_loop
from langchain_core.tools import tool
import datetime

@human_in_the_loop
@tool
def get_current_time() -> str:
    """è·å–å½“å‰æ—¶é—´æˆ³"""
    return str(datetime.datetime.now().timestamp())
```


### 4. **æ™ºèƒ½ä½“å¼€å‘**

åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

- å¤šæ™ºèƒ½ä½“æ„å»º
- å¸¸ç”¨çš„ä¸­é—´ä»¶ç»„ä»¶

#### 4.1 å¤šæ™ºèƒ½ä½“æ„å»º

å°†æ™ºèƒ½ä½“å°è£…ä¸ºå·¥å…·æ˜¯å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„ä¸€ç§å¸¸è§å®ç°æ¨¡å¼ï¼ŒLangChain å®˜æ–¹æ–‡æ¡£å¯¹æ­¤æœ‰è¯¦ç»†é˜è¿°ã€‚ä¸ºæ­¤ï¼Œæœ¬åº“æä¾›äº†é¢„æ„å»ºå‡½æ•°`wrap_agent_as_tool` æ¥å®ç°æ­¤æ¨¡å¼ï¼Œè¯¥å‡½æ•°èƒ½å¤Ÿå°†ä¸€ä¸ªæ™ºèƒ½ä½“å®ä¾‹å°è£…æˆä¸€ä¸ªå¯ä¾›å…¶å®ƒæ™ºèƒ½ä½“è°ƒç”¨çš„å·¥å…·ã€‚

ä½¿ç”¨ç¤ºä¾‹ï¼š

```python
import datetime
from langchain_dev_utils.agents import create_agent, wrap_agent_as_tool
from langchain.agents import AgentState

@tool
def get_current_time() -> str:
    """è·å–å½“å‰æ—¶é—´"""
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

time_agent = create_agent("vllm:qwen3-4b", tools=[get_current_time], name="time-agent")
call_time_agent_tool = wrap_agent_as_tool(time_agent)  

agent = create_agent(
    "vllm:qwen3-4b",
    name="agent",
    tools=[call_time_agent_tool],
)
response = agent.invoke(
    {"messages": [{"role": "user", "content": "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ"}]}
)
print(response)
```

#### 4.2 ä¸­é—´ä»¶

æä¾›äº†ä¸€äº›å¸¸ç”¨çš„ä¸­é—´ä»¶ç»„ä»¶ã€‚ä¸‹é¢ä»¥`ToolCallRepairMiddleware`å’Œ`PlanMiddleware`ä¸ºä¾‹ã€‚

`ToolCallRepairMiddleware`ç”¨äºå¤§æ¨¡å‹çš„ `invaild_tool_calls` å†…å®¹çš„ä¿®å¤ã€‚

`PlanMiddleware`ç”¨äºæ™ºèƒ½ä½“çš„è®¡åˆ’ã€‚

```python
from langchain_dev_utils.agents.middleware import (
    ToolCallRepairMiddleware,
    PlanMiddleware,
)

agent=create_agent(
    "vllm:qwen3-4b",
    name="plan-agent",
    middleware=[ToolCallRepairMiddleware(), PlanMiddleware(
        use_read_plan_tool=False
    )]
)
response = agent.invoke({"messages": [{"role": "user", "content": "ç»™æˆ‘ä¸€ä¸ªå»çº½çº¦æ—…è¡Œçš„è®¡åˆ’"}]}))
print(response)
```


### 5. **çŠ¶æ€å›¾ç¼–æ’**

åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

- é¡ºåºå›¾ç¼–æ’
- å¹¶è¡Œå›¾ç¼–æ’

#### 5.1 é¡ºåºå›¾ç¼–æ’

åˆ©ç”¨`create_sequential_pipeline`å¯ä»¥å°†å¤šä¸ªå­å›¾æŒ‰ç…§é¡ºåºè¿›è¡Œç¼–æ’ï¼š

```python
from langchain.agents import AgentState
from langchain_core.messages import HumanMessage
from langchain_dev_utils.agents import create_agent
from langchain_dev_utils.pipeline import create_sequential_pipeline
from langchain_dev_utils.chat_models import register_model_provider

register_model_provider(
    provider_name="vllm",
    chat_model="openai-compatible",
    base_url="http://localhost:8000/v1",
)

# æ„å»ºé¡ºåºç®¡é“ï¼ˆæ‰€æœ‰å­å›¾é¡ºåºæ‰§è¡Œï¼‰
graph = create_sequential_pipeline(
    sub_graphs=[
        create_agent(
            model="vllm:qwen3-4b",
            tools=[get_current_time],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæ—¶é—´æŸ¥è¯¢åŠ©æ‰‹,ä»…èƒ½å›ç­”å½“å‰æ—¶é—´,å¦‚æœè¿™ä¸ªé—®é¢˜å’Œæ—¶é—´æ— å…³,è¯·ç›´æ¥å›ç­”æˆ‘æ— æ³•å›ç­”",
            name="time_agent",
        ),
        create_agent(
            model="vllm:qwen3-4b",
            tools=[get_current_weather],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªå¤©æ°”æŸ¥è¯¢åŠ©æ‰‹,ä»…èƒ½å›ç­”å½“å‰å¤©æ°”,å¦‚æœè¿™ä¸ªé—®é¢˜å’Œå¤©æ°”æ— å…³,è¯·ç›´æ¥å›ç­”æˆ‘æ— æ³•å›ç­”",
            name="weather_agent",
        ),
        create_agent(
            model="vllm:qwen3-4b",
            tools=[get_current_user],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªç”¨æˆ·æŸ¥è¯¢åŠ©æ‰‹,ä»…èƒ½å›ç­”å½“å‰ç”¨æˆ·,å¦‚æœè¿™ä¸ªé—®é¢˜å’Œç”¨æˆ·æ— å…³,è¯·ç›´æ¥å›ç­”æˆ‘æ— æ³•å›ç­”",
            name="user_agent",
        ),
    ],
    state_schema=AgentState,
)

response = graph.invoke({"messages": [HumanMessage("ä½ å¥½")]})
print(response)
```

#### 5.2 å¹¶è¡Œå›¾ç¼–æ’

åˆ©ç”¨`create_parallel_pipeline`å¯ä»¥å°†å¤šä¸ªå­å›¾æŒ‰ç…§å¹¶è¡Œè¿›è¡Œç¼–æ’ï¼š

```python
from langchain_dev_utils.pipeline import create_parallel_pipeline

# æ„å»ºå¹¶è¡Œç®¡é“ï¼ˆæ‰€æœ‰å­å›¾å¹¶è¡Œæ‰§è¡Œï¼‰
graph = create_parallel_pipeline(
    sub_graphs=[
        create_agent(
            model="vllm:qwen3-4b",
            tools=[get_current_time],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæ—¶é—´æŸ¥è¯¢åŠ©æ‰‹,ä»…èƒ½å›ç­”å½“å‰æ—¶é—´,å¦‚æœè¿™ä¸ªé—®é¢˜å’Œæ—¶é—´æ— å…³,è¯·ç›´æ¥å›ç­”æˆ‘æ— æ³•å›ç­”",
            name="time_agent",
        ),
        create_agent(
            model="vllm:qwen3-4b",
            tools=[get_current_weather],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªå¤©æ°”æŸ¥è¯¢åŠ©æ‰‹,ä»…èƒ½å›ç­”å½“å‰å¤©æ°”,å¦‚æœè¿™ä¸ªé—®é¢˜å’Œå¤©æ°”æ— å…³,è¯·ç›´æ¥å›ç­”æˆ‘æ— æ³•å›ç­”",
            name="weather_agent",
        ),
        create_agent(
            model="vllm:qwen3-4b",
            tools=[get_current_user],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªç”¨æˆ·æŸ¥è¯¢åŠ©æ‰‹,ä»…èƒ½å›ç­”å½“å‰ç”¨æˆ·,å¦‚æœè¿™ä¸ªé—®é¢˜å’Œç”¨æˆ·æ— å…³,è¯·ç›´æ¥å›ç­”æˆ‘æ— æ³•å›ç­”",
            name="user_agent",
        ),
    ],
    state_schema=AgentState,
)
response = graph.invoke({"messages": [HumanMessage("ä½ å¥½")]})
print(response)
```


## ğŸ’¬ åŠ å…¥ç¤¾åŒº

- [GitHub ä»“åº“](https://github.com/TBice123123/langchain-dev-utils) â€” æµè§ˆæºä»£ç ï¼Œæäº¤ Pull Request
- [é—®é¢˜è¿½è¸ª](https://github.com/TBice123123/langchain-dev-utils/issues) â€” æŠ¥å‘Š Bug æˆ–æå‡ºæ”¹è¿›å»ºè®®
- æˆ‘ä»¬æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ® â€”â€” æ— è®ºæ˜¯ä»£ç ã€æ–‡æ¡£è¿˜æ˜¯ä½¿ç”¨ç¤ºä¾‹ã€‚è®©æˆ‘ä»¬ä¸€èµ·æ„å»ºä¸€ä¸ªæ›´å¼ºå¤§ã€æ›´å®ç”¨çš„ LangChain å¼€å‘ç”Ÿæ€ç³»ç»Ÿï¼
