{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a675d2a8",
   "metadata": {
    "id": "a675d2a8"
   },
   "source": [
    "# ORCA-PT-1 Hands-On Tutorial\n",
    "Welcome to the hands-on introduction to the **ORCA-PT-1 Quantum Computer** via the PCSS QAPI.\n",
    "\n",
    "This notebook includes three practical sections:\n",
    "- **Time Bin Interferometer (TBI)**: for quantum sampling.\n",
    "- **Quantum ML Layer (PTLayer)**: for neural network integration.\n",
    "- **Binary Bosonic Solver (BBS)**: for combinatorial optimization.\n",
    "\n",
    "Each section includes meaningful use cases to build from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce082013",
   "metadata": {
    "id": "ce082013",
    "outputId": "3fefe843-9752-490a-b913-f1e47689b0b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîê Authorize Access\n",
      "----------------------------------------\n",
      "You are about to be redirected to an authorization server.\n",
      "There, you will be asked to grant access permissions.\n",
      "This allows the system to act on your behalf using delegated access.\n",
      "Please confirm only if you trust this application.\n",
      "‚û°Ô∏è  Click to authorize: https://sso.classroom.pionier.net.pl/auth/realms/Classroom/device?user_code=GNBM-PMMU\n",
      "\n",
      "‚úÖ Access granted.                                                     \n"
     ]
    }
   ],
   "source": [
    "from pcss_qapi import AuthorizationService\n",
    "# Log in to PCSS QAPI (interactive prompt will appear)\n",
    "AuthorizationService.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8595ef4d-4945-40c1-a25e-d05ec5c84498",
   "metadata": {},
   "source": [
    "In the next cell we initialize the OrcaProvider, which can list available quantum simulators and real devices. It helps to check the computing backends accessible after login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a47580b-a389-4709-a5b6-0e3be0dff313",
   "metadata": {
    "id": "a13b3ad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available simulators: ['single_loop_simulator', 'multi_loop_simulator']\n",
      "Available real devices: ['ORCA-PT-1-A', 'ORCA-PT-1-B']\n"
     ]
    }
   ],
   "source": [
    "from pcss_qapi.orca.provider import OrcaProvider\n",
    "provider = OrcaProvider() \n",
    "\n",
    "print(\"Available simulators:\", provider.available_backends(simulators=True))\n",
    "print(\"Available real devices:\", provider.available_backends(simulators=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620a9229",
   "metadata": {
    "id": "620a9229"
   },
   "source": [
    "## 1. Time Bin Interferometer (TBI)\n",
    "\n",
    "The Time Bin Interferometer (TBI) is used to simulate quantum interference from multi-photon inputs over looped time-bin paths.  \n",
    "**Sampling** refers to drawing repeated outcomes from a quantum circuit probabilistically, akin to sampling from a quantum distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ab78a",
   "metadata": {
    "id": "087ab78a"
   },
   "outputs": [],
   "source": [
    "# Choose backend\n",
    "backend = provider.get_backend(\"multi_loop_simulator\")\n",
    "\n",
    "# Get the tbi from the chosen backend\n",
    "tbi = backend.get_tbi()\n",
    "tbi.draw(input_state = [1, 0, 1, 0])\n",
    "\n",
    "# Tbi's sample method runs sampling\n",
    "samples = tbi.sample(input_state=[1, 0, 1, 0], theta_list=[0.2, 1.0, 0.2], n_samples=50)\n",
    "\n",
    "print(\"TBI samples:\", samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ba71ab",
   "metadata": {},
   "source": [
    "Observe how output changes based on the changes of theta list. If we set the input_state to [1, 0] and leave default value of loop lengths, which is [1], there will be only one beam splitter. There is a simple way to calculate number of beam splitters in the tbi: Just substract length of the loop from length of the input state for every loop and sum over all loops. Alternatively you can use ptseries' built in function calculate_parameters (It requires importing from the right file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbi.draw(input_state = [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd803cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBI samples: {(1, 0): 50}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "samples = tbi.sample(input_state=[1, 0], theta_list=[0], n_samples=50)\n",
    "\n",
    "print(\"TBI samples:\", samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a9cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = tbi.sample(input_state=[1, 0], theta_list=[np.pi / 2], n_samples=50)\n",
    "\n",
    "print(\"TBI samples:\", samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f35f0",
   "metadata": {},
   "source": [
    "Even though the input state stays the same, change in the angle of beam splitter causes photons to end up in the other detector. Notice that angles are passed as radians, so beam splitter with angle set to integer * Pi will work as it would have it's angle set to 0. You can also change the input_state however you want, but keep in mind, that bigger input state complexifies the circuit and lenghtens processing time. It is worth to mention that on real hardware length of the input_state doesn't have that much impact on the processing time as number of photons does. There can be a situation where circuit with input_state [1, 0, 0, 0, 0] will be much faster than [1, 1, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa6fec",
   "metadata": {},
   "source": [
    "There are two more parameters with which you can directly influence the output of the sample method. First one is really usefull - n_tiling. Try figuring out what it does.  \n",
    "  \n",
    "Tip: Make sure that length of theta list is multiplied by the number you chose n_tiling to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e43cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = tbi.sample(input_state=[1, 0], theta_list=[np.pi / 3, np.pi / 2], n_samples=50, n_tiling = 2)\n",
    "\n",
    "print(\"TBI samples:\", samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c0cf65",
   "metadata": {},
   "source": [
    "Tiling is an alternative way of calculating too big circuits. If you use tiling, n_tiling circuits are run separately and outputs are classically merged into one output. Tiling scales linearly, which can cause a situation in which running many smaller circuits is faster than running one big. In this case you'd lose on quantum (because photons don't interact between tiles), but you gain time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd851b0",
   "metadata": {},
   "source": [
    "The other parameter is there purely for convenience. It's caleed output_format and thanks to it you can choose the output to be in a dictionary, tuple, list or array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = tbi.sample(input_state=[1, 0], theta_list=[0], n_samples=50, output_format=\"dict\") # \"tuple\", \"list\", \"array\"\n",
    "\n",
    "print(\"TBI samples:\", samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e477854",
   "metadata": {},
   "source": [
    "You can also influence the output indirectly through TBI parameters. Most of them are there to make simulations not perfect (and you probably will never use them, unless you are doing some deep reserach), but there are two that can be used quite often: n_loops and loop_lengths. See for yourself how they affect the output and structure of the TBI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85680d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbi = backend.get_tbi(n_loops = 3, loop_lengths=[1, 2, 3])\n",
    "\n",
    "tbi.draw(input_state = [1, 0, 1, 0])\n",
    "\n",
    "samples = tbi.sample(input_state=[1, 0, 1, 0], theta_list=[0.1, 0.4, 0.2, 1, 1.5, 2], n_samples=50)\n",
    "\n",
    "print(\"TBI samples:\", samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26998873",
   "metadata": {},
   "source": [
    "N_loops is necessary only when you just want to specify the number of loops and want to use lengths of 1. If you specify loop_lengths, n_loops is not necessary. But what does the length of the loop mean? For example: If you set loop length to 2, only qumodes that have one qumode between them will be connected with beam splitter. If set to 3, then qumodes with 2 qumodes between them will be connected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f1d5fb",
   "metadata": {},
   "source": [
    "## Universal Parameters\n",
    "\n",
    "- **`n_loops`** *(int)*  \n",
    "  Number of loops in the TBI.  \n",
    "\n",
    "- **`loop_lengths`** *(list of int)*  \n",
    "  List of lengths of the loops.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b9e9a",
   "metadata": {},
   "source": [
    "## Simulator Parameters\n",
    "\n",
    "- **`distinguishable`** *(bool)*  \n",
    "  If `True`, photons behave like non-quantum (classical) particles.  \n",
    "\n",
    "- **`bs_loss`** *(float, [0‚Äì1])*  \n",
    "  Probability of photon loss on every beam splitter.  \n",
    "\n",
    "- **`bs_noise`** *(float, [0-1])*  \n",
    "  Percentage by which the beam splitter angle may vary.  \n",
    "\n",
    "- **`input_loss`** *(float, [0‚Äì1])*  \n",
    "  Probability of photon loss at the input.  \n",
    "\n",
    "- **`detector_efficiency`** *(float, [0‚Äì1])*  \n",
    "  Probability of correctly detecting a photon.  \n",
    "\n",
    "- **`n_signal_detectors`** *(int)*  \n",
    "  Number of detectors in the mode.  \n",
    "\n",
    "- **`g2`** *(float)*  \n",
    "  Autocorrelation of a pair of generated photons.  \n",
    "\n",
    "- **`afterpulse_probability`** *(float, [0‚Äì1])*  \n",
    "  Probability of another, unwanted photon being generated.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f230806a",
   "metadata": {},
   "source": [
    "## Real Hardware Parameters\n",
    "\n",
    "- **`postselection`** *(bool)*  \n",
    "  If `True`, enables postselection that reduces errors.  \n",
    "\n",
    "- **`postselection_threshold`** *(int)*  \n",
    "  The threshold for postselection. Defaults to None. If None, and postselection is True, then the threshold is set to the number of input photons.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2bce34",
   "metadata": {},
   "source": [
    "## Playground  \n",
    "Try experimenting with other parameters. In order to use them you have to pass them to the get_tbi method as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e6b457-eec5-4de1-b8a9-2d1d017e3716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6d37e86d-7b1e-4c84-a279-bb2be4203b13',\n",
       " '20885320-a9a9-4af2-bc35-cf290b7f9b7b']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provider.get_task_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator_parameters = {\n",
    "    \"distinguishable\": True,\n",
    "}\n",
    "\n",
    "tbi = backend.get_tbi(simulator_params=simulator_parameters)\n",
    "\n",
    "samples = tbi.sample(input_state=[1, 0, 1, 0], theta_list=[1, 0.5, 2], n_samples=50)\n",
    "\n",
    "print(\"Tbi samples\", samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932be014",
   "metadata": {},
   "source": [
    "## Here you can use the real quantum computer - PT-1  \n",
    "But remember that there are only so many available ones, so if you do not have to, do not run thousands of samples. Real hardware is rather small. It has 8 qumodes and 2 loops which means that the highest length of the input state can be 8 and you can use either 1 or 2 loops, but the lengths are fixed to 1. Also keep in mind that producing singular photons is really hard, so running circuits with more than 4 photons can already be slow. Producing these photons requires shooting laser into a crystal, but in order for that to work the source of the laser has to warm up. So if you are the first user to use the PT-1 it may take additional time. It all sounds like PT-1 has many limitations, but it is the first of it's kind and it's next generation is already being tested and the results are quite convincing. By researching PT-1 we pave the way for the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61597d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBI samples: {(0, 1): 3, (1, 0): 7}\n"
     ]
    }
   ],
   "source": [
    "backend = provider.get_backend(\"ORCA-PT-1-B\")\n",
    "\n",
    "tbi = backend.get_tbi()\n",
    "\n",
    "samples = tbi.sample(input_state=[1, 0], theta_list=[np.pi/4], n_samples=10)\n",
    "\n",
    "print(\"TBI samples:\", samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a3756c",
   "metadata": {
    "id": "86a3756c"
   },
   "source": [
    "## 2. Quantum Machine Learning with PTLayer\n",
    "You can integrate ORCA-PT-1 as a trainable quantum layer inside classical PyTorch models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14224403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to the simulator if you used real hardware\n",
    "\n",
    "backend = provider.get_backend(\"multi_loop_simulator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc70fd6",
   "metadata": {
    "id": "bcc70fd6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Simulate 3 input features representing encoded quantum parameters\n",
    "ptlayer = backend.get_ptlayer(in_features=3)\n",
    "\n",
    "x = torch.tensor([[1.0, -0.5, 0.3]], dtype=torch.float32)\n",
    "output = ptlayer(x)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b818a282",
   "metadata": {
    "id": "b818a282"
   },
   "source": [
    "### Example Use Case: Classifier Feature Injection\n",
    "You can place this layer in the middle of a classical network to enhance non-linearity with quantum interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3672b1c",
   "metadata": {
    "id": "e3672b1c"
   },
   "outputs": [],
   "source": [
    "# Example: feed-forward classifier with quantum middle layer\n",
    "class HybridNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(4, 3)\n",
    "        self.q = backend.get_ptlayer(in_features=3)\n",
    "        self.fc2 = torch.nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.q(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "model = HybridNet()\n",
    "example_input = torch.randn((1, 4))\n",
    "print(\"Predicted output:\", model(example_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481d3f7",
   "metadata": {
    "id": "8481d3f7"
   },
   "source": [
    "### Multi-Class Classification with Iris Dataset and PTLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda656f",
   "metadata": {
    "id": "8cda656f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c62c500-463e-4781-928b-c92848ccbd96",
   "metadata": {},
   "source": [
    "In the next cell we apply Principal Component Analysis (PCA) to reduce the Iris dataset to 2D and plot the classes, allowing for easy visualization of class separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zXCt20hpCDHG",
   "metadata": {
    "id": "zXCt20hpCDHG"
   },
   "outputs": [],
   "source": [
    "# Visualize Iris dataset after PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "plt.figure(figsize=(6, 4))\n",
    "for cls in range(3):\n",
    "    plt.scatter(X_2d[y == cls, 0], X_2d[y == cls, 1], label=iris.target_names[cls])\n",
    "plt.title('Iris Dataset After PCA')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260ec15-7806-4ab3-b620-3cee5afe9fbf",
   "metadata": {},
   "source": [
    "Next, let's create a simple PyTorch hybrid classifier (placeholder for a quantum-classical hybrid). The network stacks fully-connected layers and outputs class probabilities with softmax for the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X4WoZSklCGGy",
   "metadata": {
    "id": "X4WoZSklCGGy"
   },
   "outputs": [],
   "source": [
    "# Define Quantum-Classical Hybrid Network\n",
    "class HybridNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(4, 8)\n",
    "        self.fc2 = torch.nn.Linear(8, 3)\n",
    "        self.q_layer = backend.get_ptlayer(in_features=3)\n",
    "        self.fc3 = torch.nn.Linear(4, 3)  # output 3 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.q_layer(x)\n",
    "        x = self.fc3(x)\n",
    "        return torch.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da7714-53b4-4e7d-a327-e06fbad40bcd",
   "metadata": {},
   "source": [
    "Now we will train the model. We will apply Adam optimizer and run 50 epochs. Each 5th epoch we will print the loss for the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sqNEHHlHCKkG",
   "metadata": {
    "id": "sqNEHHlHCKkG"
   },
   "outputs": [],
   "source": [
    "# Train Model\n",
    "model = HybridNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "import torch.nn.functional as F\n",
    "losses = []\n",
    "\n",
    "for epoch in range(40):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = F.cross_entropy(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss / len(train_loader))\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f99da6-e9db-4358-af11-41727776adf1",
   "metadata": {},
   "source": [
    "Now let's see how the loss decreases though the training and what is the final accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cn6vPDQYCNZU",
   "metadata": {
    "id": "cn6vPDQYCNZU"
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FXZL9PKoCPv3",
   "metadata": {
    "id": "FXZL9PKoCPv3"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test_t)\n",
    "    acc = (preds.argmax(1) == y_test_t).float().mean()\n",
    "print(f\"Test Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2434ad29-0856-47ff-941b-c03325735c7d",
   "metadata": {},
   "source": [
    "Now let's see how many samples were classified correctly and not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure model is in eval mode and gradients are off \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test_t)\n",
    "    predicted_labels = preds.argmax(1)\n",
    "    incorrect = (predicted_labels != y_test_t)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "    \n",
    "for cls in range(3):\n",
    "    plt.scatter(X_test[y_test == cls, 0], X_test[y_test == cls, 1], label = iris.target_names[cls])\n",
    "    \n",
    "plt.scatter(X_test[incorrect, 0], X_test[incorrect, 1], c='red', marker='x')\n",
    "\n",
    "# Visualization\n",
    "plt.title('Iris Dataset After PCA with errors marked')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d2f47",
   "metadata": {},
   "source": [
    "PTLayer as well as TBI also has some additional parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de7eb4b",
   "metadata": {},
   "source": [
    "## Layer Parameters\n",
    "\n",
    "- **`input_state`** *(list of int)*  \n",
    "  State that will be passed to the TBI.  \n",
    "\n",
    "- **`in_features`** *(list of float)*  \n",
    "  Angles of the beam splitters, determined by the input of the layer.  \n",
    "  If set to a list with samller length than the number of beam splitters, the remaining beam splitters become trainable parameters.  \n",
    "\n",
    "- **`tbi_params`** *(dict)*  \n",
    "  Parameters of the TBI to be used in the `PTLayer`.  \n",
    "\n",
    "- **`observable`** *(str)*  \n",
    "  Method of interpreting detected photons:  \n",
    "  - `\"mean\"` ‚Üí use `Mean()` (single-mode mean photon numbers).  \n",
    "  - `\"correlations\"` ‚Üí use `Correlations()` (two-point photon correlators).  \n",
    "  - `\"covariances\"` ‚Üí use `Covariances()` (two-point photon covariances).  \n",
    "  - `\"single-sample\"` ‚Üí use `SingleSample()` (one Monte Carlo sample per forward pass).  \n",
    "\n",
    "- **`n_samples`** *(int)*  \n",
    "  Number of samples to draw.  \n",
    "\n",
    "- **`n_tiling`** *(int)*  \n",
    "  Number of tiles. Tiles are replicas of the circuit that are later postprocessed to behave as one big circuit.  \n",
    "\n",
    "- **`gradient_mode`** *(str)*  \n",
    "  Method of gradient calculation:  \n",
    "  - `\"parameter-shift\"`  \n",
    "  - `\"finite-difference\"`  \n",
    "  - `\"spsa\"`  \n",
    "\n",
    "- **`gradient_delta`** *(float)*  \n",
    "  Value used for gradient calculation.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb8344",
   "metadata": {},
   "source": [
    "## Playground\n",
    "Check out how other parameters influence the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb8577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e85cc3c",
   "metadata": {
    "id": "2e85cc3c"
   },
   "source": [
    "## 3. Binary Bosonic Solver (BBS)\n",
    "\n",
    "The BBS algorithm solves **combinatorial optimization problems** using quantum-classical loop. Certain output state is obtained from TBI and mapped to potential binary solution of a problem. After that bitflip model is applied negating certain values of the solution based on probabilities. These probabilities are trainable parameters of the model. After negating the bits, the solution is evaluated based on an objective. Based on the value of evaluation score, known as cost or energy, model parameters are updated using gradient methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5af9e8",
   "metadata": {},
   "source": [
    "Here you will solve an instance of the Max-Cut problem.  \n",
    "\n",
    "The Max-Cut problem is about dividing the set of vertices of a graph into two groups so that the number of edges connecting these groups is as large as possible. In other words, we want to ‚Äúcut‚Äù the graph into two parts and count how many edges cross between them ‚Äî and the goal is to maximize that number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862bf7c7",
   "metadata": {
    "id": "862bf7c7"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Define a small graph.\n",
    "\n",
    "edges = [(0, 1), (1, 2), (2,3), (3,0)]\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "nx.draw(G, pos, node_size=800, font_color=\"white\")\n",
    "plt.show()\n",
    "\n",
    "def objective_function(x):\n",
    "    return sum([int(x[i] == x[j]) for i, j in edges])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4311f65",
   "metadata": {},
   "source": [
    "BBS always tries to minimize given objective function, so make sure that objective function does what you want and not the opposite. Here we want to maximize the number of cuts, but since BBS minimizes we have to negate the objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40642513",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs = backend.get_bbs(pb_dim = 4, objective = objective_function)\n",
    "bbs.solve(updates=20, print_frequency=2)\n",
    "\n",
    "best_energy = bbs.best_cost\n",
    "solution = bbs.best_solution\n",
    "\n",
    "print(\"Best energy:\", best_energy)\n",
    "\n",
    "colors = [\"red\" if solution[i] == 0 else \"blue\" for i in G.nodes()]\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, node_color=colors, node_size=800, font_color=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b447e9",
   "metadata": {},
   "source": [
    "## BBS Parameters\n",
    "\n",
    "- **`pb_dim`** *(int)*  \n",
    "  Number of decision variables.  \n",
    "\n",
    "- **`objective`** *(array or callable)*  \n",
    "  QUBO matrix or non-QUBO function.  \n",
    "\n",
    "- **`input_state`** *(list of int)*  \n",
    "  State that will be passed to the TBI (constant).  \n",
    "\n",
    "- **`tbi_params`** *(dict)*  \n",
    "  Parameters of the TBI used for sampling.  \n",
    "\n",
    "- **`n_samples`** *(int)*  \n",
    "  Number of samples.  \n",
    "\n",
    "- **`gradient_delta`** *(float)*  \n",
    "  Value used for gradient calculation.  \n",
    "\n",
    "- **`gradient_mode`** *(str)*  \n",
    "  Way of calculating the gradient.  \n",
    "\n",
    "- **`spsa_params`** *(dict)*  \n",
    "  Parameters for SPSA calculation.  \n",
    "\n",
    "- **`sampling_factor`** *(int)*  \n",
    "  Number of times quantum samples are passed through the classical flipping layer.  \n",
    "\n",
    "- **`entropy_penalty`** *(float)*  \n",
    "  Factor that incentivises convergence of the bit-flip model.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c4a174",
   "metadata": {},
   "source": [
    "## Playground\n",
    "Check out how other parameters influence the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8339c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
