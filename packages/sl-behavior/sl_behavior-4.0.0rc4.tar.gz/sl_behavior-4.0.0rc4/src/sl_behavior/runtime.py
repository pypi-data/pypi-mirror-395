"""This module provides the assets for extracting the acquisition-system and runtime task data from the .npz log
archives generated by data acquisition systems used in the Sun lab.
"""

from typing import TYPE_CHECKING
from pathlib import Path  # noqa: TC003

from numba import njit  # type: ignore[import-untyped]
import numpy as np
import polars as pl
from numpy.typing import NDArray  # noqa: TC002
from sl_shared_assets import (
    SessionData,
    SessionTypes,
    ProcessingTracker,
    MesoscopeExperimentTrial,
    MesoscopeExperimentConfiguration,
)
from ataraxis_base_utilities import LogLevel, console
from sl_forgery.shared_assets import ProcessingTrackers

if TYPE_CHECKING:
    from numpy.lib.npyio import NpzFile

# Message codes used by the Mesoscope-VR data acquisition system to identify the type of logged data.
_CUE_SEQUENCE_MIN_LENGTH: int = 500
"""The minimum length, in bytes, of a valid VR wall cue sequence message."""
_SYSTEM_STATE_CODE: int = 1
"""Message code for VR system state data."""
_EXPERIMENT_STATE_CODE: int = 2
"""Message code for experiment state data."""
_GUIDANCE_STATE_CODE: int = 3
"""Message code for lick guidance state data."""
_REWARD_VISIBILITY_CODE: int = 4
"""Message code for reward visibility state data."""
_CUE_SEQUENCE_BREAKPOINT_CODE: int = 5
"""Message code for cue sequence breakpoint distance data."""


def _prepare_motif_data(
    trial_motifs: list[NDArray[np.uint8]], trial_distances: list[float]
) -> tuple[NDArray[np.uint8], NDArray[np.int32], NDArray[np.int32], NDArray[np.int32], NDArray[np.float32]]:
    """Prepares the flattened motif data for faster cue sequence-to-trial decomposition (conversion).

    Args:
        trial_motifs: The trial motifs (wall cue sequences) to decompose.
        trial_distances: The trial motif distances, in centimeters.

    Returns:
        A tuple with five elements. The first element is the flattened array that stores all motifs. The second
        element is the array that stores the starting indices of each motif in the flattened array. The third
        element is the array that stores the length of each motif, in cues. The fourth element is the array
        that stores the original indices of motifs before sorting. The fifth element is the array of trial distances
        in centimeters.
    """
    # Sorts motifs by length (longest first)
    motif_data: list[tuple[int, NDArray[np.uint8], int]] = [
        (i, motif, len(motif)) for i, motif in enumerate(trial_motifs)
    ]
    motif_data.sort(key=lambda x: x[2], reverse=True)

    # Calculates total size needed to represent all motifs in an array.
    total_size: int = sum(len(motif) for motif in trial_motifs)
    num_motifs: int = len(trial_motifs)

    # Creates arrays with specified dtypes.
    motifs_flat: NDArray[np.uint8] = np.zeros(total_size, dtype=np.uint8)
    motif_starts: NDArray[np.int32] = np.zeros(num_motifs, dtype=np.int32)
    motif_lengths: NDArray[np.int32] = np.zeros(num_motifs, dtype=np.int32)
    motif_indices: NDArray[np.int32] = np.zeros(num_motifs, dtype=np.int32)

    # Fills the arrays
    current_pos: int = 0
    for i, (orig_idx, motif, length) in enumerate(motif_data):
        # Ensures motifs are stored as uint8
        motif_uint8 = motif.astype(np.uint8) if motif.dtype != np.uint8 else motif
        motifs_flat[current_pos : current_pos + length] = motif_uint8
        motif_starts[i] = current_pos
        motif_lengths[i] = length
        motif_indices[i] = orig_idx
        current_pos += length

    # Converts distances to float32 type
    distances_array: NDArray[np.float32] = np.array(trial_distances, dtype=np.float32)

    return motifs_flat, motif_starts, motif_lengths, motif_indices, distances_array


@njit(cache=True)
def _decompose_sequence_numba_flat(
    cue_sequence: NDArray[np.uint8],
    motifs_flat: NDArray[np.uint8],
    motif_starts: NDArray[np.int32],
    motif_lengths: NDArray[np.int32],
    motif_indices: NDArray[np.int32],
    max_trials: int,
) -> tuple[NDArray[np.int32], int]:
    """Decomposes a long sequence of Virtual Reality (VR) wall cues into individual trial motifs.

    Notes:
        This worker function is used to speed up decomposition via numba-acceleration.

    Args:
        cue_sequence: The full Virtual Reality environment cue sequence to decompose.
        motifs_flat: All trial type motifs supported by the acquired session, concatenated into a single 1D array.
        motif_starts: The starting index of each unique motif in the motifs_flat array.
        motif_lengths: The length of each unique motif in the motifs_flat array.
        motif_indices: Stores the original trial type motif indices before they are sorted to optimize the lookup
            speed.
        max_trials: The maximum number of trials that can make up the entire cue sequence.

    Returns:
        A tuple of two elements. The first element is the array of trials (trial-type indices) decoded from the
        cue sequence. The second element is the total number of trials extracted from the cue sequence.
    """
    # Prepares runtime trackers.
    trial_indices: NDArray[np.int32] = np.zeros(max_trials, dtype=np.int32)
    trial_count = 0
    sequence_pos = 0
    sequence_length = len(cue_sequence)
    num_motifs = len(motif_lengths)

    # Decomposes the sequence into trial motifs using greedy matching. Longer motifs are matched over shorter ones.
    while sequence_pos < sequence_length and trial_count < max_trials:
        motif_found = False

        for i in range(num_motifs):
            motif_length = motif_lengths[i]

            # Checks if the current position allows for a complete motif match.
            if sequence_pos + motif_length <= sequence_length:
                motif_start = motif_starts[i]

                # Checks if the motif matches the current sequence position.
                match = True
                for j in range(motif_length):
                    if cue_sequence[sequence_pos + j] != motifs_flat[motif_start + j]:
                        match = False
                        break

                # Records the match and advances to the next sequence position.
                if match:
                    trial_indices[trial_count] = motif_indices[i]
                    trial_count += 1
                    sequence_pos += motif_length
                    motif_found = True
                    break

        # Returns error code if no motif matches the current position.
        if not motif_found:
            return trial_indices, -1

    return trial_indices[:trial_count], trial_count


def _decompose_multiple_cue_sequences_into_trials(
    experiment_configuration: MesoscopeExperimentConfiguration,
    cue_sequences: list[NDArray[np.uint8]],
    distance_breakpoints: list[np.float64],
) -> tuple[NDArray[np.int32], NDArray[np.float64]]:
    """Decomposes multiple Virtual Reality environment cue sequences into a unified sequence of trials.

    Notes:
        This function handles cases where the original cue sequence was interrupted and a new sequence was generated
        during runtime. It uses distance breakpoints to stitch sequences together correctly.

    Args:
        experiment_configuration: The MesoscopeExperimentConfiguration instance for the processed session.
        cue_sequences: The Virtual Reality environment cue sequences in the order they were used during runtime.
        distance_breakpoints: The cumulative distances, in centimeters, at which each sequence ends. Should have
            the same number of elements as the number of cue sequences minus one.

    Returns:
        A tuple of two elements. The first element is an array of trial type indices stored in the order encountered
        during runtime. The second element is an array of cumulative distances at the end of each trial.

    Raises:
        ValueError: If the number of breakpoints does not match the number of sequences minus one.
        RuntimeError: If the function is unable to fully decompose any of the cue sequences.
    """
    # Validates inputs
    if len(cue_sequences) == 0:
        message = (
            "Unable to decompose input cue sequence(s) into trials. Expected at least one cue sequence as input, but "
            "received none."
        )
        console.error(message=message, error=ValueError)

    if len(cue_sequences) > 1 and len(distance_breakpoints) != len(cue_sequences) - 1:
        message = (
            f"Unable to decompose input cue sequence(s) into trials. Expected the number of distance breakpoints "
            f"to be ({len(cue_sequences) - 1} (number of sequences - 1), but encountered ({len(distance_breakpoints)})."
        )
        console.error(message=message, error=ValueError)

    # Extracts the list of trial structures supported by the processed experiment runtime
    trials: list[MesoscopeExperimentTrial] = list(experiment_configuration.trial_structures.values())

    # Extracts trial motif (cue sequences for each trial type) and their corresponding distances in cm
    trial_motifs: list[NDArray[np.uint8]] = [np.array(trial.cue_sequence, dtype=np.uint8) for trial in trials]
    trial_distances: list[float] = [float(trial.trial_length_cm) for trial in trials]

    # Prepares the flattened motif data
    motifs_flat, motif_starts, motif_lengths, motif_indices, distances_array = _prepare_motif_data(
        trial_motifs, trial_distances
    )

    # Estimates the maximum number of trials across all sequences
    min_motif_length = min(len(motif) for motif in trial_motifs)
    total_cue_length = sum(len(seq) for seq in cue_sequences)
    max_trials = total_cue_length // min_motif_length + 1

    # Processes each sequence and collects results
    all_trial_indices: list[int] = []
    all_trial_distances: list[float] = []
    cumulative_distance = 0.0

    for seq_idx, cue_sequence in enumerate(cue_sequences):
        # Decomposes the current sequence
        trial_indices_array, trial_count = _decompose_sequence_numba_flat(
            cue_sequence, motifs_flat, motif_starts, motif_lengths, motif_indices, max_trials
        )

        # Checks for decomposition errors
        if trial_count == -1:
            # Finds the position where decomposition failed
            sequence_pos = 0
            trial_indices_list = trial_indices_array[:max_trials].tolist()

            for idx in trial_indices_list:
                if idx == 0 and sequence_pos > 0:
                    break
                sequence_pos += len(trial_motifs[idx])

            remaining_sequence = cue_sequence[sequence_pos : sequence_pos + 20]
            message = (
                f"Unable to decompose VR wall cue sequence {seq_idx + 1} of {len(cue_sequences)} into a sequence of "
                f"trial distances. No trial motif matched at position {sequence_pos}. The next 20 cues: "
                f"{remaining_sequence.tolist()}"
            )
            console.error(message=message, error=RuntimeError)
            raise RuntimeError(message)

        # Extracts trial indices for this sequence
        sequence_trial_indices = trial_indices_array[:trial_count].tolist()

        for trial_idx in sequence_trial_indices:
            trial_distance = distances_array[trial_idx]
            new_cumulative_distance = cumulative_distance + trial_distance

            # If this is not the last sequence, checks if the loop has reached the breakpoint distance to
            # truncate the sequence
            if seq_idx < len(cue_sequences) - 1:
                breakpoint_distance = distance_breakpoints[seq_idx]

                # If the processed trial includes the breakpoint distance, truncates the sequence at the breakpoint
                if new_cumulative_distance > breakpoint_distance:
                    # This trial extends beyond the breakpoint. Adds a truncated version of this trial to the
                    # tracking list. The trial type is preserved, but later processing code is expected to catch the
                    # abrupt trial transition
                    truncated_distance = breakpoint_distance - cumulative_distance

                    # Once the truncated trial is found, modifies the trials' data to reflect the fact that the trial
                    # did not reach the final associated distance.
                    if truncated_distance > 0:
                        all_trial_indices.append(trial_idx)
                        all_trial_distances.append(breakpoint_distance)

                        # Notifies the user about the detected breakpoint
                        message = (
                            f"Sequence {seq_idx + 1}, Trial {trial_idx}: truncated. Full trial should have ended at "
                            f"{new_cumulative_distance:.1f} cm, but the sequence was interrupted at "
                            f"{breakpoint_distance:.1f} cm"
                        )
                        console.echo(message=message, level=LogLevel.WARNING)

                    # Stops processing trials (truncates the sequence) after breakpoint
                    cumulative_distance = breakpoint_distance
                    break
                # If the trial was traversed fully, adds its data to the stitched sequence
                all_trial_indices.append(trial_idx)
                all_trial_distances.append(new_cumulative_distance)
                cumulative_distance = new_cumulative_distance
            else:
                # For the last sequence, adds all available trials to the stitched sequence.
                all_trial_indices.append(trial_idx)
                all_trial_distances.append(new_cumulative_distance)
                cumulative_distance = new_cumulative_distance

    # Converts results to numpy arrays before returning them to the caller
    trial_type_sequence = np.array(all_trial_indices, dtype=np.int32)
    trial_distance_sequence = np.array(all_trial_distances, dtype=np.float64)

    return trial_type_sequence, trial_distance_sequence


def _decompose_cue_sequence_into_trials(
    experiment_configuration: MesoscopeExperimentConfiguration,
    cue_sequence: NDArray[np.uint8],
) -> tuple[NDArray[np.int32], NDArray[np.float64]]:
    """Decomposes a single Virtual Reality environment cue sequence into a sequence of trials.

    Notes:
        This is a convenience wrapper around the _decompose_multiple_cue_sequences_into_trials() function for
        runtimes that only used a single wall cue sequence. Since multiple sequences are only present in runtimes
        that encountered issues, this function is typically used during most data processing runtimes.

    Args:
        experiment_configuration: The MesoscopeExperimentConfiguration instance for the processed session.
        cue_sequence: The Virtual Reality environment cue sequence to decompose into trials.

    Returns:
        A tuple of two elements. The first element is an array of trial type indices stored in the order encountered
        during runtime. The second element is an array of cumulative distances at the end of each trial.

    Raises:
        RuntimeError: If the function is unable to fully decompose the cue sequence.
    """
    trial_indices, trial_distances = _decompose_multiple_cue_sequences_into_trials(
        experiment_configuration=experiment_configuration,
        cue_sequences=[cue_sequence],
        distance_breakpoints=[],
    )

    return trial_indices, trial_distances


def _process_trial_sequence(
    experiment_configuration: MesoscopeExperimentConfiguration,
    trial_types: NDArray[np.int32],
    trial_distances: NDArray[np.float64],
) -> tuple[NDArray[np.uint8], NDArray[np.float64], NDArray[np.float64], NDArray[np.float64], NDArray[np.float64]]:
    """Processes the sequence of trials experienced by the animal during runtime to extract trial metadata.

    Notes:
        This function processes the trial sequences generated by the _decompose_cue_sequence_into_trials() and
        _decompose_multiple_cue_sequences_into_trials() functions. The metadata extracted by this function is used
        to support trial-based data analysis in the sl-forgery library.

    Args:
        experiment_configuration: The MesoscopeExperimentConfiguration instance for the processed session.
        trial_types: The indices used to query the trial data for each trial experienced by the animal during runtime.
            The indices are used to query each trial's MesoscopeExperimentTrial instance from the configuration.
        trial_distances: The cumulative traveled distance, in centimeters, at which the animal fully completed each
            trial during runtime. The elements in this array use the same order as elements in the trial_types array.

    Returns:
        A tuple of five NumPy arrays. The first array stores the IDs of the Virtual Reality environment cues
        experienced by the animal during runtime. The second array stores the cumulative distance, in centimeters,
        traveled by the animal at the onset of each cue. The third array stores the cumulative distance traveled by
        the animal when it entered each trial's reward zone. The fourth array stores the cumulative distance traveled
        by the animal when it left each trial's reward zone. The fifth array stores the cumulative distance traveled
        by the animal at the start of each trial.
    """
    # Extracts the list of trial type objects from experiment configuration data.
    trials: list[MesoscopeExperimentTrial] = list(experiment_configuration.trial_structures.values())

    # Also extract the dictionary that maps wall cue IDs to the length of each cue, in centimeters, and a static
    # offset used to shift the animal's starting position on the VR track.
    cue_offset = experiment_configuration.cue_offset_cm
    cue_map = experiment_configuration.cue_map  # Maps cue_id -> length_cm

    # Pre-initializes output iterables as lists to efficiently support dynamic growth
    distances_list: list[np.float64] = []
    cues_list: list[np.uint8] = []
    reward_zone_starts_list: list[np.float64] = []
    reward_zone_ends_list: list[np.float64] = []
    trial_start_distances_list: list[np.float64] = []

    # Tracks the cumulative distance as the function essentially rebuilds the stitched cue sequence from trial
    # information
    cumulative_distance = np.float64(0)

    # Tracks whether to apply the cue position offset, which is done at the start and after each trial truncation
    # (sequence regeneration).
    apply_offset_to_next_cue = True

    # Loops over each trial in the sequence experienced by the animal and reconstructs the requested mappings
    previous_trial_end_distance = np.float64(0)
    index: int
    trial: np.int32
    for index, trial in enumerate(trial_types):
        # Uses the trial type to query the corresponding ExperimentTrial object for each trial. Note! This assumes that
        # the items stored in the experiment configuration class always follow the same order and that the order used
        # here and during sequence-to-trial decomposition is the same.
        trial_type = trials[trial]

        # Records the start distance for this trial
        trial_start_distances_list.append(previous_trial_end_distance)

        # Queries the actual distance traveled by the animal while running the processed trial
        actual_trial_distance = trial_distances[index] - previous_trial_end_distance

        # Queries the cue sequence for this trial
        trial_cue_sequence = trial_type.cue_sequence  # List of cue IDs

        # Tracks the distance within this trial to handle truncation
        distance_within_trial = np.float64(0)

        # Processes each cue in the trial
        for cue_idx, cue_id in enumerate(trial_cue_sequence):
            # Determines the length of each cue using the experiment cue_map
            cue_length = cue_map[int(cue_id)]

            # Applies offset if this is the first cue after a sequence start/restart
            if apply_offset_to_next_cue and cue_idx == 0:
                # This is the first cue of a new sequence (initial or after the sequence was regenerated). The animal
                # starts cue_offset cm into this cue
                effective_distance_to_next_cue = cue_length - cue_offset
                apply_offset_to_next_cue = False
            else:
                effective_distance_to_next_cue = cue_length

            # Checks if the trial is truncated (abruptly ended before completion). In this case, the actual trial
            # distance would be less than the end-distance of the currently processed cue
            if distance_within_trial + effective_distance_to_next_cue > actual_trial_distance:
                # In this case, stops processing the trial after this cue
                cues_list.append(np.uint8(cue_id))
                distances_list.append(cumulative_distance)  # Logs current cue onset distance as the end of previous cue

                # Updates the cumulative distance to the actual end of this trial. When the processing continues with
                # the next sequence, this would be used to accurately reflect the partial coverage of this abruptly
                # truncated cue.
                cumulative_distance = previous_trial_end_distance + actual_trial_distance

                # Since this trial was truncated, the next trial will start a new sequence, requiring the offset
                # to be applied again
                apply_offset_to_next_cue = True
                break

            # Otherwise, includes each cue and associated distance in the distance list.
            cues_list.append(np.uint8(cue_id))
            distances_list.append(cumulative_distance)

            # Updates distance trackers
            cumulative_distance += effective_distance_to_next_cue
            distance_within_trial += effective_distance_to_next_cue

        # Queries reward zone boundaries relative to trial start.
        reward_start_relative = trial_type.reward_zone_start_cm
        reward_end_relative = trial_type.reward_zone_end_cm

        # Converts to absolute positions given the global monotonically increasing traveled distance
        reward_start_absolute = previous_trial_end_distance + reward_start_relative
        reward_end_absolute = previous_trial_end_distance + reward_end_relative

        # Only adds reward zones if the start falls within the actual distance traveled
        if reward_start_absolute <= trial_distances[index]:
            reward_zone_starts_list.append(reward_start_absolute)

            # Clips the end if the trial was truncated before the animal reached the end of the reward zone
            if reward_end_absolute <= trial_distances[index]:
                reward_zone_ends_list.append(reward_end_absolute)
            else:
                # The reward zone was cut off by trial truncation, so 'ends' reward zone using the trial breakpoint
                # data
                # noinspection PyTypeChecker
                reward_zone_ends_list.append(trial_distances[index])

        # Updates previous trial end distance for next iteration
        previous_trial_end_distance = trial_distances[index]

    # Converts lists to numpy arrays and returns them to caller
    distances = np.array(distances_list, dtype=np.float64)
    cues = np.array(cues_list, dtype=np.uint8)
    reward_zone_starts = np.array(reward_zone_starts_list, dtype=np.float64)
    reward_zone_ends = np.array(reward_zone_ends_list, dtype=np.float64)
    trial_start_distances = np.array(trial_start_distances_list, dtype=np.float64)

    return cues, distances, reward_zone_starts, reward_zone_ends, trial_start_distances


def _extract_mesoscope_vr_data(
    log_path: Path, output_directory: Path, experiment_configuration: MesoscopeExperimentConfiguration | None = None
) -> None:
    """Extracts acquisition system and runtime (task) data from the Mesoscope-VR .npz log file.

    Notes:
        This function is specifically designed to process the data logged by the Mesoscope-VR data acquisition
        system. It does not work for any other Sun lab data acquisition system.

    Args:
        log_path: The path to the .npz archive containing the Mesoscope-VR acquisition system data to parse.
        output_directory: The path to the directory where to save the extracted data as uncompressed .feather files.
        experiment_configuration: The MesoscopeExperimentConfiguration instance for the processed session. Only
            required if the processed session is an experiment session.
    """
    # Loads the archive into RAM
    archive: NpzFile = np.load(file=log_path)

    # Pre-creates the variables used to store extracted data
    system_states = []
    system_timestamps = []
    experiment_states = []
    experiment_timestamps = []
    guidance_states = []
    guidance_timestamps = []
    reward_visibility_states = []
    reward_visibility_timestamps = []
    cue_sequences: list[NDArray[np.uint8]] = []
    cue_sequence_breakpoints: list[np.float64] = []

    # Locates the logging onset timestamp. The onset is used to convert the timestamps for logged data into absolute
    # UTC timestamps. Originally, all timestamps other than onset are stored as elapsed time in microseconds
    # relative to the onset timestamp.
    timestamp_offset = 0
    onset_us = np.uint64(0)
    timestamp: np.uint64
    for number, item in enumerate(archive.files):
        message: NDArray[np.uint8] = archive[item]  # Extracts message payload from the compressed .npy file

        # Recovers the uint64 timestamp value from each message. The timestamp occupies 8 bytes of each logged
        # message starting at index 1. If the timestamp value is 0, the message contains the onset timestamp value
        # stored as an 8-byte payload. Index 0 stores the source ID (uint8 value)
        if np.uint64(message[1:9].view(np.uint64)[0]) == 0:
            # Extracts the byte-serialized UTC timestamp stored as microseconds since epoch onset.
            onset_us = np.uint64(message[9:].view("<i8")[0].copy())

            # Breaks the loop once the onset is found. Generally, the onset is expected to be found very early into
            # the loop
            timestamp_offset = number  # Records the item number at which the onset value was found.
            break

    # Once the onset has been discovered, loops over all remaining messages and extracts data stored in these
    # messages.
    for item in archive.files[timestamp_offset + 1 :]:
        message = archive[item]

        # Extracts the elapsed microseconds since timestamp and uses it to calculate the global timestamp for the
        # message, in microseconds since epoch onset.
        elapsed_microseconds = np.uint64(message[1:9].view(np.uint64)[0].copy())
        timestamp = onset_us + elapsed_microseconds

        payload = message[9:]  # Extracts the payload from the message

        # If the message is longer than _CUE_SEQUENCE_MIN_LENGTH bytes, it is a sequence of wall cues.
        if len(payload) > _CUE_SEQUENCE_MIN_LENGTH and experiment_configuration is not None:
            # Since some runtimes now support generating multiple cue sequences, each sequence is cached into a storage
            # list to be processed later
            cue_sequences.append(payload.view(np.uint8).copy())  # Keeps the original numpy uint8 format

        # If the first element is _SYSTEM_STATE_CODE, the message communicates the VR state code.
        elif payload[0] == _SYSTEM_STATE_CODE:
            # Extracts the VR state code from the second byte of the message.
            system_states.append(np.uint8(payload[1]))
            system_timestamps.append(timestamp)

        # If the starting code is _EXPERIMENT_STATE_CODE, the message communicates the experiment state code.
        elif payload[0] == _EXPERIMENT_STATE_CODE:
            # Extracts the experiment state code from the second byte of the message.
            experiment_states.append(np.uint8(payload[1]))
            experiment_timestamps.append(timestamp)

        # If the starting code is _GUIDANCE_STATE_CODE, the message communicates the current lick guidance state
        elif payload[0] == _GUIDANCE_STATE_CODE:
            guidance_states.append(np.uint8(payload[1]))
            guidance_timestamps.append(timestamp)

        # If the starting code is _REWARD_VISIBILITY_CODE, the message communicates the current reward collision wall
        # visibility state
        elif payload[0] == _REWARD_VISIBILITY_CODE:
            reward_visibility_states.append(np.uint8(payload[1]))
            reward_visibility_timestamps.append(timestamp)

        # If the starting code is _CUE_SEQUENCE_BREAKPOINT_CODE, the message communicates the breakpoint distance for
        # the current cue sequence.
        elif payload[0] == _CUE_SEQUENCE_BREAKPOINT_CODE:
            # Skips the first byte (message code) and gets the next 8 bytes storing the distance as a float64
            distance_bytes = payload[1:9]
            traveled_distance = distance_bytes.view(dtype="<f8")[0]  # Converts back to float64
            # noinspection PyTypeChecker
            cue_sequence_breakpoints.append(traveled_distance)

        # Otherwise, the payload cannot be attributed to a known type and is, therefore, ignored

    # Closes the archive to free up memory
    archive.close()

    # Converts extracted data into Polar Feather files:
    # System states
    system_dataframe = pl.DataFrame(
        {
            "time_us": system_timestamps,
            "system_state": system_states,
        }
    )
    system_dataframe.write_ipc(output_directory.joinpath("system_state_data.feather"), compression="uncompressed")

    # Experiment states
    exp_dataframe = pl.DataFrame(
        {
            "time_us": experiment_timestamps,
            "experiment_state": experiment_states,
        }
    )
    exp_dataframe.write_ipc(output_directory.joinpath("experiment_state_data.feather"), compression="uncompressed")

    # Note, although lick guidance and reward visibility are parsed for all sessions, this data only exists for
    # experiment sessions. Therefore, only attempt to export the data if the processed session is an experiment session.
    # The same holds with respect to the VR track data parsed below.
    if experiment_configuration is not None:
        # Lick guidance states
        system_dataframe = pl.DataFrame(
            {
                "time_us": guidance_timestamps,
                "lick_guidance_state": guidance_states,
            }
        )
        system_dataframe.write_ipc(output_directory.joinpath("guidance_state_data.feather"), compression="uncompressed")

        # Reward visibility states
        system_dataframe = pl.DataFrame(
            {
                "time_us": reward_visibility_timestamps,
                "reward_visibility_state": reward_visibility_states,
            }
        )
        system_dataframe.write_ipc(
            output_directory.joinpath("reward_visibility_state_data.feather"), compression="uncompressed"
        )

        # Cue sequence for Mesoscope-VR system

        # Most sessions should only have a single cue sequence. However, if necessary, the runtime also supports
        # stitching multiple abruptly terminated sequences to recover useful information from sessions that encountered
        # issues during runtime.
        if len(cue_sequences) > 1:
            trial_types, trial_distances = _decompose_multiple_cue_sequences_into_trials(
                experiment_configuration=experiment_configuration,
                cue_sequences=cue_sequences,
                distance_breakpoints=cue_sequence_breakpoints,
            )
        else:
            trial_types, trial_distances = _decompose_cue_sequence_into_trials(
                experiment_configuration=experiment_configuration, cue_sequence=cue_sequences.pop()
            )

        # Uses the computed sequence of trials and the information stored inside the ExperimentConfiguration class to
        # determine which VR cues were seen by the animal as it progressed through the experiment trials. Also computes
        # the traveled distance boundaries for reward zones.
        cue_sequence, distance_sequence, reward_start, reward_stop, trial_start = _process_trial_sequence(
            experiment_configuration, trial_types, trial_distances
        )

        # Exports the cue-distance mapping as a Polars dataframe
        cue_dataframe = pl.DataFrame(
            {
                "vr_cue": cue_sequence,
                "traveled_distance_cm": distance_sequence,
            }
        )
        cue_dataframe.write_ipc(output_directory.joinpath("vr_cue_data.feather"), compression="uncompressed")

        # Exports reward_zone-distance mapping as a Polars dataframe
        reward_dataframe = pl.DataFrame(
            {
                "reward_zone_start_cm": reward_start,
                "reward_zone_end_cm": reward_stop,
            }
        )
        reward_dataframe.write_ipc(output_directory.joinpath("vr_reward_zone_data.feather"), compression="uncompressed")

        # Exports trial-distance mapping as a Polars dataframe
        trial_dataframe = pl.DataFrame(
            {
                "trial_type_index": trial_types,
                "traveled_distance_cm": trial_start,
            }
        )
        trial_dataframe.write_ipc(output_directory.joinpath("trial_data.feather"), compression="uncompressed")


def process_runtime_data(
    session_path: Path,
    job_id: str,
) -> None:
    """Extracts acquisition system and runtime (task) data from the data acquisition system .npz log file.

    Notes:
        This function is used to process the log archives generated by the Mesoscope-VR data acquisition system
        used in the Sun lab. It assumes that the data was logged using the assets from the sl-experiment library
        and that the acquisition system log file uses the source ID '1'.

    Args:
        session_path: The path to the session directory for which to process the acquisition system log file.
        job_id: The unique hexadecimal identifier for this processing job.
    """
    # Loads the target session's data hierarchy into memory
    session = SessionData.load(session_path=session_path)

    # Resolves the path to the processed log file. Statically assumes that all acquisition systems store their data
    # under the log file with source ID '1'.
    log_path = session.raw_data.behavior_data_path.joinpath("1_log.npz")

    # Initializes the processing tracker for this pipeline.
    tracker = ProcessingTracker(
        file_path=session.tracking_data.tracking_data_path.joinpath(ProcessingTrackers.BEHAVIOR)
    )

    # Marks the job as running.
    tracker.start_job(job_id=job_id)

    try:
        # If the session is an experiment, loads the experiment configuration data to memory
        experiment_configuration: MesoscopeExperimentConfiguration | None = None
        if session.session_type == SessionTypes.MESOSCOPE_EXPERIMENT:
            experiment_configuration = MesoscopeExperimentConfiguration.from_yaml(
                session.raw_data.experiment_configuration_path
            )

        console.echo(message="Extracting runtime data from the '1' log file...")

        # Extracts the runtime data
        _extract_mesoscope_vr_data(
            log_path=log_path,
            experiment_configuration=experiment_configuration,
            output_directory=session.processed_data.behavior_data_path,
        )

        # Marks the job as successfully completed.
        tracker.complete_job(job_id=job_id)
        console.echo(message="Runtime data processing: Complete.", level=LogLevel.SUCCESS)

    # If the runtime encounters an error, marks the job as failed.
    except Exception:
        tracker.fail_job(job_id=job_id)
        raise
