[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "llm-caching"
version = "0.1.1"
description = "Cache LLM API calls to speed up development and prevent rate limits"
readme = "README.md"
requires-python = ">=3.9"
license = {text = "MIT"}
authors = [
    {name = "Frederic Legrand"}
]
keywords = ["llm", "cache", "caching", "openai", "anthropic", "development"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
]

dependencies = [
    "fastapi>=0.104.0",
    "uvicorn>=0.24.0",
    "httpx>=0.25.0",
    "redis>=5.0.0",
    "python-dotenv>=1.0.0",
    "pydantic>=2.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "ruff>=0.1.0",
]

[project.scripts]
llm-caching-proxy = "llm_cache.proxy.server:main"

[tool.hatch.build.targets.wheel]
packages = ["llm_cache"]

[tool.black]
line-length = 88
target-version = ['py313']

[tool.isort]
profile = "black"
line_length = 88

[tool.ruff]
line-length = 88
target-version = "py38"

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
asyncio_mode = "auto"

[dependency-groups]
dev = [
    "httpx>=0.28.1",
    "pytest>=8.3.5",
    "pytest-asyncio>=0.24.0",
]
