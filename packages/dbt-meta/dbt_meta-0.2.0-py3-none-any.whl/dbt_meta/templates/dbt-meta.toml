# ==============================================================================
# dbt-meta Configuration File (TOML format)
# ==============================================================================
# This is the configuration template for dbt-meta CLI tool.
# Copy this file to one of the following locations:
#   1. ~/.config/dbt-meta/config.toml  (recommended, XDG standard)
#   2. ~/.dbt-meta.toml                (alternative, user home)
#   3. ./.dbt-meta.toml                (project-local override)
#
# Priority order: CLI flags > Config file > Built-in defaults
# All paths support tilde (~) expansion for home directory
#
# Generate this file: meta config init
# View merged config:  meta config show
# Validate config:     meta config validate
# ==============================================================================


# ==============================================================================
# MANIFEST
# ==============================================================================
# Locations of dbt manifest.json files
#
# Manifest files contain metadata about all dbt models, including:
# - Model names, schemas, tables
# - Column definitions (if documented in schema.yml)
# - Dependencies (refs, sources, macros)
# - Model configuration (materialization, partitioning, etc.)
#
# Production manifest: Stable reference for production data
# Dev manifest: Built locally with 'defer run' for testing changes
# ==============================================================================

[manifest]

# Path to production manifest.json
# Default: ~/dbt-state/manifest.json
#
# This manifest represents the stable production state of your dbt project.
# Typically synced from remote storage (GCS, S3) or CI/CD artifacts.
# Used by all commands without --dev flag.
#
# How to populate:
#   - Auto-sync: Run 'meta refresh' (calls sync-artifacts.sh)
#   - Manual: Copy from production build location
#
prod_path = "~/dbt-state/manifest.json"

# Path to development manifest.json
# Default: ./target/manifest.json
#
# This manifest is generated locally by 'dbt parse' or 'dbt compile'.
# Contains your local changes before deploying to production.
# Used by all commands with --dev flag.
#
# How to populate:
#   - Quick: Run 'meta refresh --dev' (runs dbt parse)
#   - Full: Run 'dbt compile' or 'dbt run' in your project
#
dev_path = "./target/manifest.json"


# ==============================================================================
# CATALOG
# ==============================================================================
# Locations of dbt catalog.json files (optional)
#
# Catalog files contain database metadata from INFORMATION_SCHEMA:
# - Column names and data types (from actual database)
# - Column statistics (if available)
# - Table metadata
#
# Used as fallback when manifest.json lacks column information.
# Generated by 'dbt docs generate' command.
# ==============================================================================

[catalog]

# Path to production catalog.json
# Default: ~/dbt-state/catalog.json
#
# Synced alongside production manifest.
# Provides column types when not documented in schema.yml
#
prod_path = "~/dbt-state/catalog.json"

# Path to development catalog.json
# Default: ./target/catalog.json
#
# Generated locally by 'dbt docs generate'
# Useful for exploring undocumented column types
#
dev_path = "./target/catalog.json"


# ==============================================================================
# FALLBACK
# ==============================================================================
# Control 3-level fallback strategy for missing metadata
#
# When model or column information is not found in manifest.json:
# 1. Try dev manifest (if dev_enabled=true)
# 2. Try catalog.json (if catalog_enabled=true)
# 3. Try BigQuery INFORMATION_SCHEMA (if bigquery_enabled=true)
#
# Each level provides progressively broader coverage but slower performance.
# ==============================================================================

[fallback]

# Enable dev manifest fallback
# Default: true
#
# When true: If model not in production, check dev manifest
# Use case: New models only in local development
# Performance: Fast (manifest already loaded)
#
dev_enabled = true

# Enable catalog.json fallback
# Default: true
#
# When true: Use catalog for column types when not in manifest
# Use case: 64% of models lack column metadata in manifest
# Performance: Fast (file read + JSON parse)
# Requires: catalog.json must exist and be up-to-date
#
catalog_enabled = true

# Enable BigQuery metadata fallback
# Default: true
#
# When true: Query INFORMATION_SCHEMA when all else fails
# Use case: External tables, manual tables, missing catalog
# Performance: Slow (network call to BigQuery)
# Requires: BigQuery credentials, table must exist
#
bigquery_enabled = true


# ==============================================================================
# DEV ENVIRONMENT
# ==============================================================================
# Configuration for development schema/dataset naming
#
# Dev schema: Where 'defer run' builds your modified models
# Default pattern: personal_{username}
#
# Override this when:
# - Multiple users share a dev project
# - Company naming standards require specific format
# - Testing in dedicated dev dataset
# ==============================================================================

[dev]

# Dev schema/dataset name
# Default: personal_{username} (from system USER variable)
#
# Examples:
#   schema = "personal_john_doe"      # Explicit name
#   schema = "dev_analytics"          # Shared dev dataset
#   schema = "scratch"                # Testing dataset
#
# When not set: Automatically generated as personal_{USER}
#
# schema = "personal_myusername"

# Username for default schema generation
# Default: System $USER environment variable
#
# Only used when 'schema' is not explicitly set.
# Useful when system username differs from dbt username.
#
# user = "myusername"


# ==============================================================================
# PRODUCTION
# ==============================================================================
# Control how production table and schema names are resolved
#
# dbt models can have different names in different contexts:
# - Model name: File name (customers.sql → customers)
# - Alias: config.alias in model SQL or dbt_project.yml
# - Schema: config.schema or folder-based
#
# These settings determine which name is used when querying BigQuery.
# ==============================================================================

[production]

# Table name resolution strategy
# Default: "alias_or_name"
#
# Options:
#   "alias_or_name" - Use config.alias if set, else model name (RECOMMENDED)
#   "name"          - Always use model name (ignore alias)
#   "alias"         - Always use config.alias (error if not set)
#
# Example:
#   Model: dim_customers.sql with config.alias = "customers"
#   - alias_or_name → "customers" (uses alias)
#   - name          → "dim_customers" (ignores alias)
#   - alias         → "customers" (requires alias)
#
table_name_strategy = "alias_or_name"

# Schema source strategy
# Default: "config_or_model"
#
# Options:
#   "config_or_model" - Use config.schema if set, else model schema (RECOMMENDED)
#   "model"           - Always use model schema (ignore config)
#   "config"          - Always use config.schema (error if not set)
#
# Example:
#   Model in folder: models/analytics/customers.sql
#   With config: schema = "core"
#   - config_or_model → "core" (uses config)
#   - model           → "analytics" (ignores config)
#   - config          → "core" (requires config)
#
schema_source = "config_or_model"


# ==============================================================================
# BIGQUERY
# ==============================================================================
# Configuration for BigQuery metadata fallback
#
# When manifest and catalog don't have column information,
# dbt-meta can query BigQuery INFORMATION_SCHEMA directly.
#
# This section controls BigQuery client behavior and performance.
# ==============================================================================

[bigquery]

# BigQuery project ID for metadata queries
# Default: Auto-detect from gcloud CLI or GOOGLE_CLOUD_PROJECT env var
#
# Override when:
# - Multiple GCP projects in use
# - Need explicit project for billing
# - Auto-detection fails
#
# Examples:
#   project_id = "my-analytics-project"
#   project_id = "production-dwh"
#
# project_id = ""

# Timeout for BigQuery queries (seconds)
# Default: 10
#
# How long to wait for INFORMATION_SCHEMA queries before failing.
# Increase for:
# - Slow network connections
# - Large datasets with complex metadata
# - Shared BigQuery quota limits
#
timeout = 10

# Number of retry attempts for failed queries
# Default: 3
#
# Retries help with:
# - Transient network errors
# - BigQuery quota exhaustion (with exponential backoff)
# - Intermittent connectivity issues
#
retries = 3

# Location/region for BigQuery queries
# Default: "US"
#
# Must match your dataset location for queries to work.
# Common values: "US", "EU", "us-central1", "europe-west1"
#
# location = "US"


# ==============================================================================
# DATABASE (Future Enhancement)
# ==============================================================================
# Credentials for alternative data warehouses
#
# NOTE: Not yet implemented - planned for future releases
# Will enable direct metadata queries to PostgreSQL, Redshift, Snowflake, etc.
#
# When implemented, this will allow dbt-meta to work with non-BigQuery projects.
# ==============================================================================

[database]

# Database type
# Future options: postgresql, redshift, snowflake, databricks
# type = ""

# Connection parameters
# host = ""
# port = 5432
# name = ""  # Database name
# username = ""
# password = ""  # Consider using keyring or env var for security

# Connection pool settings
# min_connections = 1
# max_connections = 5
# timeout = 30


# ==============================================================================
# OUTPUT
# ==============================================================================
# Control output formatting and display options
#
# These settings affect how dbt-meta displays results to the terminal.
# Useful for:
# - Consistent formatting in scripts
# - Accessibility (color blindness, screen readers)
# - CI/CD environments (plain text logs)
# ==============================================================================

[output]

# Default output format
# Default: "text"
#
# Options:
#   "text"  - Human-readable formatted text (default for terminal)
#   "json"  - Machine-readable JSON (can be overridden with -j flag)
#   "table" - Rich formatted tables (experimental)
#
# Note: CLI -j/--json flag always overrides this setting
#
default_format = "text"

# Pretty-print JSON output
# Default: true
#
# When true: JSON with indentation and newlines (readable)
# When false: Compact JSON on single line (smaller, faster)
#
# Applies to:
# - Commands with -j/--json flag
# - default_format = "json"
#
json_pretty = true

# Enable color output
# Default: "auto"
#
# Options:
#   "auto"   - Enable colors if terminal supports it (RECOMMENDED)
#   "always" - Always use colors (for color-capable log viewers)
#   "never"  - Never use colors (plain text only)
#
# Use "never" for:
# - CI/CD logs without ANSI support
# - Piping to files or other commands
# - Accessibility requirements
#
color = "auto"

# Show metadata source in output
# Default: true
#
# When true: Display where data came from (manifest, catalog, BigQuery)
# When false: Only show the data, no source information
#
# Useful for debugging fallback behavior and performance issues.
#
show_source = true


# ==============================================================================
# DEFER (Future Enhancement)
# ==============================================================================
# Configuration for defer workflow automation
#
# NOTE: Partially implemented - full automation planned for future releases
# Currently 'meta refresh' manually syncs production artifacts.
#
# When fully implemented, this will:
# - Auto-sync manifest before defer run
# - Validate manifest freshness
# - Handle multi-target workflows
# ==============================================================================

[defer]

# Auto-sync production manifest before defer run
# Default: true
#
# When true: Check manifest age and update if stale
# When false: Use existing manifest (faster, may be outdated)
#
# auto_sync = true

# Maximum manifest age in seconds before re-syncing
# Default: 3600 (1 hour)
#
# Manifest older than this triggers auto-sync.
# Common values:
#   3600   = 1 hour (default, good for active development)
#   1800   = 30 minutes (frequent deploys)
#   86400  = 24 hours (stable production)
#
# sync_threshold = 3600

# Command to sync production artifacts
# Default: Calls sync-artifacts.sh script
#
# Custom examples:
#   sync_command = "gsutil cp gs://bucket/artifacts/* ~/dbt-state/"
#   sync_command = "aws s3 sync s3://bucket/artifacts/ ~/dbt-state/"
#   sync_command = "rsync -avz remote:/path/ ~/dbt-state/"
#
# sync_command = ""

# Target name for defer builds
# Default: "dev" (from dbt profiles.yml)
#
# Override when:
# - Using non-standard target names
# - Multiple dev environments (dev, qa, staging)
#
# target = "dev"
