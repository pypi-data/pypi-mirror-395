"""
@phlo_quality decorator for declarative quality checks.

This decorator reduces quality check boilerplate from 30-40 lines to 5-10 lines
by automatically generating Dagster asset checks from declarative quality check definitions.
"""

from __future__ import annotations

from functools import wraps
from typing import Any, Callable, List, Optional

from dagster import AssetCheckResult, AssetCheckSeverity, AssetKey, MetadataValue, asset_check

from phlo.quality.checks import QualityCheck, QualityCheckResult

_QUALITY_CHECKS: list[Any] = []


def phlo_quality(
    table: str,
    checks: List[QualityCheck],
    asset_key: Optional[AssetKey] = None,
    group: Optional[str] = None,
    blocking: bool = True,
    warn_threshold: float = 0.0,
    description: Optional[str] = None,
    query: Optional[str] = None,
    backend: str = "trino",
) -> Callable:
    """
    Decorator that generates Dagster asset checks from quality check definitions.

    This decorator reduces quality check boilerplate by 70%, transforming verbose
    asset check implementations into concise declarative definitions.

    Args:
        table: Fully qualified table name (e.g., "bronze.weather_observations")
        checks: List of quality checks to execute
        asset_key: Optional Dagster AssetKey (derived from table if not provided)
        group: Optional asset group
        blocking: Whether check failures block downstream assets (default: True)
        warn_threshold: Fraction of checks that can fail before marking as WARN (0.0 = fail immediately)
        description: Optional description (auto-generated if not provided)
        query: Optional custom SQL query (defaults to SELECT * FROM {table})
        backend: Backend to use ("trino" or "duckdb", default: "trino")

    Returns:
        Decorated function that executes quality checks

    Example:
        ```python
        from phlo.quality import phlo_quality, NullCheck, RangeCheck

        @phlo_quality(
            table="bronze.weather_observations",
            checks=[
                NullCheck(columns=["station_id", "temperature"]),
                RangeCheck(column="temperature", min_value=-50, max_value=60),
            ],
            group="weather",
        )
        def weather_quality_check():
            '''Quality checks for weather observations.'''
            pass
        ```

        This generates a Dagster asset check that:
        - Queries the table via Trino/DuckDB
        - Executes all quality checks
        - Returns AssetCheckResult with rich metadata
        - Reduces code from ~40 lines to ~8 lines (80% reduction)
    """

    def decorator(func: Callable) -> Callable:
        # Derive asset key from table name if not provided
        nonlocal asset_key, description

        if asset_key is None:
            # Extract table name from fully qualified name
            # e.g., "bronze.weather_observations" -> "weather_observations"
            table_parts = table.split(".")
            table_name = table_parts[-1]
            asset_key = AssetKey([table_name])

        # Auto-generate description if not provided
        if description is None:
            check_names = [check.name for check in checks]
            description = f"Quality checks for {table}: {', '.join(check_names[:3])}" + (
                "..." if len(check_names) > 3 else ""
            )

        # Build the SQL query
        default_query = f"SELECT * FROM {table}"
        sql_query = query or default_query

        # Create the Dagster asset check function
        @asset_check(
            name=func.__name__,
            asset=asset_key,
            blocking=blocking,
            description=description,
        )
        @wraps(func)
        def quality_check_wrapper(context, **resources) -> AssetCheckResult:
            """
            Execute all quality checks on the table.

            This function is auto-generated by @phlo_quality decorator.
            """
            # Get partition key if available
            partition_key = getattr(context, "partition_key", None)
            if partition_key is None:
                partition_key = getattr(context, "asset_partition_key", None)

            # Build query with partition filter if needed
            final_query = sql_query
            if partition_key and "WHERE" not in sql_query.upper():
                # Auto-add partition filter for common timestamp columns
                # This is a heuristic; users can override with custom query
                final_query = f"{sql_query}\nWHERE DATE(timestamp) = DATE '{partition_key}'"
                context.log.info(f"Validating partition: {partition_key}")

            # Load data based on backend
            try:
                if backend == "trino":
                    df = _load_data_trino(context, final_query, resources)
                elif backend == "duckdb":
                    df = _load_data_duckdb(context, final_query, resources)
                else:
                    raise ValueError(f"Unknown backend: {backend}")

            except Exception as exc:
                context.log.error(f"Failed to load data: {exc}")
                return AssetCheckResult(
                    passed=False,
                    metadata={
                        "reason": MetadataValue.text("query_failed"),
                        "error": MetadataValue.text(str(exc)),
                        "query": MetadataValue.text(final_query),
                    },
                )

            # Handle empty data
            if df.empty:
                context.log.warning("No rows returned; marking check as skipped.")
                return AssetCheckResult(
                    passed=True,
                    metadata={
                        "rows_validated": MetadataValue.int(0),
                        "note": MetadataValue.text("No data available for validation"),
                    },
                )

            # Execute all quality checks
            context.log.info(f"Executing {len(checks)} quality checks on {len(df)} rows...")

            check_results: List[QualityCheckResult] = []
            all_passed = True

            for check in checks:
                try:
                    result = check.execute(df, context)
                    check_results.append(result)

                    if not result.passed:
                        all_passed = False
                        context.log.warning(
                            f"Quality check '{check.name}' failed: {result.failure_message}"
                        )
                    else:
                        context.log.info(f"Quality check '{check.name}' passed")

                except Exception as exc:
                    context.log.exception(f"Error executing quality check '{check.name}': {exc}")
                    check_results.append(
                        QualityCheckResult(
                            passed=False,
                            metric_name=check.name,
                            metric_value=None,
                            metadata={"error": str(exc)},
                            failure_message=f"Check execution failed: {exc}",
                        )
                    )
                    all_passed = False

            # Build metadata for Dagster UI
            metadata = _build_metadata(df, check_results)

            # Calculate severity based on warn_threshold
            passed_count = sum(1 for r in check_results if r.passed)
            failed_count = sum(1 for r in check_results if not r.passed)
            failure_fraction = failed_count / len(check_results) if check_results else 0.0

            summary = f"{passed_count}/{len(check_results)} quality checks passed"

            if failed_count > 0:
                failed_checks = [
                    f"{r.metric_name}: {r.failure_message}" for r in check_results if not r.passed
                ]
                metadata["failures"] = MetadataValue.md(
                    "## Failed Checks\n\n" + "\n".join(f"- {f}" for f in failed_checks)
                )

            metadata["summary"] = MetadataValue.text(summary)

            # Determine if this should be a warning or failure
            severity = AssetCheckSeverity.SUCCESS if all_passed else AssetCheckSeverity.FAILURE

            # If warn_threshold is set and we're below it, downgrade to warning
            if failure_fraction > 0 and failure_fraction <= warn_threshold:
                severity = AssetCheckSeverity.WARN
                context.log.warning(
                    f"Quality check warning: {failure_fraction:.1%} of checks failed "
                    f"(within warn threshold of {warn_threshold:.1%})"
                )

            return AssetCheckResult(
                passed=all_passed or (failure_fraction <= warn_threshold),
                severity=severity if all_passed else None,
                metadata=metadata,
            )

        _QUALITY_CHECKS.append(quality_check_wrapper)
        return quality_check_wrapper

    return decorator


def get_quality_checks() -> list[Any]:
    """
    Get all asset checks registered with @phlo_quality decorator.

    Returns:
        List of Dagster asset check definitions
    """
    return _QUALITY_CHECKS.copy()


def _load_data_trino(context: Any, query: str, resources: dict) -> Any:
    """Load data from Trino."""
    import pandas as pd

    # Get Trino resource
    trino = resources.get("trino")
    if trino is None:
        raise ValueError("Trino resource not found in context")

    # Execute query
    with trino.cursor() as cursor:
        cursor.execute(query)
        rows = cursor.fetchall()

        if not cursor.description:
            raise ValueError("Trino did not return column metadata")

        columns = [desc[0] for desc in cursor.description]

    # Convert to DataFrame
    df = pd.DataFrame(rows, columns=columns)

    context.log.info(f"Loaded {len(df)} rows from Trino")

    return df


def _load_data_duckdb(context: Any, query: str, resources: dict) -> Any:
    """Load data from DuckDB."""

    # Get DuckDB connection
    duckdb_conn = resources.get("duckdb")
    if duckdb_conn is None:
        raise ValueError("DuckDB resource not found in context")

    # Execute query
    df = duckdb_conn.execute(query).fetchdf()

    context.log.info(f"Loaded {len(df)} rows from DuckDB")

    return df


def _build_metadata(df: Any, check_results: List[QualityCheckResult]) -> dict:
    """Build metadata dictionary for Dagster UI."""
    metadata = {
        "rows_validated": MetadataValue.int(len(df)),
        "columns_validated": MetadataValue.int(len(df.columns)),
        "checks_executed": MetadataValue.int(len(check_results)),
        "checks_passed": MetadataValue.int(sum(1 for r in check_results if r.passed)),
        "checks_failed": MetadataValue.int(sum(1 for r in check_results if not r.passed)),
    }

    # Add individual check results
    for result in check_results:
        # Add metric value
        if result.metric_value is not None:
            if isinstance(result.metric_value, dict):
                metadata[f"{result.metric_name}_value"] = MetadataValue.json(result.metric_value)
            else:
                metadata[f"{result.metric_name}_value"] = MetadataValue.text(
                    str(result.metric_value)
                )

        # Add check metadata
        if result.metadata:
            for key, value in result.metadata.items():
                metadata_key = f"{result.metric_name}_{key}"
                if isinstance(value, (dict, list)):
                    metadata[metadata_key] = MetadataValue.json(value)
                elif isinstance(value, (int, float)):
                    metadata[metadata_key] = MetadataValue.float(float(value))
                else:
                    metadata[metadata_key] = MetadataValue.text(str(value))

    # Build quality summary table
    summary_rows = []
    for result in check_results:
        summary_rows.append(
            f"| {result.metric_name} | {'✅ Pass' if result.passed else '❌ Fail'} | "
            f"{result.metric_value} | {result.failure_message or '-'} |"
        )

    if summary_rows:
        summary_table = (
            "## Quality Check Results\n\n"
            "| Check | Status | Value | Message |\n"
            "|-------|--------|-------|----------|\n" + "\n".join(summary_rows)
        )
        metadata["quality_summary"] = MetadataValue.md(summary_table)

    return metadata
