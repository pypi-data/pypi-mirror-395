{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "445ed882",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from hamilton import driver\n",
    "\n",
    "from world_machine_experiments import shared\n",
    "from world_machine_experiments.toy1d import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56afc9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_args = {\"sequence_length\": 1000,\n",
    "            \"n_sequence\": 10000,\n",
    "            \"context_size\": 200,\n",
    "            \"seed\":[42,0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79cffbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = driver.Builder().with_modules(base, shared).build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381c5547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrapped get_dimension_item\n"
     ]
    }
   ],
   "source": [
    "outputs = d.execute([\"toy1d_datasets\"], inputs=base_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a18ebed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<world_machine_experiments.toy1d.base.dataset.Toy1dDataset at 0x14b19691f10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"toy1d_datasets\"][\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "316ffd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Toy1dDataset.get_dimension_item of <world_machine_experiments.toy1d.base.dataset.Toy1dDataset object at 0x0000014B19691F10>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"toy1d_datasets\"][\"train\"].get_dimension_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b61af4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = outputs[\"toy1d_datasets\"][\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69ac9ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQUI\n",
      "AQUI\n",
      "AQUI\n",
      "AQUI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        index: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        inputs: TensorDict(\n",
       "            fields={\n",
       "                measurement: Tensor(shape=torch.Size([200, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                state_control: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                state_decoded: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([200]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        targets: TensorDict(\n",
       "            fields={\n",
       "                measurement: Tensor(shape=torch.Size([200, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                state_control: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                state_decoded: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([200]),\n",
       "            device=None,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79787378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Toy1dDataset.get_dimension_item of <world_machine_experiments.toy1d.base.dataset.Toy1dDataset object at 0x0000014B19691F10>>\n",
      "<class 'method'>\n",
      "<class 'method'>\n",
      "<function Toy1dDataset.get_dimension_item at 0x0000014B0C416020>\n"
     ]
    }
   ],
   "source": [
    "ds = outputs[\"toy1d_datasets\"][\"train\"]\n",
    "print(ds.get_dimension_item)\n",
    "print(type(ds.get_dimension_item))\n",
    "print(ds.get_dimension_item.__class__)\n",
    "print(ds.get_dimension_item.__func__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef18ed69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function Toy1dDataset.get_dimension_item at 0x0000014B0C416020>\n",
      "world_machine_experiments.toy1d.base.dataset\n",
      "Toy1dDataset.get_dimension_item\n"
     ]
    }
   ],
   "source": [
    "from world_machine_experiments.toy1d.base.dataset import Toy1dDataset\n",
    "\n",
    "print(Toy1dDataset.get_dimension_item)\n",
    "print(Toy1dDataset.get_dimension_item.__module__)\n",
    "print(Toy1dDataset.get_dimension_item.__qualname__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f17d6a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def get_dimension_item(self, dimension: str, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
      "        item_index = index // self._items_in_sequence\n",
      "        item_seq_index = index % self._items_in_sequence\n",
      "\n",
      "        start = item_seq_index*self._context_size\n",
      "        end = start+self._context_size\n",
      "\n",
      "        item = []\n",
      "\n",
      "        for i in range(2):\n",
      "            item.append(torch.Tensor(\n",
      "                self._data[dimension][item_index, start+i:end+i]))\n",
      "\n",
      "            if self._return_dimensions is not None and dimension == \"state_decoded\":\n",
      "                item[i] = item[i][:, self._return_dimensions]\n",
      "\n",
      "            data_raw = self._data[dimension][item_index,\n",
      "                                             start:end+1][:, 0]\n",
      "            s_max = data_raw.max()\n",
      "            s_min = data_raw.min()\n",
      "\n",
      "            item[i] = (item[i]-s_min)/(s_max-s_min)\n",
      "            item[i] = (2*item[i])-1\n",
      "\n",
      "            if dimension == \"measurement\":\n",
      "                item[i] = np.tanh(item[i])\n",
      "\n",
      "        return item\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "print(inspect.getsource(outputs[\"toy1d_datasets\"][\"train\"].get_dimension_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87089e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e50e12b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'world_machine_experiments.toy1d.base.dataset_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mworld_machine_experiments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtoy1d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_class\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Toy1dDataset\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'world_machine_experiments.toy1d.base.dataset_class'"
     ]
    }
   ],
   "source": [
    "from world_machine_experiments.toy1d.base.dataset_class import Toy1dDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cadbffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"toy1d_datasets\"][\"train\"].__class__ is Toy1dDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873e47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from world_machine_experiments.toy1d.base import dataset_class\n",
    "from world_machine_experiments.toy1d.base.dataset_class import Toy1dDataset\n",
    "\n",
    "\n",
    "print(dataset_class.Toy1dDataset is Toy1dDataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6546fc9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function Toy1dDataset.get_dimension_item at 0x00000221F128AB60>: it's not the same object as world_machine_experiments.toy1d.base.dataset_class.Toy1dDataset.get_dimension_item",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoy1d_datasets.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoy1d_datasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function Toy1dDataset.get_dimension_item at 0x00000221F128AB60>: it's not the same object as world_machine_experiments.toy1d.base.dataset_class.Toy1dDataset.get_dimension_item"
     ]
    }
   ],
   "source": [
    "with open(\"toy1d_datasets.bin\", \"wb\") as file:\n",
    "    pickle.dump(outputs[\"toy1d_datasets\"], file, protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6977b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a13138",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"toy1d_export\\\\toy1d_datasets.pkl\", \"rb\") as file:\n",
    "    datasets = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a49b068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        index: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        inputs: TensorDict(\n",
       "            fields={\n",
       "                measurement: Tensor(shape=torch.Size([200, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                state_control: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                state_decoded: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([200]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        targets: TensorDict(\n",
       "            fields={\n",
       "                measurement: Tensor(shape=torch.Size([200, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                state_control: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                state_decoded: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([200]),\n",
       "            device=None,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6689b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
