{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da17db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "\n",
    "gpu_ok = False\n",
    "if torch.cuda.is_available():\n",
    "    device_cap = torch.cuda.get_device_capability()\n",
    "    if device_cap in ((7, 0), (8, 0), (9, 0)):\n",
    "        gpu_ok = True\n",
    "\n",
    "if not gpu_ok:\n",
    "    warnings.warn(\n",
    "        \"GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower \"\n",
    "        \"than expected.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ecd7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the result of running `fn()` and the time it took for `fn()` to run,\n",
    "# in seconds. We use CUDA events and synchronization for the most accurate\n",
    "# measurements.\n",
    "def timed(fn):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000\n",
    "\n",
    "# Generates random input and targets data for the model, where `b` is\n",
    "# batch size.\n",
    "def generate_data(b):\n",
    "    return (\n",
    "        torch.randn(b, 3, 128, 128).to(torch.float32).cuda(),\n",
    "        torch.randint(1000, (b,)).cuda(),\n",
    "    )\n",
    "\n",
    "N_ITERS = 10\n",
    "\n",
    "from torchvision.models import densenet121\n",
    "def init_model():\n",
    "    return densenet121().to(torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ab90bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager: 0.6182738037109375\n",
      "compile: 73.2932265625\n"
     ]
    }
   ],
   "source": [
    "model = init_model()\n",
    "\n",
    "# Reset since we are using a different mode.\n",
    "import torch._dynamo\n",
    "torch._dynamo.reset()\n",
    "\n",
    "model_opt = torch.compile(model, mode=\"reduce-overhead\")\n",
    "\n",
    "inp = generate_data(16)[0]\n",
    "with torch.no_grad():\n",
    "    print(\"eager:\", timed(lambda: model(inp))[1])\n",
    "    print(\"compile:\", timed(lambda: model_opt(inp))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7bdc767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager: 0.029868032455444334\n",
      "compile: 0.9026836547851562\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"eager:\", timed(lambda: model(inp))[1])\n",
    "    print(\"compile:\", timed(lambda: model_opt(inp))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "256061d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager: 0.02528358459472656\n",
      "compile: 0.006692863941192627\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"eager:\", timed(lambda: model(inp))[1])\n",
    "    print(\"compile:\", timed(lambda: model_opt(inp))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from world_machine.profile import profile_range\n",
    "\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = init_model()\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db420fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4836ec47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager: 0.021358591079711914\n",
      "compile: 8.074880859375\n"
     ]
    }
   ],
   "source": [
    "torch._dynamo.reset()\n",
    "\n",
    "model_opt = torch.compile(model, mode=\"reduce-overhead\")\n",
    "\n",
    "inp = generate_data(16)[0]\n",
    "with torch.no_grad():\n",
    "    print(\"eager:\", timed(lambda: model(inp))[1])\n",
    "    print(\"compile:\", timed(lambda: model_opt(inp))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01395916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager: 0.01586995220184326\n",
      "compile: 0.0067276802062988285\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"eager:\", timed(lambda: model(inp))[1])\n",
    "    print(\"compile:\", timed(lambda: model_opt(inp))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15db8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from world_machine import WorldMachine, WorldMachineBuilder\n",
    "from world_machine.layers import PointwiseFeedforward\n",
    "\n",
    "\n",
    "def get_benchmark_model() -> WorldMachine:\n",
    "    builder = WorldMachineBuilder(128, 100, \"alibi\", False)\n",
    "\n",
    "    builder.add_sensorial_dimension(\"dim0\",\n",
    "                                    128,\n",
    "                                    PointwiseFeedforward(\n",
    "                                        3, 2*128, output_dim=128),\n",
    "                                    PointwiseFeedforward(128, 2*128, output_dim=3))\n",
    "\n",
    "    builder.add_sensorial_dimension(\"dim1\",\n",
    "                                    128,\n",
    "                                    PointwiseFeedforward(\n",
    "                                        3, 2*128, output_dim=128),\n",
    "                                    PointwiseFeedforward(128, 2*128, output_dim=3))\n",
    "\n",
    "    builder.add_block(1, \"dim0\", n_attention_head=4)\n",
    "    builder.add_block(1, \"dim1\", n_attention_head=1)\n",
    "\n",
    "    builder.remove_positional_encoding = False\n",
    "    builder.state_activation = \"tanh\"\n",
    "    builder.state_dropout = False\n",
    "\n",
    "    model = builder.build()\n",
    "\n",
    "    return model\n",
    "\n",
    "import torch\n",
    "\n",
    "from world_machine.data import WorldMachineDataLoader, WorldMachineDataset\n",
    "\n",
    "\n",
    "class BenchmarkDataset(WorldMachineDataset):\n",
    "    def __init__(self):\n",
    "        sensorial_dimensions = [\"dim0\", \"dim1\"]\n",
    "        size = 32*10\n",
    "        has_state_decoded = False\n",
    "        has_masks = True\n",
    "        super().__init__(sensorial_dimensions, size, has_state_decoded, has_masks)\n",
    "\n",
    "    def get_dimension_item(self, dimension: str, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        return torch.empty([100, 3]), torch.empty([100, 3])\n",
    "\n",
    "    def get_dimension_mask(self, dimension, index) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        return torch.ones(100, dtype=bool), torch.ones(100, dtype=bool)\n",
    "\n",
    "\n",
    "def get_benchmark_dataloaders():\n",
    "    dataset = BenchmarkDataset()\n",
    "\n",
    "    train_loader = WorldMachineDataLoader(dataset, 32, True)\n",
    "    val_loader = WorldMachineDataLoader(dataset, 32, True)\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef44f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_benchmark_model()\n",
    "model.eval()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9bba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader, _ = get_benchmark_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474e8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = next(iter(loader))\n",
    "item = item.cuda()\n",
    "\n",
    "state = torch.zeros([32, 100, 128], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d55a21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager: 0.8495134887695313\n",
      "compile: 0.25009152221679687\n"
     ]
    }
   ],
   "source": [
    "torch._dynamo.reset()\n",
    "\n",
    "model_opt = torch.compile(model, mode=\"reduce-overhead\")\n",
    "\n",
    "inp = item\n",
    "with torch.no_grad():\n",
    "    print(\"eager:\", timed(lambda: model.inference(\n",
    "                state, sensorial_data=item[\"inputs\"], sensorial_masks=item[\"input_masks\"]))[1])\n",
    "    print(\"compile:\", timed(lambda: model_opt.inference(\n",
    "                state, sensorial_data=item[\"inputs\"], sensorial_masks=item[\"input_masks\"]))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8b4789d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager: 0.27407461547851564\n",
      "compile: 0.23983821105957032\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"eager:\", timed(lambda: model.inference(\n",
    "                state, sensorial_data=item[\"inputs\"], sensorial_masks=item[\"input_masks\"]))[1])\n",
    "    print(\"compile:\", timed(lambda: model_opt.inference(\n",
    "                state, sensorial_data=item[\"inputs\"], sensorial_masks=item[\"input_masks\"]))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d21953a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager: 0.00329420804977417\n",
      "compile: 8.89790625\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"eager:\", timed(lambda: model(\n",
    "                state, sensorial_data=item[\"inputs\"], sensorial_masks=item[\"input_masks\"]))[1])\n",
    "    print(\"compile:\", timed(lambda: model_opt(\n",
    "                state, sensorial_data=item[\"inputs\"], sensorial_masks=item[\"input_masks\"]))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24c49d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager eval time 0: 0.005171199798583984\n",
      "eager eval time 1: 0.0037355520725250242\n",
      "eager eval time 2: 0.0030412800312042236\n",
      "eager eval time 3: 0.0032481279373168946\n",
      "eager eval time 4: 0.002983936071395874\n",
      "eager eval time 5: 0.003458048105239868\n",
      "eager eval time 6: 0.002942975997924805\n",
      "eager eval time 7: 0.003034111976623535\n",
      "eager eval time 8: 0.0027596800327301025\n",
      "eager eval time 9: 0.0030146560668945313\n",
      "~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/cuda/graphs.py:84: UserWarning: The CUDA Graph is empty. This usually means that the graph was attempted to be captured on wrong device or stream. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:175.)\n",
      "  super().capture_end()\n",
      "/usr/local/lib/python3.12/dist-packages/torch/cuda/graphs.py:84: UserWarning: The CUDA Graph is empty. This usually means that the graph was attempted to be captured on wrong device or stream. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:175.)\n",
      "  super().capture_end()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile eval time 0: 4.11998291015625\n",
      "compile eval time 1: 0.004907008171081543\n",
      "compile eval time 2: 0.0033894400596618654\n",
      "compile eval time 3: 0.004100096225738525\n",
      "compile eval time 4: 0.0036382720470428467\n",
      "compile eval time 5: 0.003408895969390869\n",
      "compile eval time 6: 0.005074944019317627\n",
      "compile eval time 7: 0.0037969920635223388\n",
      "compile eval time 8: 0.003471359968185425\n",
      "compile eval time 9: 0.004237311840057373\n",
      "~~~~~~~~~~\n",
      "(eval) eager median: 0.003037696003913879, compile median: 0.003948544144630432, speedup: 0.7693205122310202x\n",
      "~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "eager_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate_data(16)[0]\n",
    "    with torch.no_grad():\n",
    "        _, eager_time = timed(lambda: model(\n",
    "                state, sensorial_data=item[\"inputs\"], sensorial_masks=item[\"input_masks\"]))\n",
    "    eager_times.append(eager_time)\n",
    "    print(f\"eager eval time {i}: {eager_time}\")\n",
    "\n",
    "print(\"~\" * 10)\n",
    "\n",
    "compile_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate_data(16)[0]\n",
    "    with torch.no_grad():\n",
    "        _, compile_time = timed(lambda: model_opt(\n",
    "                state, sensorial_data=item[\"inputs\"], sensorial_masks=item[\"input_masks\"]))\n",
    "    compile_times.append(compile_time)\n",
    "    print(f\"compile eval time {i}: {compile_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "import numpy as np\n",
    "eager_med = np.median(eager_times)\n",
    "compile_med = np.median(compile_times)\n",
    "speedup = eager_med / compile_med\n",
    "#assert(speedup > 1)\n",
    "print(f\"(eval) eager median: {eager_med}, compile median: {compile_med}, speedup: {speedup}x\")\n",
    "print(\"~\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86a0f1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:1150: UserWarning: Synchronization debug mode is a prototype feature and does not yet detect all synchronizing operations (Triggered internally at /opt/pytorch/pytorch/torch/csrc/cuda/Module.cpp:978.)\n",
      "  torch._C._cuda_set_sync_debug_mode(debug_mode)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_sync_debug_mode(\"warn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6aa79e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/WorldMachine/src/world_machine/layers/attention.py:184: UserWarning: called a synchronizing CUDA operation (Triggered internally at /opt/pytorch/pytorch/c10/cuda/CUDAFunctions.cpp:152.)\n",
      "  E = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        dim0: Tensor(shape=torch.Size([32, 100, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        dim1: Tensor(shape=torch.Size([32, 100, 3]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        state: Tensor(shape=torch.Size([32, 100, 128]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        state_decoded: Tensor(shape=torch.Size([32, 100, 128]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "    batch_size=torch.Size([32, 100]),\n",
       "    device=cuda:0,\n",
       "    is_shared=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(state, sensorial_data=item[\"inputs\"], sensorial_masks=item[\"input_masks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b385379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
