{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e272d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tensordict import TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae9866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\Users\\eltsu\\Documentos\\Projetos\\WorldMachine\\resultados\\toy1d_experiment0_protocol_test\\Base\\run_0\\toy1d_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5227beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab3675e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.randn((1, 20, 128), dtype=torch.float32, device=\"cuda\")\n",
    "sensory_data = TensorDict({\"measurement\":torch.randn((1, 20, 2), dtype=torch.float32)}, batch_size=[1,20], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec39f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        measurement: Tensor(shape=torch.Size([1, 20, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        state: Tensor(shape=torch.Size([1, 20, 128]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        state_decoded: Tensor(shape=torch.Size([1, 20, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "    batch_size=torch.Size([1, 20]),\n",
       "    device=cuda:0,\n",
       "    is_shared=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(state=state, sensory_data=sensory_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "377a806e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': {},\n",
       " '_buffers': {},\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': {'_blocks': ModuleList(\n",
       "    (0-1): 2 x BlockContainer(\n",
       "      (block): AdaLNZeroBlock(\n",
       "        (conditioning_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (modulate1): Modulate()\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (attention): MultiHeadAttention(\n",
       "            (_positional_encoder): AlibiPositionalEncoder()\n",
       "            (input_projection): Linear(in_features=128, out_features=384, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (dropout_attention): Dropout(p=0.0, inplace=False)\n",
       "        (modulate2): Modulate()\n",
       "        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (modulate3): Modulate()\n",
       "        (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (dropout_linear1): Dropout(p=0.0, inplace=False)\n",
       "        (act): GELU(approximate='tanh')\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (dropout_linear2): Dropout(p=0.0, inplace=False)\n",
       "        (modulate4): Modulate()\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  '_state_encoder': PointwiseFeedforward(\n",
       "    (linear1): Linear(in_features=1, out_features=256, bias=True)\n",
       "    (dropout_linear1): Dropout(p=0.0, inplace=False)\n",
       "    (relu): ReLU()\n",
       "    (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (dropout_linear2): Dropout(p=0.0, inplace=False)\n",
       "  ),\n",
       "  '_state_decoder': PointwiseFeedforward(\n",
       "    (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (dropout_linear1): Dropout(p=0.0, inplace=False)\n",
       "    (relu): ReLU()\n",
       "    (linear2): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (dropout_linear2): Dropout(p=0.0, inplace=False)\n",
       "  ),\n",
       "  '_positional_encoder': AlibiPositionalEncoder(),\n",
       "  '_state_activation': Tanh(),\n",
       "  '_sensory_encoders': ModuleDict(\n",
       "    (measurement): PointwiseFeedforward(\n",
       "      (linear1): Linear(in_features=2, out_features=256, bias=True)\n",
       "      (dropout_linear1): Dropout(p=0.0, inplace=False)\n",
       "      (relu): ReLU()\n",
       "      (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (dropout_linear2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  ),\n",
       "  '_sensory_decoders': ModuleDict(\n",
       "    (measurement): PointwiseFeedforward(\n",
       "      (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (dropout_linear1): Dropout(p=0.0, inplace=False)\n",
       "      (relu): ReLU()\n",
       "      (linear2): Linear(in_features=256, out_features=2, bias=True)\n",
       "      (dropout_linear2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )},\n",
       " '_max_context_size': 200,\n",
       " '_state_size': 128,\n",
       " '_detach_decoders': set(),\n",
       " '_positional_encoder_type': 'alibi',\n",
       " '_remove_positional_encoding': False,\n",
       " '_state_dropout': None,\n",
       " '_local_mode': False,\n",
       " '_sensory_channels': {'measurement'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422e94f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
