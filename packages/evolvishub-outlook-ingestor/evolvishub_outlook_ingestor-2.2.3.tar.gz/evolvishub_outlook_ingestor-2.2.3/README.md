<div align="center">
  <img src="https://evolvis.ai/wp-content/uploads/2025/08/evie-solutions-03.png" alt="Evolvis AI - Evie Solutions Logo" width="400">
</div>

# Evolvishub Outlook Email Ingestor

**Enterprise-ready email ingestion library with unified database connector architecture.**

A streamlined Python library specifically designed for ingesting emails from Microsoft Outlook using Microsoft Graph API. Built as a pure data ingestion library that can be easily integrated into other applications and microservices. **Now featuring standardized database connectors with enterprise-grade consistency across all 8 supported database types.**

## Download Statistics

[![Weekly Downloads](https://pepy.tech/badge/evolvishub-outlook-ingestor/week)](https://pepy.tech/project/evolvishub-outlook-ingestor)
[![Monthly Downloads](https://pepy.tech/badge/evolvishub-outlook-ingestor/month)](https://pepy.tech/project/evolvishub-outlook-ingestor)
[![Total Downloads](https://pepy.tech/badge/evolvishub-outlook-ingestor)](https://pepy.tech/project/evolvishub-outlook-ingestor)

[![PyPI Version](https://img.shields.io/pypi/v/evolvishub-outlook-ingestor)](https://pypi.org/project/evolvishub-outlook-ingestor/)
[![Python Versions](https://img.shields.io/pypi/pyversions/evolvishub-outlook-ingestor)](https://pypi.org/project/evolvishub-outlook-ingestor/)
[![Evolvis AI License](https://img.shields.io/pypi/l/evolvishub-outlook-ingestor)](LICENSE)

## Quick Start

```python
import asyncio
from evolvishub_outlook_ingestor import EmailIngestor, ingest_emails_simple

# Simple usage - minimal configuration
async def simple_example():
    result = await ingest_emails_simple(
        client_id="your-client-id",
        client_secret="your-client-secret",
        tenant_id="your-tenant-id",
        output_format="json"
    )
    print(f"Processed {result['processed_emails']} emails")

# Advanced usage - full control
async def advanced_example():
    from evolvishub_outlook_ingestor import Settings, IngestionConfig
    from evolvishub_outlook_ingestor.adapters.microsoft_graph import MicrosoftGraphAdapter

    # Setup
    settings = Settings()
    settings.graph_api.client_id = "your-client-id"
    settings.graph_api.client_secret = "your-client-secret"
    settings.graph_api.tenant_id = "your-tenant-id"

    adapter = MicrosoftGraphAdapter(settings)
    await adapter.initialize()

    # Configure ingestion
    config = IngestionConfig(
        batch_size=100,
        include_attachments=True,
        progress_callback=lambda p, t: print(f"Progress: {p}/{t}")
    )

    # Ingest emails
    ingestor = EmailIngestor(settings=settings, graph_adapter=adapter)
    await ingestor.initialize(config)

    result = await ingestor.ingest_emails(
        folder_ids=["inbox", "sent"],
        output_format="database"
    )

    print(f"Ingestion completed: {result.processed_emails} emails")

# Run examples
asyncio.run(simple_example())
```

## üéØ Focused Email Ingestion (v2.1.0)

**This library is now focused exclusively on email ingestion.** We've removed all non-email functionality (calendar, contacts, etc.) to create a streamlined, reliable tool that does one thing exceptionally well.

### üöÄ **NEW in v2.1.0: Complete Database Connector Standardization**

**All 8 supported database types now have enterprise-grade consistency!** We've eliminated architectural bias by standardizing all database connectors to use the unified `DatabaseConnector` interface, providing equal implementation quality and features across all database types.

### ‚ú® Key Features

#### üìß **Complete Email Operations**
- **Full Email Access**: Read emails from all folders (inbox, sent, drafts, etc.)
- **Advanced Search**: Complex OData queries and cross-folder search
- **Message Threading**: Conversation tracking and thread management
- **Attachment Handling**: Complete attachment processing with size limits
- **Email Metadata**: Full access to headers, properties, and classifications
- **Folder Management**: Access to all mail folders and hierarchies

#### ‚ö° **Production-Ready Ingestion**
- **Batch Processing**: Configurable batch sizes for optimal performance
- **Progress Tracking**: Real-time progress monitoring with callbacks
- **Error Handling**: Comprehensive retry mechanisms and error recovery
- **Async/Await Support**: High-performance concurrent processing
- **Memory Efficient**: Streaming processing for large datasets
- **Rate Limiting**: Built-in throttling to respect API limits

#### üîß **Easy Integration**
- **Simple API**: Clean, intuitive interface for easy integration
- **Multiple Output Formats**: JSON, CSV, database storage
- **Configurable Processing**: Flexible configuration options
- **Health Monitoring**: Built-in health checks and diagnostics
- **Comprehensive Logging**: Detailed logging for debugging and monitoring
- **Type Safety**: Full type hints and Pydantic models

#### üè¢ **Enterprise Features**
- **Delta Sync**: Incremental synchronization for efficiency
- **Connection Pooling**: Optimized HTTP connection management
- **Retry Logic**: Exponential backoff with configurable attempts
- **Resource Cleanup**: Proper resource management and cleanup
- **Multi-tenant Support**: Support for multiple user accounts
- **Security**: Secure credential handling and OAuth2 flows


## Installation

```bash
# Basic installation (email ingestion only)
pip install evolvishub-outlook-ingestor

# With all database connectors (8 databases supported)
pip install 'evolvishub-outlook-ingestor[database]'

# Individual database connectors
pip install 'evolvishub-outlook-ingestor[postgresql]'  # PostgreSQL
pip install 'evolvishub-outlook-ingestor[mongodb]'     # MongoDB
pip install 'evolvishub-outlook-ingestor[sqlite]'      # SQLite
pip install 'evolvishub-outlook-ingestor[cockroachdb]' # CockroachDB
pip install 'evolvishub-outlook-ingestor[mariadb]'     # MariaDB
pip install 'evolvishub-outlook-ingestor[mssql]'       # MS SQL Server
pip install 'evolvishub-outlook-ingestor[oracle]'      # Oracle Database
pip install 'evolvishub-outlook-ingestor[clickhouse]'  # ClickHouse

# Development installation
pip install 'evolvishub-outlook-ingestor[dev]'
```

## Core Features

### Email Ingestion & Processing
- Microsoft Graph API integration for Office 365/Exchange Online
- Exchange Web Services (EWS) support for on-premises Exchange
- IMAP/POP3 protocol support for legacy systems
- Comprehensive email metadata extraction and processing

### üóÑÔ∏è **Enterprise Database Storage (8 Database Types)**
- **Unified DatabaseConnector Interface**: All databases now use the same standardized interface
- **Complete Database Support**: PostgreSQL, MongoDB, SQLite, CockroachDB, MariaDB, MS SQL Server, Oracle, ClickHouse
- **Enterprise Features**: Async operations, connection pooling, batch processing, error handling
- **Database-Specific Optimizations**: MERGE statements, UPSERT operations, columnar optimizations
- **Zero Architectural Bias**: Equal implementation quality across all database types
- **Easy Migration**: Switch between databases without code changes

## üèóÔ∏è **Database Connector Standardization (v2.1.0)**

### **Unified DatabaseConnector Architecture**

All 8 supported database types now implement the same standardized `DatabaseConnector` interface, eliminating architectural bias and providing enterprise-grade consistency:

```python
from evolvishub_outlook_ingestor.connectors.database_connector import create_database_connector, DatabaseConfig

# Same interface for all 8 database types!
config = DatabaseConfig(
    database_type="postgresql",  # or "mongodb", "sqlite", "cockroachdb",
                                 # "mariadb", "mssql", "oracle", "clickhouse"
    host="localhost",
    database="emails",
    username="user",
    password="password"
)

# Factory function creates the appropriate connector
connector = create_database_connector(config)

# All connectors support the same methods
await connector.connect()
await connector.create_schema()
await connector.store_email_batch(emails)
count = await connector.get_total_email_count()
await connector.disconnect()
```

### **Enterprise Features Across All Databases**

| Feature | All 8 Databases |
|---------|-----------------|
| **Async Operations** | ‚úÖ Full async/await support |
| **Connection Pooling** | ‚úÖ High-performance connection pools |
| **Batch Processing** | ‚úÖ Optimized batch operations |
| **Error Handling** | ‚úÖ Comprehensive exception management |
| **Security** | ‚úÖ Credential encryption, secure connections |
| **Monitoring** | ‚úÖ Structured logging and metrics |
| **Database-Specific Optimizations** | ‚úÖ MERGE, UPSERT, columnar operations |

### **Database-Specific Optimizations Maintained**

- **PostgreSQL**: Advanced indexing, JSONB support, full-text search
- **MongoDB**: GridFS for attachments, flexible schema, replica sets
- **SQLite**: Zero-config, file-based, ACID properties
- **CockroachDB**: Distributed consistency, UPSERT operations, multi-region
- **MariaDB**: MySQL compatibility, ON DUPLICATE KEY UPDATE, full-text search
- **MS SQL Server**: MERGE statements, enterprise security, Always Encrypted
- **Oracle**: Enterprise MERGE, JSON support (12c+), advanced data types
- **ClickHouse**: Columnar storage, analytics optimizations, large batch processing

## Advanced Features

### Real-time Streaming & Event Processing
- Redis pub/sub based event streaming with Kafka integration support
- Advanced backpressure handling with intelligent queues
- Real-time email processing capabilities
- Distributed streaming support with horizontal scaling

### Change Data Capture (CDC)
- Complete incremental processing capabilities
- Advanced change detection and synchronization
- Event-driven data capture with lineage tracking

### Data Transformation
- Complete data transformation pipelines
- NLP processing with sentiment analysis and language detection
- PII detection and entity extraction
- Content enrichment and metadata augmentation

### Analytics Engine
- Full analytics framework with communication pattern analysis
- Trend detection and insights generation
- ML-powered business intelligence and reporting

### Data Quality Validation
- Comprehensive data quality framework
- Advanced validation rules, scoring, and anomaly detection
- Duplicate detection and completeness validation

### Intelligent Caching
- Multi-level caching with LRU, LFU, and TTL strategies
- Redis integration with intelligent cache warming
- Predictive caching and performance optimization

### Multi-Tenant Support
- Complete tenant isolation and resource management
- Enterprise-grade security boundaries and access control
- Scalable multi-tenant architecture

### Data Governance
- Complete governance framework with lineage tracking
- Data retention policies and compliance monitoring
- GDPR/CCPA compliance validation and reporting

### Machine Learning Integration
- Full ML service with email classification and spam detection
- Priority prediction and sentiment analysis
- Model training and evaluation capabilities

### Monitoring & Observability
- Complete monitoring with distributed tracing
- Prometheus metrics integration and alerting
- Health checking and performance monitoring

## Supported Components

The following table provides a comprehensive overview of all supported components, connectors, and features:

| Component | Type | Status | Key Features |
|-----------|------|--------|--------------|
| **PostgreSQL** | Database | ‚úÖ **Standardized** | DatabaseConnector interface, async operations, connection pooling, ACID compliance |
| **MongoDB** | Database | ‚úÖ **Standardized** | DatabaseConnector interface, Motor async driver, GridFS support, replica sets |
| **SQLite** | Database | ‚úÖ **Standardized** | DatabaseConnector interface, zero-config setup, file-based storage, ACID properties |
| **CockroachDB** | Database | ‚úÖ **Standardized** | DatabaseConnector interface, distributed SQL, UPSERT operations, multi-region support |
| **MariaDB** | Database | ‚úÖ **Standardized** | DatabaseConnector interface, MySQL compatibility, ON DUPLICATE KEY UPDATE, clustering |
| **Microsoft SQL Server** | Database | ‚úÖ **Standardized** | DatabaseConnector interface, MERGE statements, enterprise security, Always Encrypted |
| **Oracle Database** | Database | ‚úÖ **Standardized** | DatabaseConnector interface, enterprise MERGE, JSON support, high availability |
| **ClickHouse** | Database | ‚úÖ **Standardized** | DatabaseConnector interface, columnar storage, analytics optimizations, horizontal scaling |
| **AWS S3** | Storage | Production Ready | Unlimited scalability, multiple storage classes, server-side encryption, AWS ecosystem |
| **Azure Blob Storage** | Storage | Production Ready | Multi-tier storage, Azure AD integration, geo-redundancy, threat protection |
| **Google Cloud Storage** | Storage | Production Ready | Multi-regional options, lifecycle management, GCP AI integration, strong consistency |
| **MinIO** | Storage | Production Ready | S3-compatible, high-performance, Kubernetes-native, multi-cloud gateway |
| **Delta Lake** | Storage | Production Ready | ACID transactions, schema evolution, time travel, Spark integration |
| **Apache Iceberg** | Storage | Production Ready | Schema evolution, hidden partitioning, time travel, multi-engine compatibility |
| **Real-time Email Streaming** | Streaming | Production Ready | Redis pub/sub, low-latency delivery, pattern subscriptions, auto-failover |
| **Kafka Integration** | Streaming | Production Ready | High-throughput messaging, exactly-once semantics, stream processing, multi-datacenter |
| **Change Data Capture (CDC)** | Streaming | Production Ready | Real-time change detection, event sourcing, conflict resolution, lineage tracking |
| **Event-driven Architecture** | Streaming | Production Ready | Event sourcing patterns, CQRS, saga pattern, event replay |
| **Analytics Engine** | Processing | Production Ready | Communication analysis, network mapping, trend detection, BI dashboards |
| **ML Service** | Processing | Production Ready | Email classification (95%+ accuracy), spam detection, priority prediction, sentiment analysis |
| **Data Quality Validator** | Processing | Production Ready | Anomaly detection, completeness checks, duplicate detection, quality scoring |
| **NLP Processor** | Processing | Production Ready | Multi-language analysis, NER, sentiment detection, topic modeling, text summarization |
| **Intelligent Caching** | Processing | Production Ready | Multi-level caching (LRU/LFU/TTL), predictive warming, distributed sync |
| **Data Governance** | Governance | Production Ready | GDPR/CCPA compliance, lineage tracking, automated validation, privacy assessments |
| **Multi-tenant Management** | Governance | Production Ready | Tenant isolation, resource quotas, RBAC, audit logging |
| **Advanced Monitoring** | Monitoring | Production Ready | Prometheus metrics, Grafana dashboards, distributed tracing, APM |
| **Security & Compliance** | Security | Production Ready | End-to-end encryption, OAuth 2.0/OIDC, certificate auth, audit trails |

### Component Categories

- **Database Connectors**: 8 standardized database systems with unified DatabaseConnector interface and enterprise-grade consistency
- **Storage Connectors**: 6 cloud and on-premises storage solutions for scalable data persistence
- **Streaming & CDC**: 4 real-time processing components for event-driven architectures
- **Advanced Processing**: 5 AI/ML and analytics components for intelligent email processing
- **Governance & Monitoring**: 4 enterprise-grade components for compliance and observability

### Integration Notes

All components are designed for:
- **Async Operations**: Full asynchronous support for high-performance processing
- **Horizontal Scaling**: Built-in support for distributed deployments
- **Enterprise Security**: Comprehensive security features and compliance support
- **Production Readiness**: Thoroughly tested and optimized for enterprise workloads

## Configuration

### Basic Configuration

```python
from evolvishub_outlook_ingestor import Settings
from evolvishub_outlook_ingestor.connectors.database_connector import DatabaseConfig

settings = Settings()

# Unified database configuration (works with all 8 database types!)
database_config = DatabaseConfig(
    database_type="postgresql",  # or any of the 8 supported types
    host="localhost",
    port=5432,
    database="outlook_emails",
    username="user",
    password="password",
    table_name="emails",
    batch_size=100,
    max_connections=10
)

# Microsoft Graph API
settings.protocols.graph.client_id = "your-client-id"
settings.protocols.graph.client_secret = "your-client-secret"
settings.protocols.graph.tenant_id = "your-tenant-id"
```

### Database-Specific Configuration Examples

```python
# PostgreSQL
postgresql_config = DatabaseConfig(
    database_type="postgresql",
    host="localhost",
    port=5432,
    database="emails"
)

# MongoDB
mongodb_config = DatabaseConfig(
    database_type="mongodb",
    host="localhost",
    port=27017,
    database="emails"
)

# CockroachDB
cockroachdb_config = DatabaseConfig(
    database_type="cockroachdb",
    host="localhost",
    port=26257,
    database="emails",
    sslmode="require"
)

# ClickHouse
clickhouse_config = DatabaseConfig(
    database_type="clickhouse",
    host="localhost",
    port=8123,
    database="emails",
    secure=True,
    compression=True
)

# MS SQL Server
mssql_config = DatabaseConfig(
    database_type="mssql",
    host="localhost",
    port=1433,
    database="emails",
    encrypt=True,
    trust_server_certificate=False
)
```

### Advanced Configuration

```python
# Enable advanced features
settings.enable_analytics = True
settings.enable_ml = True
settings.enable_governance = True
settings.enable_monitoring = True

# Streaming configuration
settings.streaming.backend = "redis"
settings.streaming.redis_url = "redis://localhost:6379"

# ML configuration
settings.ml.enable_spam_detection = True
settings.ml.enable_classification = True
settings.ml.enable_priority_prediction = True

# Governance configuration
settings.governance.enable_compliance_monitoring = True
settings.governance.enable_retention_policies = True
settings.governance.enable_lineage_tracking = True
```

## Advanced Usage

### Complete Pipeline with All Features

```python
import asyncio
from evolvishub_outlook_ingestor import (
    OutlookIngestor,
    AdvancedMonitoringService,
    IntelligentCacheManager,
    MLService,
    DataQualityValidator,
    AnalyticsEngine,
    GovernanceService,
    Settings
)

async def advanced_pipeline():
    settings = Settings()
    
    # Initialize core ingestor
    ingestor = OutlookIngestor(settings)
    
    # Initialize advanced services
    monitoring = AdvancedMonitoringService({'enable_tracing': True})
    cache = IntelligentCacheManager({'backend': 'memory'})
    ml_service = MLService({'enable_spam_detection': True})
    quality_validator = DataQualityValidator({'enable_duplicate_detection': True})
    analytics = AnalyticsEngine({'enable_communication_analysis': True})
    governance = GovernanceService({'enable_compliance_monitoring': True})
    
    # Initialize all services
    await monitoring.initialize()
    await cache.initialize()
    await ml_service.initialize()
    await quality_validator.initialize()
    await analytics.initialize()
    await governance.initialize()
    
    print("All services initialized successfully!")
    print("Advanced email processing pipeline ready")
    
    # Cleanup
    await monitoring.shutdown()
    await cache.shutdown()
    await ml_service.shutdown()
    await quality_validator.shutdown()
    await analytics.shutdown()
    await governance.shutdown()

asyncio.run(advanced_pipeline())
```

## Performance

### Production Benchmarks

| Configuration | Emails/Minute | Memory Usage | Notes |
|---------------|---------------|--------------|-------|
| Basic Processing | 500-1000 | 128MB | Core ingestion with optimizations |
| With Database Storage | 800-1500 | 256MB | PostgreSQL/MongoDB with connection pooling |
| With Redis Caching | 1200-2000 | 384MB | Intelligent caching enabled |
| Full ML Pipeline | 600-1200 | 512MB | Complete ML classification and analysis |
| Enterprise Setup | 1500-3000 | 1GB | All features with monitoring and governance |

### Feature Performance

| Feature | Status | Performance | Notes |
|---------|--------|-------------|-------|
| Real-time Streaming | Production Ready | 2000+ emails/min | Redis + Kafka support |
| ML Classification | Production Ready | 1000+ emails/min | Full sklearn/spacy pipeline |
| Analytics Engine | Production Ready | Real-time insights | Complete communication analysis |
| Intelligent Caching | Production Ready | 95%+ hit rate | Multi-level LRU/LFU/TTL strategies |
| Data Governance | Production Ready | Full compliance | GDPR/CCPA monitoring and reporting |

## Requirements

### System Requirements
- Python 3.9+
- 4GB+ RAM (8GB+ recommended for enterprise features)
- 10GB+ disk space for data storage

### Optional External Services
- Database: PostgreSQL 12+ or MongoDB 4.4+ (for data persistence)
- Message Queue: Redis 6.0+ (for streaming) or Kafka 2.8+ (with aiokafka dependency)
- Monitoring: Prometheus, Jaeger, InfluxDB (for observability)
- Cache: Redis 6.0+ (for distributed caching)

## Documentation

- [Configuration Reference](docs/CONFIGURATION_REFERENCE.md)
- [Deployment Guide](docs/DEPLOYMENT_GUIDE.md)
- [Advanced Features](docs/ADVANCED_FEATURES.md)
- [API Reference](docs/API_REFERENCE.md)

## License

This project is licensed under the Evolvis AI License - see the [LICENSE](LICENSE) file for details.

## Support

For support, please contact Montgomery Miralles [m.miralles@evolvis.ai](mailto:m.miralles@evolvis.ai) or visit our [documentation](https://docs.evolvis.ai).
