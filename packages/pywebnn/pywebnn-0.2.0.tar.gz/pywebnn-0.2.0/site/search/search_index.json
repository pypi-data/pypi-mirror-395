{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#webnn-python-api-documentation","title":"WebNN Python API Documentation","text":"<p>Welcome to the WebNN Python API documentation. This library provides Python bindings for the W3C WebNN (Web Neural Network) API, enabling you to build, validate, and execute neural network graphs in Python.</p>"},{"location":"#overview","title":"Overview","text":"<p>The WebNN Python API allows you to:</p> <ul> <li>Build neural network graphs using a simple, intuitive Python API</li> <li>Validate graphs using the same validation logic as web browsers</li> <li>Convert graphs to ONNX and CoreML formats</li> <li>Execute models on CPU, GPU, or Neural Engine (macOS)</li> <li>Integrate seamlessly with NumPy for tensor operations</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<p>\u2705 W3C Standard Compliant - Implements the official WebNN specification \u2705 Type-Safe - Full type hints for IDE autocomplete \u2705 NumPy Integration - Seamless conversion between NumPy arrays and graph operands \u2705 Multiple Backends - ONNX and CoreML export support \u2705 Fast - Built with Rust and PyO3 for maximum performance \u2705 Cross-Platform - Works on Linux, macOS, and Windows</p>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import webnn\nimport numpy as np\n\n# Create ML context\nml = webnn.ML()\ncontext = ml.create_context(device_type=\"cpu\")\nbuilder = context.create_graph_builder()\n\n# Build a simple neural network\ninput_tensor = builder.input(\"input\", [1, 784], \"float32\")\nweights = builder.constant(np.random.randn(784, 10).astype('float32'))\nbias = builder.constant(np.zeros(10, dtype='float32'))\n\n# Forward pass: output = relu(input @ weights + bias)\nmatmul_result = builder.matmul(input_tensor, weights)\nadd_result = builder.add(matmul_result, bias)\noutput = builder.relu(add_result)\n\n# Compile the graph\ngraph = builder.build({\"output\": output})\n\n# Export to ONNX\ncontext.convert_to_onnx(graph, \"model.onnx\")\nprint(f\"Graph compiled: {graph.operand_count} operands, {graph.operation_count} operations\")\n</code></pre>"},{"location":"#installation","title":"Installation","text":""},{"location":"#from-source","title":"From Source","text":"<pre><code># Clone the repository\ngit clone https://github.com/your-org/rust-webnn-graph.git\ncd rust-webnn-graph\n\n# Install maturin\npip install maturin\n\n# Build and install\nmaturin develop --features python\n</code></pre>"},{"location":"#from-pypi-coming-soon","title":"From PyPI (Coming Soon)","text":"<pre><code>pip install webnn\n</code></pre>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>Getting Started - Installation and first steps</li> <li>API Reference - Complete API documentation</li> <li>Examples - Code examples and tutorials</li> <li>Advanced Topics - Advanced usage patterns</li> </ul>"},{"location":"#support","title":"Support","text":"<ul> <li>GitHub Issues: Report bugs or request features</li> <li>Specification: W3C WebNN Spec</li> </ul>"},{"location":"#license","title":"License","text":"<p>Apache-2.0 License - See LICENSE for details.</p>"},{"location":"advanced/","title":"Advanced Topics","text":"<p>Advanced usage patterns and best practices for the WebNN Python API.</p>"},{"location":"advanced/#performance-optimization","title":"Performance Optimization","text":""},{"location":"advanced/#graph-compilation","title":"Graph Compilation","text":"<p>Compile graphs once and reuse them:</p> <pre><code>import webnn\n\nclass ModelCache:\n    def __init__(self):\n        self.ml = webnn.ML()\n        self.context = self.ml.create_context()\n        self.graphs = {}\n\n    def get_or_build_graph(self, name, builder_fn):\n        \"\"\"Cache compiled graphs for reuse.\"\"\"\n        if name not in self.graphs:\n            builder = self.context.create_graph_builder()\n            output = builder_fn(builder)\n            self.graphs[name] = builder.build({name: output})\n        return self.graphs[name]\n\n# Usage\ncache = ModelCache()\n\ndef build_relu(builder):\n    x = builder.input(\"x\", [100], \"float32\")\n    return builder.relu(x)\n\n# First call: compiles the graph\ngraph1 = cache.get_or_build_graph(\"relu\", build_relu)\n\n# Second call: returns cached graph (fast!)\ngraph2 = cache.get_or_build_graph(\"relu\", build_relu)\nassert graph1 is graph2\n</code></pre>"},{"location":"advanced/#memory-efficient-constants","title":"Memory-Efficient Constants","text":"<p>For large constant tensors, use the most memory-efficient data type:</p> <pre><code>import webnn\nimport numpy as np\n\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = context.create_graph_builder()\n\n# Use float16 instead of float32 to halve memory usage\nlarge_weights = np.random.randn(1000, 1000).astype('float16')\nweights_op = builder.constant(large_weights)\n\nprint(f\"Memory saved: {large_weights.nbytes / 1024 / 1024:.2f} MB vs \"\n      f\"{(large_weights.nbytes * 2) / 1024 / 1024:.2f} MB for float32\")\n</code></pre>"},{"location":"advanced/#integration-with-other-libraries","title":"Integration with Other Libraries","text":""},{"location":"advanced/#numpy-integration","title":"NumPy Integration","text":"<p>Seamless conversion between NumPy and WebNN:</p> <pre><code>import webnn\nimport numpy as np\n\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = context.create_graph_builder()\n\n# NumPy arrays are automatically converted\nweights = np.random.randn(100, 50).astype('float32')\nbias = np.zeros(50, dtype='float32')\n\n# Direct usage\nw_op = builder.constant(weights)\nb_op = builder.constant(bias)\n\n# Different NumPy dtypes\nfp16_array = np.random.randn(10, 10).astype('float16')\nint8_array = np.random.randint(-128, 127, (10, 10), dtype='int8')\n\nfp16_op = builder.constant(fp16_array)\nint8_op = builder.constant(int8_array)\n</code></pre>"},{"location":"advanced/#onnx-integration","title":"ONNX Integration","text":"<p>Load existing ONNX models and convert them:</p> <pre><code>import webnn\nimport numpy as np\n# Note: This is a conceptual example. Full ONNX loading\n# would require parsing the ONNX protobuf format.\n\ndef load_onnx_weights(onnx_path):\n    \"\"\"\n    Conceptual example of loading ONNX weights.\n    In practice, you'd use onnx.load() to parse the model.\n    \"\"\"\n    # This is a simplified example\n    weights = {\n        'fc1': np.random.randn(784, 128).astype('float32'),\n        'fc1_bias': np.zeros(128, dtype='float32'),\n        'fc2': np.random.randn(128, 10).astype('float32'),\n        'fc2_bias': np.zeros(10, dtype='float32'),\n    }\n    return weights\n\ndef build_from_onnx_weights(weights):\n    ml = webnn.ML()\n    context = ml.create_context()\n    builder = context.create_graph_builder()\n\n    # Build graph using ONNX weights\n    x = builder.input(\"input\", [1, 784], \"float32\")\n\n    w1 = builder.constant(weights['fc1'])\n    b1 = builder.constant(weights['fc1_bias'])\n    h1 = builder.matmul(x, w1)\n    h1 = builder.add(h1, b1)\n    h1 = builder.relu(h1)\n\n    w2 = builder.constant(weights['fc2'])\n    b2 = builder.constant(weights['fc2_bias'])\n    output = builder.matmul(h1, w2)\n    output = builder.add(output, b2)\n\n    return builder.build({\"output\": output})\n\nweights = load_onnx_weights(\"model.onnx\")\ngraph = build_from_onnx_weights(weights)\n</code></pre>"},{"location":"advanced/#graph-introspection","title":"Graph Introspection","text":"<p>Inspect and analyze compiled graphs:</p> <pre><code>import webnn\n\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = context.create_graph_builder()\n\n# Build a complex graph\nx = builder.input(\"x\", [10, 20], \"float32\")\ny = builder.input(\"y\", [20, 30], \"float32\")\nz = builder.matmul(x, y)\nw = builder.relu(z)\noutput = builder.sigmoid(w)\n\ngraph = builder.build({\"final\": output})\n\n# Inspect the graph\nprint(\"Graph Analysis:\")\nprint(f\"  Inputs: {graph.get_input_names()}\")\nprint(f\"  Outputs: {graph.get_output_names()}\")\nprint(f\"  Total operands: {graph.operand_count}\")\nprint(f\"  Total operations: {graph.operation_count}\")\nprint(f\"  Operations per input: {graph.operation_count / len(graph.get_input_names()):.1f}\")\n</code></pre>"},{"location":"advanced/#custom-graph-patterns","title":"Custom Graph Patterns","text":""},{"location":"advanced/#residual-connections","title":"Residual Connections","text":"<pre><code>import webnn\nimport numpy as np\n\ndef residual_block(builder, x, hidden_size):\n    \"\"\"Create a residual block: output = relu(x + fc(x))\"\"\"\n\n    # Linear transformation\n    w = builder.constant(np.random.randn(hidden_size, hidden_size).astype('float32') * 0.01)\n    transformed = builder.matmul(x, w)\n\n    # Add residual connection\n    residual = builder.add(x, transformed)\n\n    # Activation\n    output = builder.relu(residual)\n\n    return output\n\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = context.create_graph_builder()\n\nx = builder.input(\"x\", [1, 128], \"float32\")\ny = residual_block(builder, x, 128)\ngraph = builder.build({\"output\": y})\n\ncontext.convert_to_onnx(graph, \"residual.onnx\")\n</code></pre>"},{"location":"advanced/#attention-mechanism-simplified","title":"Attention Mechanism (Simplified)","text":"<pre><code>import webnn\nimport numpy as np\n\ndef scaled_dot_product_attention(builder, query, key, value, d_k):\n    \"\"\"\n    Simplified attention mechanism (without softmax for now).\n    attention = (query @ key.T) @ value\n    \"\"\"\n    # Transpose key (conceptually)\n    key_t = key  # In practice, you'd need to handle transposition\n\n    # Attention scores: query @ key.T\n    scores = builder.matmul(query, key_t)\n\n    # Apply scaling factor (as a constant multiply)\n    scale = 1.0 / np.sqrt(d_k)\n    scale_tensor = builder.constant(np.full_like(scores, scale))\n    scaled_scores = builder.mul(scores, scale_tensor)\n\n    # Attention output: scores @ value\n    output = builder.matmul(scaled_scores, value)\n\n    return output\n</code></pre>"},{"location":"advanced/#error-handling-strategies","title":"Error Handling Strategies","text":""},{"location":"advanced/#comprehensive-error-handling","title":"Comprehensive Error Handling","text":"<pre><code>import webnn\nimport sys\nimport traceback\n\ndef safe_graph_export(graph_fn, output_path):\n    \"\"\"\n    Safely build and export a graph with comprehensive error handling.\n    \"\"\"\n    try:\n        ml = webnn.ML()\n        context = ml.create_context()\n        builder = context.create_graph_builder()\n\n        # Build the graph\n        try:\n            output = graph_fn(builder)\n            graph = builder.build({\"output\": output})\n        except ValueError as e:\n            print(f\"\u274c Graph validation failed: {e}\", file=sys.stderr)\n            traceback.print_exc()\n            return False\n\n        # Export to ONNX\n        try:\n            context.convert_to_onnx(graph, output_path)\n            print(f\"\u2705 Successfully exported to {output_path}\")\n            return True\n        except IOError as e:\n            print(f\"\u274c File I/O error: {e}\", file=sys.stderr)\n            return False\n        except RuntimeError as e:\n            print(f\"\u274c Conversion failed: {e}\", file=sys.stderr)\n            return False\n\n    except Exception as e:\n        print(f\"\u274c Unexpected error: {e}\", file=sys.stderr)\n        traceback.print_exc()\n        return False\n\n# Usage\ndef my_graph(builder):\n    x = builder.input(\"x\", [10], \"float32\")\n    return builder.relu(x)\n\nsuccess = safe_graph_export(my_graph, \"model.onnx\")\nsys.exit(0 if success else 1)\n</code></pre>"},{"location":"advanced/#testing-graphs","title":"Testing Graphs","text":""},{"location":"advanced/#unit-testing-webnn-graphs","title":"Unit Testing WebNN Graphs","text":"<pre><code>import unittest\nimport webnn\nimport numpy as np\nimport os\n\nclass TestWebNNGraphs(unittest.TestCase):\n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.ml = webnn.ML()\n        self.context = self.ml.create_context()\n\n    def test_simple_relu(self):\n        \"\"\"Test ReLU graph creation and export.\"\"\"\n        builder = self.context.create_graph_builder()\n        x = builder.input(\"x\", [10], \"float32\")\n        y = builder.relu(x)\n        graph = builder.build({\"y\": y})\n\n        self.assertEqual(graph.operand_count, 2)\n        self.assertEqual(graph.operation_count, 1)\n        self.assertIn(\"x\", graph.get_input_names())\n        self.assertIn(\"y\", graph.get_output_names())\n\n    def test_onnx_export(self):\n        \"\"\"Test ONNX export functionality.\"\"\"\n        builder = self.context.create_graph_builder()\n        x = builder.input(\"x\", [10], \"float32\")\n        y = builder.relu(x)\n        graph = builder.build({\"y\": y})\n\n        output_path = \"test_model.onnx\"\n        try:\n            self.context.convert_to_onnx(graph, output_path)\n            self.assertTrue(os.path.exists(output_path))\n            self.assertGreater(os.path.getsize(output_path), 0)\n        finally:\n            if os.path.exists(output_path):\n                os.remove(output_path)\n\n    def test_invalid_shape(self):\n        \"\"\"Test that invalid shapes raise errors.\"\"\"\n        builder = self.context.create_graph_builder()\n\n        # This should work\n        x = builder.input(\"x\", [10, 20], \"float32\")\n\n        # Empty shape is valid (scalar)\n        scalar = builder.input(\"scalar\", [], \"float32\")\n\n    def test_multiple_outputs(self):\n        \"\"\"Test graphs with multiple outputs.\"\"\"\n        builder = self.context.create_graph_builder()\n        x = builder.input(\"x\", [10], \"float32\")\n\n        y1 = builder.relu(x)\n        y2 = builder.sigmoid(x)\n\n        graph = builder.build({\"relu\": y1, \"sigmoid\": y2})\n\n        outputs = graph.get_output_names()\n        self.assertIn(\"relu\", outputs)\n        self.assertIn(\"sigmoid\", outputs)\n\nif __name__ == '__main__':\n    unittest.main()\n</code></pre>"},{"location":"advanced/#debugging-tips","title":"Debugging Tips","text":""},{"location":"advanced/#verbose-graph-building","title":"Verbose Graph Building","text":"<pre><code>import webnn\n\nclass VerboseBuilder:\n    \"\"\"Wrapper that logs all operations.\"\"\"\n\n    def __init__(self, context):\n        self.context = context\n        self.builder = context.create_graph_builder()\n        self.op_count = 0\n\n    def input(self, name, shape, dtype=\"float32\"):\n        result = self.builder.input(name, shape, dtype)\n        print(f\"[{self.op_count}] INPUT: {name} {shape} {dtype}\")\n        self.op_count += 1\n        return result\n\n    def constant(self, value, **kwargs):\n        result = self.builder.constant(value, **kwargs)\n        print(f\"[{self.op_count}] CONSTANT: shape={value.shape}\")\n        self.op_count += 1\n        return result\n\n    def relu(self, x):\n        result = self.builder.relu(x)\n        print(f\"[{self.op_count}] RELU\")\n        self.op_count += 1\n        return result\n\n    def matmul(self, a, b):\n        result = self.builder.matmul(a, b)\n        print(f\"[{self.op_count}] MATMUL\")\n        self.op_count += 1\n        return result\n\n    # Add other operations as needed...\n\n    def build(self, outputs):\n        print(f\"\\nBuilding graph with {len(outputs)} output(s)...\")\n        return self.builder.build(outputs)\n\n# Usage\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = VerboseBuilder(context)\n\nx = builder.input(\"x\", [10], \"float32\")\ny = builder.relu(x)\ngraph = builder.build({\"y\": y})\n</code></pre> <p>Output: <pre><code>[0] INPUT: x [10] float32\n[1] RELU\n\nBuilding graph with 1 output(s)...\n</code></pre></p>"},{"location":"advanced/#platform-specific-features","title":"Platform-Specific Features","text":""},{"location":"advanced/#macos-coreml","title":"macOS CoreML","text":"<pre><code>import webnn\nimport platform\n\ndef export_for_platform(graph, base_name=\"model\"):\n    \"\"\"Export model in the best format for the current platform.\"\"\"\n    ml = webnn.ML()\n    context = ml.create_context()\n\n    # Always export ONNX (cross-platform)\n    onnx_path = f\"{base_name}.onnx\"\n    context.convert_to_onnx(graph, onnx_path)\n    print(f\"\u2713 Exported ONNX: {onnx_path}\")\n\n    # Export CoreML if on macOS\n    if platform.system() == \"Darwin\":\n        try:\n            coreml_path = f\"{base_name}.mlmodel\"\n            context.convert_to_coreml(graph, coreml_path)\n            print(f\"\u2713 Exported CoreML: {coreml_path}\")\n        except RuntimeError as e:\n            print(f\"\u26a0 CoreML export failed: {e}\")\n    else:\n        print(\"\u2139 CoreML export skipped (not on macOS)\")\n\n# Usage\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = context.create_graph_builder()\n\nx = builder.input(\"x\", [10], \"float32\")\ny = builder.add(x, x)  # Use only CoreML-supported ops\ngraph = builder.build({\"y\": y})\n\nexport_for_platform(graph, \"my_model\")\n</code></pre>"},{"location":"advanced/#best-practices-summary","title":"Best Practices Summary","text":"<ol> <li>Compile once, reuse: Cache compiled graphs</li> <li>Use appropriate data types: float16 for memory efficiency</li> <li>Handle errors gracefully: Wrap operations in try-except blocks</li> <li>Test thoroughly: Write unit tests for your graphs</li> <li>Validate shapes: Check tensor dimensions before building</li> <li>Profile performance: Measure compilation and export times</li> <li>Document graphs: Add comments explaining graph structure</li> <li>Use type hints: Leverage Python type hints for better IDE support</li> </ol> <pre><code>from typing import Dict\nimport webnn\nimport numpy as np\n\ndef build_classifier(\n    input_size: int,\n    hidden_size: int,\n    num_classes: int\n) -&gt; webnn.MLGraph:\n    \"\"\"\n    Build a simple classifier graph.\n\n    Args:\n        input_size: Size of input features\n        hidden_size: Size of hidden layer\n        num_classes: Number of output classes\n\n    Returns:\n        Compiled MLGraph ready for export\n    \"\"\"\n    ml = webnn.ML()\n    context = ml.create_context()\n    builder = context.create_graph_builder()\n\n    # Build model...\n    x = builder.input(\"input\", [1, input_size], \"float32\")\n    # ... rest of the model\n\n    return graph\n</code></pre>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete reference for the WebNN Python API.</p>"},{"location":"api-reference/#module-webnn","title":"Module: <code>webnn</code>","text":"<p>The main module exports all public classes and types.</p> <pre><code>import webnn\n</code></pre>"},{"location":"api-reference/#class-ml","title":"Class: <code>ML</code>","text":"<p>Entry point for the WebNN API. Provides methods to create execution contexts.</p>"},{"location":"api-reference/#constructor","title":"Constructor","text":"<pre><code>ml = webnn.ML()\n</code></pre> <p>Creates a new ML namespace instance.</p>"},{"location":"api-reference/#methods","title":"Methods","text":""},{"location":"api-reference/#create_contextdevice_typecpu-power_preferencedefault","title":"<code>create_context(device_type=\"cpu\", power_preference=\"default\")</code>","text":"<p>Creates a new execution context.</p> <p>Parameters:</p> <ul> <li><code>device_type</code> (str): Device to use. Options: <code>\"cpu\"</code>, <code>\"gpu\"</code>, <code>\"npu\"</code>. Default: <code>\"cpu\"</code></li> <li><code>power_preference</code> (str): Power preference. Options: <code>\"default\"</code>, <code>\"high-performance\"</code>, <code>\"low-power\"</code>. Default: <code>\"default\"</code></li> </ul> <p>Returns: <code>MLContext</code></p> <p>Example:</p> <pre><code>ml = webnn.ML()\ncontext = ml.create_context(device_type=\"cpu\", power_preference=\"default\")\n</code></pre>"},{"location":"api-reference/#class-mlcontext","title":"Class: <code>MLContext</code>","text":"<p>Represents an execution context for neural network operations.</p>"},{"location":"api-reference/#properties","title":"Properties","text":""},{"location":"api-reference/#device_type-str-read-only","title":"<code>device_type</code> (str, read-only)","text":"<p>The device type for this context.</p>"},{"location":"api-reference/#power_preference-str-read-only","title":"<code>power_preference</code> (str, read-only)","text":"<p>The power preference for this context.</p>"},{"location":"api-reference/#methods_1","title":"Methods","text":""},{"location":"api-reference/#create_graph_builder","title":"<code>create_graph_builder()</code>","text":"<p>Creates a new graph builder for constructing computational graphs.</p> <p>Returns: <code>MLGraphBuilder</code></p> <p>Example:</p> <pre><code>builder = context.create_graph_builder()\n</code></pre>"},{"location":"api-reference/#computegraph-inputs-outputsnone","title":"<code>compute(graph, inputs, outputs=None)</code>","text":"<p>Executes the graph with given inputs (placeholder implementation).</p> <p>Parameters:</p> <ul> <li><code>graph</code> (MLGraph): The compiled graph to execute</li> <li><code>inputs</code> (dict): Dictionary mapping input names to NumPy arrays</li> <li><code>outputs</code> (dict, optional): Pre-allocated output arrays</li> </ul> <p>Returns: dict - Dictionary mapping output names to result NumPy arrays</p> <p>Example:</p> <pre><code>results = context.compute(graph, {\n    \"input\": np.array([[1, 2, 3]], dtype=np.float32)\n})\n</code></pre>"},{"location":"api-reference/#convert_to_onnxgraph-output_path","title":"<code>convert_to_onnx(graph, output_path)</code>","text":"<p>Converts the graph to ONNX format and saves it to a file.</p> <p>Parameters:</p> <ul> <li><code>graph</code> (MLGraph): The graph to convert</li> <li><code>output_path</code> (str): Path where the ONNX model will be saved</li> </ul> <p>Example:</p> <pre><code>context.convert_to_onnx(graph, \"model.onnx\")\n</code></pre>"},{"location":"api-reference/#convert_to_coremlgraph-output_path","title":"<code>convert_to_coreml(graph, output_path)</code>","text":"<p>Converts the graph to CoreML format (macOS only).</p> <p>Parameters:</p> <ul> <li><code>graph</code> (MLGraph): The graph to convert</li> <li><code>output_path</code> (str): Path where the CoreML model will be saved</li> </ul> <p>Note: Only available on macOS. Supports limited operations (add, matmul).</p> <p>Example:</p> <pre><code>context.convert_to_coreml(graph, \"model.mlmodel\")\n</code></pre>"},{"location":"api-reference/#class-mlgraphbuilder","title":"Class: <code>MLGraphBuilder</code>","text":"<p>Builder for constructing computational graphs using a declarative API.</p>"},{"location":"api-reference/#inputconstant-operations","title":"Input/Constant Operations","text":""},{"location":"api-reference/#inputname-shape-data_typefloat32","title":"<code>input(name, shape, data_type=\"float32\")</code>","text":"<p>Creates an input operand.</p> <p>Parameters:</p> <ul> <li><code>name</code> (str): Name of the input</li> <li><code>shape</code> (list[int]): Shape of the tensor</li> <li><code>data_type</code> (str): Data type. Options: <code>\"float32\"</code>, <code>\"float16\"</code>, <code>\"int32\"</code>, <code>\"uint32\"</code>, <code>\"int8\"</code>, <code>\"uint8\"</code></li> </ul> <p>Returns: <code>MLOperand</code></p> <p>Example:</p> <pre><code>x = builder.input(\"x\", [1, 3, 224, 224], \"float32\")\n</code></pre>"},{"location":"api-reference/#constantvalue-shapenone-data_typenone","title":"<code>constant(value, shape=None, data_type=None)</code>","text":"<p>Creates a constant operand from a NumPy array or Python list.</p> <p>Parameters:</p> <ul> <li><code>value</code> (array-like): NumPy array or Python list</li> <li><code>shape</code> (list[int], optional): Shape override</li> <li><code>data_type</code> (str, optional): Data type override</li> </ul> <p>Returns: <code>MLOperand</code></p> <p>Example:</p> <pre><code>import numpy as np\n\nweights = builder.constant(np.random.randn(784, 10).astype('float32'))\nbias = builder.constant(np.zeros(10, dtype='float32'))\n</code></pre>"},{"location":"api-reference/#binary-operations","title":"Binary Operations","text":"<p>All binary operations take two operands and return a new operand.</p>"},{"location":"api-reference/#adda-b","title":"<code>add(a, b)</code>","text":"<p>Element-wise addition: <code>a + b</code></p>"},{"location":"api-reference/#suba-b","title":"<code>sub(a, b)</code>","text":"<p>Element-wise subtraction: <code>a - b</code></p>"},{"location":"api-reference/#mula-b","title":"<code>mul(a, b)</code>","text":"<p>Element-wise multiplication: <code>a * b</code></p>"},{"location":"api-reference/#diva-b","title":"<code>div(a, b)</code>","text":"<p>Element-wise division: <code>a / b</code></p>"},{"location":"api-reference/#matmula-b","title":"<code>matmul(a, b)</code>","text":"<p>Matrix multiplication: <code>a @ b</code></p> <p>Example:</p> <pre><code>x = builder.input(\"x\", [2, 3], \"float32\")\ny = builder.input(\"y\", [2, 3], \"float32\")\n\nsum_result = builder.add(x, y)\nproduct = builder.mul(x, y)\n</code></pre>"},{"location":"api-reference/#unary-operations","title":"Unary Operations","text":"<p>All unary operations take one operand and return a new operand.</p>"},{"location":"api-reference/#relux","title":"<code>relu(x)</code>","text":"<p>Rectified Linear Unit activation: <code>max(0, x)</code></p>"},{"location":"api-reference/#sigmoidx","title":"<code>sigmoid(x)</code>","text":"<p>Sigmoid activation: <code>1 / (1 + exp(-x))</code></p>"},{"location":"api-reference/#tanhx","title":"<code>tanh(x)</code>","text":"<p>Hyperbolic tangent activation</p>"},{"location":"api-reference/#softmaxx","title":"<code>softmax(x)</code>","text":"<p>Softmax activation (normalizes to probability distribution)</p> <p>Example:</p> <pre><code>x = builder.input(\"x\", [1, 10], \"float32\")\n\nrelu_out = builder.relu(x)\nsigmoid_out = builder.sigmoid(x)\ntanh_out = builder.tanh(x)\nsoftmax_out = builder.softmax(x)\n</code></pre>"},{"location":"api-reference/#shape-operations","title":"Shape Operations","text":""},{"location":"api-reference/#reshapex-new_shape","title":"<code>reshape(x, new_shape)</code>","text":"<p>Reshapes a tensor to a new shape.</p> <p>Parameters:</p> <ul> <li><code>x</code> (MLOperand): Input operand</li> <li><code>new_shape</code> (list[int]): New shape</li> </ul> <p>Returns: <code>MLOperand</code></p> <p>Example:</p> <pre><code>x = builder.input(\"x\", [1, 784], \"float32\")\nreshaped = builder.reshape(x, [1, 28, 28, 1])\n</code></pre>"},{"location":"api-reference/#graph-building","title":"Graph Building","text":""},{"location":"api-reference/#buildoutputs","title":"<code>build(outputs)</code>","text":"<p>Compiles the graph and returns an immutable MLGraph.</p> <p>Parameters:</p> <ul> <li><code>outputs</code> (dict): Dictionary mapping output names to MLOperand objects</li> </ul> <p>Returns: <code>MLGraph</code></p> <p>Example:</p> <pre><code>x = builder.input(\"x\", [2, 3], \"float32\")\ny = builder.relu(x)\n\ngraph = builder.build({\"output\": y})\n</code></pre>"},{"location":"api-reference/#class-mloperand","title":"Class: <code>MLOperand</code>","text":"<p>Represents a tensor operand in the computational graph.</p>"},{"location":"api-reference/#properties_1","title":"Properties","text":""},{"location":"api-reference/#data_type-str-read-only","title":"<code>data_type</code> (str, read-only)","text":"<p>The data type of the operand.</p>"},{"location":"api-reference/#shape-listint-read-only","title":"<code>shape</code> (list[int], read-only)","text":"<p>The shape of the operand.</p>"},{"location":"api-reference/#name-str-none-read-only","title":"<code>name</code> (str | None, read-only)","text":"<p>The name of the operand (if any).</p> <p>Example:</p> <pre><code>x = builder.input(\"x\", [2, 3], \"float32\")\n\nprint(x.data_type)  # \"float32\"\nprint(x.shape)      # [2, 3]\nprint(x.name)       # \"x\"\n</code></pre>"},{"location":"api-reference/#class-mlgraph","title":"Class: <code>MLGraph</code>","text":"<p>Represents a compiled, immutable computational graph.</p>"},{"location":"api-reference/#properties_2","title":"Properties","text":""},{"location":"api-reference/#operand_count-int-read-only","title":"<code>operand_count</code> (int, read-only)","text":"<p>The number of operands in the graph.</p>"},{"location":"api-reference/#operation_count-int-read-only","title":"<code>operation_count</code> (int, read-only)","text":"<p>The number of operations in the graph.</p>"},{"location":"api-reference/#methods_2","title":"Methods","text":""},{"location":"api-reference/#get_input_names","title":"<code>get_input_names()</code>","text":"<p>Returns the names of all input operands.</p> <p>Returns: list[str]</p>"},{"location":"api-reference/#get_output_names","title":"<code>get_output_names()</code>","text":"<p>Returns the names of all output operands.</p> <p>Returns: list[str]</p> <p>Example:</p> <pre><code>graph = builder.build({\"output\": y})\n\nprint(f\"Operands: {graph.operand_count}\")\nprint(f\"Operations: {graph.operation_count}\")\nprint(f\"Inputs: {graph.get_input_names()}\")\nprint(f\"Outputs: {graph.get_output_names()}\")\n</code></pre>"},{"location":"api-reference/#data-types","title":"Data Types","text":"<p>Supported data types:</p> Type Description Bytes per element <code>\"float32\"</code> 32-bit floating point 4 <code>\"float16\"</code> 16-bit floating point 2 <code>\"int32\"</code> 32-bit signed integer 4 <code>\"uint32\"</code> 32-bit unsigned integer 4 <code>\"int8\"</code> 8-bit signed integer 1 <code>\"uint8\"</code> 8-bit unsigned integer 1"},{"location":"api-reference/#error-handling","title":"Error Handling","text":"<p>All operations can raise Python exceptions:</p> <pre><code>try:\n    graph = builder.build({\"output\": invalid_operand})\nexcept ValueError as e:\n    print(f\"Graph validation failed: {e}\")\n\ntry:\n    context.convert_to_onnx(graph, \"/invalid/path.onnx\")\nexcept IOError as e:\n    print(f\"Failed to write file: {e}\")\n\ntry:\n    context.convert_to_coreml(graph, \"model.mlmodel\")\nexcept RuntimeError as e:\n    print(f\"Conversion failed: {e}\")\n</code></pre> <p>Common exceptions: - <code>ValueError</code>: Invalid graph structure or parameters - <code>IOError</code>: File I/O errors - <code>RuntimeError</code>: Conversion or execution failures</p>"},{"location":"examples/","title":"Examples","text":"<p>Practical examples demonstrating the WebNN Python API.</p>"},{"location":"examples/#basic-examples","title":"Basic Examples","text":""},{"location":"examples/#simple-addition","title":"Simple Addition","text":"<pre><code>import webnn\nimport numpy as np\n\n# Create context and builder\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = context.create_graph_builder()\n\n# Define computation: z = x + y\nx = builder.input(\"x\", [2, 3], \"float32\")\ny = builder.input(\"y\", [2, 3], \"float32\")\nz = builder.add(x, y)\n\n# Compile and export\ngraph = builder.build({\"z\": z})\ncontext.convert_to_onnx(graph, \"add.onnx\")\nprint(\"\u2713 Simple addition graph exported\")\n</code></pre>"},{"location":"examples/#relu-activation","title":"ReLU Activation","text":"<pre><code>import webnn\n\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = context.create_graph_builder()\n\n# Apply ReLU to input\nx = builder.input(\"x\", [10], \"float32\")\ny = builder.relu(x)\n\ngraph = builder.build({\"y\": y})\ncontext.convert_to_onnx(graph, \"relu.onnx\")\n</code></pre>"},{"location":"examples/#intermediate-examples","title":"Intermediate Examples","text":""},{"location":"examples/#linear-layer","title":"Linear Layer","text":"<p>A simple fully-connected layer: <code>output = input @ weights + bias</code></p> <pre><code>import webnn\nimport numpy as np\n\ndef create_linear_layer(builder, input_op, in_features, out_features):\n    \"\"\"Creates a linear layer with random initialization.\"\"\"\n\n    # Create weight matrix [in_features, out_features]\n    weights = np.random.randn(in_features, out_features).astype('float32') * 0.01\n    weights_op = builder.constant(weights)\n\n    # Create bias vector [out_features]\n    bias = np.zeros(out_features, dtype='float32')\n    bias_op = builder.constant(bias)\n\n    # Compute: output = input @ weights + bias\n    matmul_result = builder.matmul(input_op, weights_op)\n    output = builder.add(matmul_result, bias_op)\n\n    return output\n\n# Use the linear layer\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = context.create_graph_builder()\n\n# Input: batch_size=1, features=784 (e.g., flattened 28x28 image)\ninput_tensor = builder.input(\"input\", [1, 784], \"float32\")\n\n# Linear layer: 784 -&gt; 10 (e.g., for digit classification)\noutput = create_linear_layer(builder, input_tensor, 784, 10)\n\n# Compile and export\ngraph = builder.build({\"output\": output})\ncontext.convert_to_onnx(graph, \"linear_layer.onnx\")\n\nprint(f\"Linear layer: {graph.operand_count} operands, {graph.operation_count} operations\")\n</code></pre>"},{"location":"examples/#multi-layer-network","title":"Multi-Layer Network","text":"<pre><code>import webnn\nimport numpy as np\n\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = context.create_graph_builder()\n\n# Input layer\ninput_tensor = builder.input(\"input\", [1, 784], \"float32\")\n\n# Hidden layer 1: 784 -&gt; 128\nw1 = builder.constant(np.random.randn(784, 128).astype('float32') * 0.01)\nb1 = builder.constant(np.zeros(128, dtype='float32'))\nhidden1 = builder.matmul(input_tensor, w1)\nhidden1 = builder.add(hidden1, b1)\nhidden1 = builder.relu(hidden1)\n\n# Hidden layer 2: 128 -&gt; 64\nw2 = builder.constant(np.random.randn(128, 64).astype('float32') * 0.01)\nb2 = builder.constant(np.zeros(64, dtype='float32'))\nhidden2 = builder.matmul(hidden1, w2)\nhidden2 = builder.add(hidden2, b2)\nhidden2 = builder.relu(hidden2)\n\n# Output layer: 64 -&gt; 10\nw3 = builder.constant(np.random.randn(64, 10).astype('float32') * 0.01)\nb3 = builder.constant(np.zeros(10, dtype='float32'))\noutput = builder.matmul(hidden2, w3)\noutput = builder.add(output, b3)\n\n# Compile\ngraph = builder.build({\"logits\": output})\ncontext.convert_to_onnx(graph, \"mlp.onnx\")\n\nprint(f\"Multi-layer network compiled:\")\nprint(f\"  Operands: {graph.operand_count}\")\nprint(f\"  Operations: {graph.operation_count}\")\n</code></pre>"},{"location":"examples/#advanced-examples","title":"Advanced Examples","text":""},{"location":"examples/#multiple-outputs","title":"Multiple Outputs","text":"<p>Create a graph with multiple outputs:</p> <pre><code>import webnn\n\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = context.create_graph_builder()\n\n# Input\nx = builder.input(\"x\", [1, 10], \"float32\")\n\n# Multiple transformations\nrelu_out = builder.relu(x)\nsigmoid_out = builder.sigmoid(x)\ntanh_out = builder.tanh(x)\n\n# Build with multiple named outputs\ngraph = builder.build({\n    \"relu\": relu_out,\n    \"sigmoid\": sigmoid_out,\n    \"tanh\": tanh_out\n})\n\n# Check outputs\nprint(\"Outputs:\", graph.get_output_names())\n# Output: ['relu', 'sigmoid', 'tanh']\n\ncontext.convert_to_onnx(graph, \"multi_output.onnx\")\n</code></pre>"},{"location":"examples/#working-with-different-data-types","title":"Working with Different Data Types","text":"<pre><code>import webnn\nimport numpy as np\n\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = context.create_graph_builder()\n\n# Float16 for reduced memory\nx_fp16 = builder.input(\"x_fp16\", [100, 100], \"float16\")\ny_fp16 = builder.relu(x_fp16)\n\n# Int8 for quantized models\nx_int8 = builder.input(\"x_int8\", [100, 100], \"int8\")\n# Note: Quantized operations would need appropriate scaling\n\n# Float32 (default)\nx_fp32 = builder.input(\"x_fp32\", [100, 100], \"float32\")\ny_fp32 = builder.relu(x_fp32)\n\ngraph = builder.build({\n    \"out_fp16\": y_fp16,\n    \"out_fp32\": y_fp32\n})\n\nprint(f\"Graph with mixed precision: {graph.operand_count} operands\")\n</code></pre>"},{"location":"examples/#reshaping-tensors","title":"Reshaping Tensors","text":"<pre><code>import webnn\n\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = context.create_graph_builder()\n\n# Flatten image: [1, 28, 28, 1] -&gt; [1, 784]\nimage = builder.input(\"image\", [1, 28, 28, 1], \"float32\")\nflattened = builder.reshape(image, [1, 784])\n\n# Unflatten back: [1, 784] -&gt; [1, 28, 28, 1]\nunflattened = builder.reshape(flattened, [1, 28, 28, 1])\n\ngraph = builder.build({\"output\": unflattened})\ncontext.convert_to_onnx(graph, \"reshape.onnx\")\n</code></pre>"},{"location":"examples/#converting-pre-trained-numpy-weights","title":"Converting Pre-trained NumPy Weights","text":"<pre><code>import webnn\nimport numpy as np\n\ndef convert_numpy_model_to_webnn(weights_dict):\n    \"\"\"\n    Convert a model with NumPy weights to WebNN graph.\n\n    Args:\n        weights_dict: Dictionary with keys like 'fc1.weight', 'fc1.bias', etc.\n    \"\"\"\n    ml = webnn.ML()\n    context = ml.create_context()\n    builder = context.create_graph_builder()\n\n    # Input\n    x = builder.input(\"input\", [1, 784], \"float32\")\n\n    # Layer 1\n    w1 = builder.constant(weights_dict['fc1.weight'].astype('float32'))\n    b1 = builder.constant(weights_dict['fc1.bias'].astype('float32'))\n    h1 = builder.matmul(x, w1)\n    h1 = builder.add(h1, b1)\n    h1 = builder.relu(h1)\n\n    # Layer 2\n    w2 = builder.constant(weights_dict['fc2.weight'].astype('float32'))\n    b2 = builder.constant(weights_dict['fc2.bias'].astype('float32'))\n    output = builder.matmul(h1, w2)\n    output = builder.add(output, b2)\n\n    # Build and export\n    graph = builder.build({\"logits\": output})\n    context.convert_to_onnx(graph, \"converted_model.onnx\")\n\n    return graph\n\n# Example usage\nweights = {\n    'fc1.weight': np.random.randn(784, 128),\n    'fc1.bias': np.zeros(128),\n    'fc2.weight': np.random.randn(128, 10),\n    'fc2.bias': np.zeros(10),\n}\n\ngraph = convert_numpy_model_to_webnn(weights)\nprint(f\"\u2713 Converted model: {graph.operation_count} operations\")\n</code></pre>"},{"location":"examples/#error-handling-examples","title":"Error Handling Examples","text":""},{"location":"examples/#graceful-error-handling","title":"Graceful Error Handling","text":"<pre><code>import webnn\nimport numpy as np\n\ndef build_and_export_safely(output_path):\n    \"\"\"Build a graph with proper error handling.\"\"\"\n    try:\n        ml = webnn.ML()\n        context = ml.create_context()\n        builder = context.create_graph_builder()\n\n        x = builder.input(\"x\", [10], \"float32\")\n        y = builder.relu(x)\n\n        graph = builder.build({\"y\": y})\n\n        # Try ONNX conversion\n        try:\n            context.convert_to_onnx(graph, output_path)\n            print(f\"\u2713 ONNX model saved to {output_path}\")\n            return True\n        except IOError as e:\n            print(f\"\u2717 Failed to save ONNX: {e}\")\n            return False\n\n    except ValueError as e:\n        print(f\"\u2717 Graph validation failed: {e}\")\n        return False\n    except Exception as e:\n        print(f\"\u2717 Unexpected error: {e}\")\n        return False\n\n# Use it\nsuccess = build_and_export_safely(\"model.onnx\")\n</code></pre>"},{"location":"examples/#validating-shapes","title":"Validating Shapes","text":"<pre><code>import webnn\nimport numpy as np\n\ndef create_safe_matmul(builder, a_shape, b_shape):\n    \"\"\"Create matmul with shape validation.\"\"\"\n    if len(a_shape) != 2 or len(b_shape) != 2:\n        raise ValueError(\"matmul requires 2D tensors\")\n\n    if a_shape[1] != b_shape[0]:\n        raise ValueError(\n            f\"Incompatible shapes for matmul: \"\n            f\"{a_shape} and {b_shape}\"\n        )\n\n    a = builder.input(\"a\", a_shape, \"float32\")\n    b_data = np.random.randn(*b_shape).astype('float32')\n    b = builder.constant(b_data)\n\n    result = builder.matmul(a, b)\n    return result\n\nml = webnn.ML()\ncontext = ml.create_context()\nbuilder = context.create_graph_builder()\n\ntry:\n    # Valid\n    output = create_safe_matmul(builder, [10, 20], [20, 30])\n    print(\"\u2713 Valid matmul created\")\n\n    # Invalid - will raise error\n    output = create_safe_matmul(builder, [10, 20], [15, 30])\nexcept ValueError as e:\n    print(f\"\u2717 Shape validation failed: {e}\")\n</code></pre>"},{"location":"examples/#complete-application-example","title":"Complete Application Example","text":""},{"location":"examples/#image-classification-pipeline","title":"Image Classification Pipeline","text":"<pre><code>import webnn\nimport numpy as np\n\nclass SimpleClassifier:\n    \"\"\"A simple image classifier using WebNN.\"\"\"\n\n    def __init__(self, num_classes=10):\n        self.ml = webnn.ML()\n        self.context = self.ml.create_context()\n        self.graph = None\n        self.num_classes = num_classes\n\n    def build_model(self):\n        \"\"\"Build the classification model.\"\"\"\n        builder = self.context.create_graph_builder()\n\n        # Input: 28x28 grayscale images\n        input_tensor = builder.input(\"image\", [1, 28, 28, 1], \"float32\")\n\n        # Flatten\n        x = builder.reshape(input_tensor, [1, 784])\n\n        # Hidden layer\n        w1 = builder.constant(np.random.randn(784, 128).astype('float32') * 0.01)\n        b1 = builder.constant(np.zeros(128, dtype='float32'))\n        x = builder.matmul(x, w1)\n        x = builder.add(x, b1)\n        x = builder.relu(x)\n\n        # Output layer\n        w2 = builder.constant(np.random.randn(128, self.num_classes).astype('float32') * 0.01)\n        b2 = builder.constant(np.zeros(self.num_classes, dtype='float32'))\n        logits = builder.matmul(x, w2)\n        logits = builder.add(logits, b2)\n\n        # Softmax\n        output = builder.softmax(logits)\n\n        # Build\n        self.graph = builder.build({\"probabilities\": output})\n        print(f\"\u2713 Model built: {self.graph.operation_count} operations\")\n\n    def export(self, path=\"classifier.onnx\"):\n        \"\"\"Export the model to ONNX.\"\"\"\n        if self.graph is None:\n            raise RuntimeError(\"Build model first!\")\n\n        self.context.convert_to_onnx(self.graph, path)\n        print(f\"\u2713 Model exported to {path}\")\n\n    def get_info(self):\n        \"\"\"Get model information.\"\"\"\n        if self.graph is None:\n            return \"Model not built yet\"\n\n        return {\n            \"operands\": self.graph.operand_count,\n            \"operations\": self.graph.operation_count,\n            \"inputs\": self.graph.get_input_names(),\n            \"outputs\": self.graph.get_output_names(),\n        }\n\n# Use the classifier\nclassifier = SimpleClassifier(num_classes=10)\nclassifier.build_model()\nclassifier.export(\"mnist_classifier.onnx\")\n\nprint(\"\\nModel Info:\")\nfor key, value in classifier.get_info().items():\n    print(f\"  {key}: {value}\")\n</code></pre> <p>This comprehensive set of examples should help you get started with various use cases!</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will help you get started with the WebNN Python API.</p>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8 or later</li> <li>Rust toolchain (for building from source)</li> <li>NumPy (automatically installed as a dependency)</li> </ul>"},{"location":"getting-started/#building-from-source","title":"Building from Source","text":"<ol> <li> <p>Install Rust (if not already installed):    <pre><code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n</code></pre></p> </li> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/your-org/rust-webnn-graph.git\ncd rust-webnn-graph\n</code></pre></p> </li> <li> <p>Install maturin:    <pre><code>pip install maturin\n</code></pre></p> </li> <li> <p>Build and install:    <pre><code># Development mode (editable install)\nmaturin develop --features python\n\n# Or build a release wheel\nmaturin build --release --features python\npip install target/wheels/webnn-*.whl\n</code></pre></p> </li> </ol>"},{"location":"getting-started/#optional-features","title":"Optional Features","text":"<p>Build with additional runtime support:</p> <pre><code># With ONNX runtime support\nmaturin develop --features python,onnx-runtime\n\n# With CoreML runtime support (macOS only)\nmaturin develop --features python,coreml-runtime\n\n# With all features\nmaturin develop --features python,onnx-runtime,coreml-runtime\n</code></pre>"},{"location":"getting-started/#your-first-graph","title":"Your First Graph","text":"<p>Let's build a simple computational graph that adds two tensors and applies ReLU activation.</p>"},{"location":"getting-started/#step-1-import-and-setup","title":"Step 1: Import and Setup","text":"<pre><code>import webnn\nimport numpy as np\n\n# Create the ML namespace and context\nml = webnn.ML()\ncontext = ml.create_context(device_type=\"cpu\", power_preference=\"default\")\n</code></pre> <p>The <code>MLContext</code> represents the execution environment. You can specify: - <code>device_type</code>: \"cpu\", \"gpu\", or \"npu\" - <code>power_preference</code>: \"default\", \"high-performance\", or \"low-power\"</p>"},{"location":"getting-started/#step-2-create-a-graph-builder","title":"Step 2: Create a Graph Builder","text":"<pre><code># Create a graph builder\nbuilder = context.create_graph_builder()\n</code></pre> <p>The graph builder is used to construct computational graphs using a declarative API.</p>"},{"location":"getting-started/#step-3-define-inputs","title":"Step 3: Define Inputs","text":"<pre><code># Define two input operands\nx = builder.input(\"x\", [2, 3], \"float32\")\ny = builder.input(\"y\", [2, 3], \"float32\")\n</code></pre> <p>Each input has: - A name for identification - A shape (list of dimensions) - A data type (\"float32\", \"float16\", \"int32\", etc.)</p>"},{"location":"getting-started/#step-4-build-operations","title":"Step 4: Build Operations","text":"<pre><code># Add the inputs\nsum_result = builder.add(x, y)\n\n# Apply ReLU activation\noutput = builder.relu(sum_result)\n</code></pre> <p>Operations are chained to build the computational graph.</p>"},{"location":"getting-started/#step-5-compile-the-graph","title":"Step 5: Compile the Graph","text":"<pre><code># Compile the graph with named outputs\ngraph = builder.build({\"output\": output})\n\n# Inspect the compiled graph\nprint(f\"Graph has {graph.operand_count} operands\")\nprint(f\"Graph has {graph.operation_count} operations\")\nprint(f\"Inputs: {graph.get_input_names()}\")\nprint(f\"Outputs: {graph.get_output_names()}\")\n</code></pre> <p>The <code>build()</code> method: - Validates the graph structure - Returns a compiled <code>MLGraph</code> object - Takes a dictionary mapping output names to operands</p>"},{"location":"getting-started/#step-6-convert-to-other-formats","title":"Step 6: Convert to Other Formats","text":"<pre><code># Convert to ONNX\ncontext.convert_to_onnx(graph, \"my_model.onnx\")\nprint(\"\u2713 ONNX model saved\")\n\n# Convert to CoreML (macOS only, basic operations)\ntry:\n    context.convert_to_coreml(graph, \"my_model.mlmodel\")\n    print(\"\u2713 CoreML model saved\")\nexcept Exception as e:\n    print(f\"CoreML conversion: {e}\")\n</code></pre>"},{"location":"getting-started/#complete-example","title":"Complete Example","text":"<p>Here's the complete code:</p> <pre><code>import webnn\nimport numpy as np\n\ndef main():\n    # Setup\n    ml = webnn.ML()\n    context = ml.create_context(device_type=\"cpu\")\n    builder = context.create_graph_builder()\n\n    # Build graph\n    x = builder.input(\"x\", [2, 3], \"float32\")\n    y = builder.input(\"y\", [2, 3], \"float32\")\n    sum_result = builder.add(x, y)\n    output = builder.relu(sum_result)\n\n    # Compile\n    graph = builder.build({\"output\": output})\n\n    # Export\n    context.convert_to_onnx(graph, \"model.onnx\")\n\n    print(f\"\u2713 Graph compiled: {graph.operand_count} operands, \"\n          f\"{graph.operation_count} operations\")\n    print(f\"\u2713 Model exported to model.onnx\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about all available operations in the API Reference</li> <li>Explore more complex examples in Examples</li> <li>Read about advanced topics in Advanced Topics</li> </ul>"},{"location":"getting-started/#common-issues","title":"Common Issues","text":""},{"location":"getting-started/#import-error","title":"Import Error","text":"<p>If you get <code>ModuleNotFoundError: No module named 'webnn'</code>: - Make sure you ran <code>maturin develop</code> successfully - Verify you're using the correct Python environment</p>"},{"location":"getting-started/#build-errors","title":"Build Errors","text":"<p>If maturin build fails: - Ensure Rust is installed: <code>rustc --version</code> - Update maturin: <code>pip install -U maturin</code> - Check that you have the required features: <code>cargo check --features python</code></p>"},{"location":"getting-started/#numpy-compatibility","title":"NumPy Compatibility","text":"<p>The library requires NumPy &gt;= 1.20.0. Update if needed: <pre><code>pip install -U numpy\n</code></pre></p>"}]}