# Bibliography

This bibliography provides references for deeper study of the mathematical concepts covered in PyDelt's theory documentation.

---

## Foundational Calculus Texts

### For Intuition and Accessibility

1. **Strang, G.** (2010). *Calculus*. Wellesley-Cambridge Press.
   - **Why read it**: Free online, excellent visualizations, focuses on understanding over formalism.
   - **Best for**: Building intuition, seeing connections between concepts.
   - **Access**: [MIT OpenCourseWare](https://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010/)

2. **Thompson, S. P.** (1914). *Calculus Made Easy*. Macmillan.
   - **Why read it**: Classic text, remarkably accessible, still relevant after 100+ years.
   - **Best for**: Absolute beginners, those intimidated by math.
   - **Access**: Public domain, freely available online.

### For Rigor

3. **Spivak, M.** (2008). *Calculus* (4th ed.). Publish or Perish.
   - **Why read it**: Rigorous but readable, beautiful proofs, develops mathematical maturity.
   - **Best for**: Those wanting deep understanding, future mathematicians.

4. **Apostol, T. M.** (1967). *Calculus, Vol. 1 & 2*. Wiley.
   - **Why read it**: Comprehensive reference, integrates linear algebra with calculus.
   - **Best for**: Complete coverage, reference work.

5. **Rudin, W.** (1976). *Principles of Mathematical Analysis* (3rd ed.). McGraw-Hill.
   - **Why read it**: The standard for rigorous real analysis.
   - **Best for**: Graduate-level understanding, proving theorems.

---

## Numerical Methods

6. **Press, W. H., Teukolsky, S. A., Vetterling, W. T., & Flannery, B. P.** (2007). *Numerical Recipes: The Art of Scientific Computing* (3rd ed.). Cambridge University Press.
   - **Why read it**: Practical algorithms with code, covers everything.
   - **Best for**: Implementation, understanding trade-offs.

7. **Trefethen, L. N.** (2013). *Approximation Theory and Approximation Practice*. SIAM.
   - **Why read it**: Modern treatment, connects theory to computation.
   - **Best for**: Understanding interpolation, polynomial approximation.

8. **Fornberg, B.** (1988). "Generation of Finite Difference Formulas on Arbitrarily Spaced Grids." *Mathematics of Computation*, 51(184), 699-706.
   - **Why read it**: Foundational paper for finite difference methods.
   - **Best for**: Understanding numerical differentiation.

---

## Machine Learning and Deep Learning

9. **Goodfellow, I., Bengio, Y., & Courville, A.** (2016). *Deep Learning*. MIT Press.
   - **Why read it**: The standard deep learning textbook, Chapter 4 covers numerical computation.
   - **Best for**: Connecting calculus to neural networks.
   - **Access**: [deeplearningbook.org](https://www.deeplearningbook.org/)

10. **Boyd, S., & Vandenberghe, L.** (2004). *Convex Optimization*. Cambridge University Press.
    - **Why read it**: Foundational for understanding optimization, gradients, Hessians.
    - **Best for**: Optimization theory, understanding gradient descent.
    - **Access**: [stanford.edu/~boyd/cvxbook](https://web.stanford.edu/~boyd/cvxbook/)

11. **Baydin, A. G., Pearlmutter, B. A., Radul, A. A., & Siskind, J. M.** (2018). "Automatic Differentiation in Machine Learning: A Survey." *Journal of Machine Learning Research*, 18(153), 1-43.
    - **Why read it**: Comprehensive survey of autodiff, the foundation of modern deep learning.
    - **Best for**: Understanding how PyTorch/TensorFlow compute gradients.

---

## Functional Data Analysis

12. **Ramsay, J. O., & Silverman, B. W.** (2005). *Functional Data Analysis* (2nd ed.). Springer.
    - **Why read it**: The definitive text on FDA, basis for PyDelt's FDA methods.
    - **Best for**: Understanding spline smoothing, functional representations.

13. **Ramsay, J. O., Hooker, G., & Graves, S.** (2009). *Functional Data Analysis with R and MATLAB*. Springer.
    - **Why read it**: Practical implementation of FDA concepts.
    - **Best for**: Hands-on FDA work.

---

## Splines and Interpolation

14. **de Boor, C.** (2001). *A Practical Guide to Splines* (Revised ed.). Springer.
    - **Why read it**: The authoritative reference on splines.
    - **Best for**: Deep understanding of spline mathematics.

15. **Wahba, G.** (1990). *Spline Models for Observational Data*. SIAM.
    - **Why read it**: Connects splines to statistics, optimal smoothing.
    - **Best for**: Understanding smoothing parameter selection.

---

## Local Regression Methods

16. **Cleveland, W. S.** (1979). "Robust Locally Weighted Regression and Smoothing Scatterplots." *Journal of the American Statistical Association*, 74(368), 829-836.
    - **Why read it**: Original LOWESS paper.
    - **Best for**: Understanding the method PyDelt implements.

17. **Fan, J., & Gijbels, I.** (1996). *Local Polynomial Modelling and Its Applications*. Chapman & Hall.
    - **Why read it**: Comprehensive treatment of local polynomial regression.
    - **Best for**: Understanding LLA-type methods.

---

## Physics-Informed Machine Learning

18. **Raissi, M., Perdikaris, P., & Karniadakis, G. E.** (2019). "Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations." *Journal of Computational Physics*, 378, 686-707.
    - **Why read it**: Foundational PINN paper.
    - **Best for**: Understanding physics-informed approaches.

19. **Chen, R. T. Q., Rubanova, Y., Bettencourt, J., & Duvenaud, D.** (2018). "Neural Ordinary Differential Equations." *Advances in Neural Information Processing Systems*, 31.
    - **Why read it**: Introduced Neural ODEs.
    - **Best for**: Understanding continuous-depth networks.

---

## Stochastic Calculus

20. **Øksendal, B.** (2003). *Stochastic Differential Equations: An Introduction with Applications* (6th ed.). Springer.
    - **Why read it**: Accessible introduction to SDEs.
    - **Best for**: Understanding Itô calculus, financial applications.

21. **Kloeden, P. E., & Platen, E.** (1992). *Numerical Solution of Stochastic Differential Equations*. Springer.
    - **Why read it**: Comprehensive treatment of numerical methods for SDEs.
    - **Best for**: Implementation of stochastic methods.

---

## Complex Analysis

22. **Needham, T.** (1997). *Visual Complex Analysis*. Oxford University Press.
    - **Why read it**: Beautiful, geometric approach to complex analysis.
    - **Best for**: Building intuition, seeing the geometry.

23. **Ahlfors, L. V.** (1979). *Complex Analysis* (3rd ed.). McGraw-Hill.
    - **Why read it**: Standard graduate text.
    - **Best for**: Rigorous treatment.

---

## Multivariate Calculus

24. **Marsden, J. E., & Tromba, A.** (2011). *Vector Calculus* (6th ed.). W. H. Freeman.
    - **Why read it**: Clear treatment of gradients, Jacobians, Hessians.
    - **Best for**: Multivariate calculus foundations.

25. **Hubbard, J. H., & Hubbard, B. B.** (2015). *Vector Calculus, Linear Algebra, and Differential Forms* (5th ed.). Matrix Editions.
    - **Why read it**: Unified treatment, connects to differential geometry.
    - **Best for**: Deeper understanding of multivariate calculus.

---

## Online Resources

### Video Courses

26. **3Blue1Brown** - "Essence of Calculus" (YouTube)
    - Beautiful visualizations, builds intuition.
    - [youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)

27. **MIT OpenCourseWare** - 18.01 Single Variable Calculus
    - Full course with lectures, notes, problem sets.
    - [ocw.mit.edu](https://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010/)

28. **Stanford CS231n** - Convolutional Neural Networks
    - Excellent backpropagation explanation.
    - [cs231n.github.io](https://cs231n.github.io/)

### Interactive Tools

29. **Desmos** - Graphing Calculator
    - Visualize functions and derivatives.
    - [desmos.com/calculator](https://www.desmos.com/calculator)

30. **GeoGebra** - Dynamic Mathematics
    - Interactive calculus visualizations.
    - [geogebra.org](https://www.geogebra.org/)

---

## How to Use This Bibliography

### If you're new to calculus:
Start with Thompson's *Calculus Made Easy* or 3Blue1Brown videos, then move to Strang.

### If you want rigorous foundations:
Work through Spivak, then Rudin for analysis.

### If you're focused on ML applications:
Read Goodfellow et al. Chapter 4, then Baydin et al. on autodiff.

### If you're implementing numerical methods:
*Numerical Recipes* is your reference, supplemented by Trefethen.

### If you're working with time series:
Ramsay & Silverman for FDA, Cleveland for LOWESS.

### If you're doing physics-informed ML:
Start with Raissi et al., then Chen et al. for Neural ODEs.

---

*Back to: [Theory Index](index.md)*
