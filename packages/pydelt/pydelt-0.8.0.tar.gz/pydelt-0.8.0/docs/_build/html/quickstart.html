

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Quick Start Guide &mdash; pydelt 0.7.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=5a057da9"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Theory: Calculus for ML" href="theory_index.html" />
    <link rel="prev" title="Installation" href="installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            pydelt
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Start Here:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Quick Start Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#universal-api-pattern">üöÄ <strong>Universal API Pattern</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="#level-1-basic-interpolation"><strong>Level 1: Basic Interpolation</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="#level-2-neural-networks-automatic-differentiation"><strong>Level 2: Neural Networks &amp; Automatic Differentiation</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="#level-3-multivariate-calculus"><strong>Level 3: Multivariate Calculus</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="#level-4-stochastic-computing-new-feature"><strong>Level 4: Stochastic Computing</strong> ‚≠ê <em>New Feature</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="#important-considerations">‚ö†Ô∏è <strong>Important Considerations</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="#progressive-learning-path">üéì <strong>Progressive Learning Path</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="#next-steps">üîó <strong>Next Steps</strong></a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Mathematical Foundations:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="theory_index.html">Theory: Calculus for ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="theory.html">Mathematical Theory</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Master the Methods:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="basic_interpolation.html">Basic Interpolation &amp; Derivatives</a></li>
<li class="toctree-l1"><a class="reference internal" href="neural_networks.html">Neural Networks &amp; Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="multivariate_calculus.html">Multivariate Calculus &amp; Vector Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="stochastic_computing.html">Stochastic Computing &amp; Probabilistic Derivatives</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference &amp; Help:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="visual_examples.html">Visual Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_comparison.html">Feature Comparison Matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">pydelt</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Quick Start Guide</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/quickstart.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="quick-start-guide">
<h1>Quick Start Guide<a class="headerlink" href="#quick-start-guide" title="Link to this heading">ÔÉÅ</a></h1>
<p>This guide introduces pydelt‚Äôs progressive feature set, from basic interpolation to advanced stochastic computing. Follow the examples below to get started quickly.</p>
<section id="universal-api-pattern">
<h2>üöÄ <strong>Universal API Pattern</strong><a class="headerlink" href="#universal-api-pattern" title="Link to this heading">ÔÉÅ</a></h2>
<p>All pydelt interpolators follow the same consistent interface:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Universal pattern for all methods</span>
<span class="n">interpolator</span> <span class="o">=</span> <span class="n">InterpolatorClass</span><span class="p">(</span><span class="o">**</span><span class="n">parameters</span><span class="p">)</span>
<span class="n">interpolator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">output_data</span><span class="p">)</span>
<span class="n">derivative_func</span> <span class="o">=</span> <span class="n">interpolator</span><span class="o">.</span><span class="n">differentiate</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">derivatives</span> <span class="o">=</span> <span class="n">derivative_func</span><span class="p">(</span><span class="n">evaluation_points</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="level-1-basic-interpolation">
<h2><strong>Level 1: Basic Interpolation</strong><a class="headerlink" href="#level-1-basic-interpolation" title="Link to this heading">ÔÉÅ</a></h2>
<p>Start with classical interpolation methods:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydelt.interpolation</span><span class="w"> </span><span class="kn">import</span> <span class="n">SplineInterpolator</span><span class="p">,</span> <span class="n">LlaInterpolator</span>

<span class="c1"># Create sample data: f(t) = sin(t)</span>
<span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">signal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">time</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">time</span><span class="p">))</span>  <span class="c1"># Add noise</span>

<span class="c1"># Method 1: Spline interpolation (best for smooth data)</span>
<span class="n">spline</span> <span class="o">=</span> <span class="n">SplineInterpolator</span><span class="p">(</span><span class="n">smoothing</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">spline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">signal</span><span class="p">)</span>
<span class="n">spline_deriv_func</span> <span class="o">=</span> <span class="n">spline</span><span class="o">.</span><span class="n">differentiate</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">spline_derivatives</span> <span class="o">=</span> <span class="n">spline_deriv_func</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>

<span class="c1"># Method 2: Local Linear Approximation (efficient, robust)</span>
<span class="n">lla</span> <span class="o">=</span> <span class="n">LlaInterpolator</span><span class="p">(</span><span class="n">window_size</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">lla</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">signal</span><span class="p">)</span>
<span class="n">lla_deriv_func</span> <span class="o">=</span> <span class="n">lla</span><span class="o">.</span><span class="n">differentiate</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">lla_derivatives</span> <span class="o">=</span> <span class="n">lla_deriv_func</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>

<span class="c1"># Compare with analytical derivative</span>
<span class="n">analytical</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Spline Error: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">spline_derivatives</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">analytical</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LLA Error: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">lla_derivatives</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">analytical</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="level-2-neural-networks-automatic-differentiation">
<h2><strong>Level 2: Neural Networks &amp; Automatic Differentiation</strong><a class="headerlink" href="#level-2-neural-networks-automatic-differentiation" title="Link to this heading">ÔÉÅ</a></h2>
<p>For complex nonlinear functions with exact derivatives:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pydelt.interpolation</span><span class="w"> </span><span class="kn">import</span> <span class="n">NeuralNetworkInterpolator</span>

<span class="c1"># Neural network with automatic differentiation</span>
<span class="n">nn_interp</span> <span class="o">=</span> <span class="n">NeuralNetworkInterpolator</span><span class="p">(</span>
    <span class="n">hidden_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>
    <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.002</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;pytorch&#39;</span>
<span class="p">)</span>
<span class="n">nn_interp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">signal</span><span class="p">)</span>

<span class="c1"># Exact derivatives via backpropagation</span>
<span class="n">nn_deriv_func</span> <span class="o">=</span> <span class="n">nn_interp</span><span class="o">.</span><span class="n">differentiate</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">nn_derivatives</span> <span class="o">=</span> <span class="n">nn_deriv_func</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Neural Network Error: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">nn_derivatives</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">analytical</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="level-3-multivariate-calculus">
<h2><strong>Level 3: Multivariate Calculus</strong><a class="headerlink" href="#level-3-multivariate-calculus" title="Link to this heading">ÔÉÅ</a></h2>
<p>For functions of multiple variables:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pydelt.multivariate</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultivariateDerivatives</span>

<span class="c1"># 2D function: f(x,y) = x¬≤ + y¬≤</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">X</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">Y</span><span class="o">**</span><span class="mi">2</span>

<span class="c1"># Prepare data</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">X</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">Y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()])</span>
<span class="n">output_data</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="c1"># Fit multivariate derivatives</span>
<span class="n">mv</span> <span class="o">=</span> <span class="n">MultivariateDerivatives</span><span class="p">(</span><span class="n">SplineInterpolator</span><span class="p">,</span> <span class="n">smoothing</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">mv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">output_data</span><span class="p">)</span>

<span class="c1"># Compute gradient: ‚àáf = [2x, 2y]</span>
<span class="n">gradient_func</span> <span class="o">=</span> <span class="n">mv</span><span class="o">.</span><span class="n">gradient</span><span class="p">()</span>
<span class="n">test_point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]])</span>
<span class="n">gradient</span> <span class="o">=</span> <span class="n">gradient_func</span><span class="p">(</span><span class="n">test_point</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient at (1,1): </span><span class="si">{</span><span class="n">gradient</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> (expected: [2, 2])&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="level-4-stochastic-computing-new-feature">
<h2><strong>Level 4: Stochastic Computing</strong> ‚≠ê <em>New Feature</em><a class="headerlink" href="#level-4-stochastic-computing-new-feature" title="Link to this heading">ÔÉÅ</a></h2>
<p>For probabilistic derivatives with uncertainty quantification:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Stock price data with geometric Brownian motion</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">T</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># 1 year</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">252</span>  <span class="c1"># Daily data</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">T</span> <span class="o">/</span> <span class="n">N</span>
<span class="n">S0</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Initial price</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mf">0.05</span>  <span class="c1"># Expected return</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.2</span>  <span class="c1"># Volatility</span>

<span class="c1"># Generate stock price path</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>
<span class="n">stock_prices</span> <span class="o">=</span> <span class="n">S0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">((</span><span class="n">mu</span> <span class="o">-</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">t</span> <span class="o">+</span> <span class="n">sigma</span><span class="o">*</span><span class="n">W</span><span class="p">)</span>

<span class="c1"># Fit with stochastic link function</span>
<span class="n">stock_interp</span> <span class="o">=</span> <span class="n">SplineInterpolator</span><span class="p">(</span><span class="n">smoothing</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">stock_interp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">stock_prices</span><span class="p">)</span>

<span class="c1"># Set log-normal stochastic link (appropriate for stock prices)</span>
<span class="n">stock_interp</span><span class="o">.</span><span class="n">set_stochastic_link</span><span class="p">(</span><span class="s1">&#39;lognormal&#39;</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;ito&#39;</span><span class="p">)</span>

<span class="c1"># Compute stochastic derivatives (includes It√¥ correction)</span>
<span class="n">stochastic_deriv_func</span> <span class="o">=</span> <span class="n">stock_interp</span><span class="o">.</span><span class="n">differentiate</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">stochastic_derivatives</span> <span class="o">=</span> <span class="n">stochastic_deriv_func</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>

<span class="c1"># Compare with regular derivatives</span>
<span class="n">stock_interp_regular</span> <span class="o">=</span> <span class="n">SplineInterpolator</span><span class="p">(</span><span class="n">smoothing</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">stock_interp_regular</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">stock_prices</span><span class="p">)</span>
<span class="n">regular_deriv_func</span> <span class="o">=</span> <span class="n">stock_interp_regular</span><span class="o">.</span><span class="n">differentiate</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">regular_derivatives</span> <span class="o">=</span> <span class="n">regular_deriv_func</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>

<span class="n">correction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">stochastic_derivatives</span> <span class="o">-</span> <span class="n">regular_derivatives</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Stochastic correction: </span><span class="si">{</span><span class="n">correction</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical drift (ŒºS): </span><span class="si">{</span><span class="n">mu</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">stock_prices</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="important-considerations">
<h2>‚ö†Ô∏è <strong>Important Considerations</strong><a class="headerlink" href="#important-considerations" title="Link to this heading">ÔÉÅ</a></h2>
<p><strong>Numerical Limitations</strong>: Interpolation-based methods can smooth critical points and sharp features. This affects:</p>
<ul class="simple">
<li><p>Optimization landscape analysis (finding exact minima/maxima)</p></li>
<li><p>Bifurcation detection in dynamical systems</p></li>
<li><p>Phase transition identification</p></li>
<li><p>Sharp boundary detection</p></li>
</ul>
<p><strong>Mitigation Strategies</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Increase data resolution</strong> in critical regions</p></li>
<li><p><strong>Reduce smoothing parameters</strong> (trade-off with noise sensitivity)</p></li>
<li><p><strong>Use neural networks</strong> for exact automatic differentiation</p></li>
<li><p><strong>Validate against analytical solutions</strong> when available</p></li>
<li><p><strong>Apply domain knowledge</strong> for result interpretation</p></li>
</ol>
<p><strong>Method Selection for Critical Applications</strong>:</p>
<ul class="simple">
<li><p><strong>Exact derivatives needed</strong>: <code class="docutils literal notranslate"><span class="pre">NeuralNetworkInterpolator</span></code> with automatic differentiation</p></li>
<li><p><strong>Optimization problems</strong>: Low smoothing + validation</p></li>
<li><p><strong>Noisy data</strong>: <code class="docutils literal notranslate"><span class="pre">LowessInterpolator</span></code> with appropriate <code class="docutils literal notranslate"><span class="pre">frac</span></code> parameter</p></li>
<li><p><strong>Financial modeling</strong>: Stochastic link functions for proper risk assessment</p></li>
</ul>
</section>
<section id="progressive-learning-path">
<h2>üéì <strong>Progressive Learning Path</strong><a class="headerlink" href="#progressive-learning-path" title="Link to this heading">ÔÉÅ</a></h2>
<p>Follow this sequence to master pydelt:</p>
<ol class="arabic simple">
<li><p><strong>Start with Basic Interpolation</strong>: Master splines, LLA, and LOWESS for fundamental understanding</p></li>
<li><p><strong>Advance to Neural Networks</strong>: Learn automatic differentiation for complex nonlinear functions</p></li>
<li><p><strong>Explore Multivariate Calculus</strong>: Compute gradients, Jacobians, and Hessians for optimization</p></li>
<li><p><strong>Master Stochastic Computing</strong>: Apply probabilistic derivatives for uncertainty quantification</p></li>
</ol>
<p><strong>Quick Method Selection Guide</strong>:</p>
<ul class="simple">
<li><p><strong>Clean, smooth data</strong>: <code class="docutils literal notranslate"><span class="pre">SplineInterpolator</span></code></p></li>
<li><p><strong>Noisy data with outliers</strong>: <code class="docutils literal notranslate"><span class="pre">LowessInterpolator</span></code></p></li>
<li><p><strong>Complex nonlinear functions</strong>: <code class="docutils literal notranslate"><span class="pre">NeuralNetworkInterpolator</span></code></p></li>
<li><p><strong>Multiple variables</strong>: <code class="docutils literal notranslate"><span class="pre">MultivariateDerivatives</span></code></p></li>
<li><p><strong>Financial/risk modeling</strong>: Add stochastic link functions</p></li>
<li><p><strong>High precision needed</strong>: <code class="docutils literal notranslate"><span class="pre">GllaInterpolator</span></code></p></li>
</ul>
</section>
<section id="next-steps">
<h2>üîó <strong>Next Steps</strong><a class="headerlink" href="#next-steps" title="Link to this heading">ÔÉÅ</a></h2>
<p>Explore the progressive learning path:</p>
<ul class="simple">
<li><p><strong>Basic Interpolation</strong>: Master fundamental methods and universal API</p></li>
<li><p><strong>Neural Networks</strong>: Learn automatic differentiation and deep learning integration</p></li>
<li><p><strong>Multivariate Calculus</strong>: Compute gradients, Jacobians, and tensor operations</p></li>
<li><p><strong>Stochastic Computing</strong>: Apply probabilistic derivatives for uncertainty quantification</p></li>
</ul>
<p>Each section builds on the previous, providing a complete framework for numerical differentiation from basic applications to cutting-edge research.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="theory_index.html" class="btn btn-neutral float-right" title="Theory: Calculus for ML" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Michael Harrison Lee.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>