{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa690b8b",
   "metadata": {},
   "source": [
    "# Deep Q-Learning (DQN) – Explained\n",
    "\n",
    "## Online Reinforcement Learning\n",
    "\n",
    "Online RL refers to learning that happens as the agent interacts with the environment — in real-time. In other words:\n",
    "\n",
    "- The agent updates its model or policy immediately after each new experience.\n",
    "- No full dataset is available in advance (unlike supervised learning).\n",
    "- The environment is often stochastic and partially unknown.\n",
    "\n",
    "DQN is a classic example of online RL, because it:\n",
    "- Learns from new interactions step-by-step.\n",
    "- Continuously updates its estimates of action values \\( Q(s, a) \\).\n",
    "- Balances exploration (trying new things) and exploitation (using what it knows).\n",
    "\n",
    "---\n",
    "\n",
    "## What is Deep Q-Learning?\n",
    "\n",
    "Deep Q-Learning (DQN) is an online RL algorithm that combines:\n",
    "- Q-learning: a value-based method that learns the function \\( Q(s, a) \\)\n",
    "- With a deep neural network to approximate that function when the state space is too large or continuous\n",
    "\n",
    "---\n",
    "\n",
    "## Objective of DQN\n",
    "\n",
    "The goal is to learn:\n",
    "\n",
    "$$\n",
    "Q^*(s, a) = \\mathbb{E}\\left[ r + \\gamma \\cdot \\max_{a'} Q^*(s', a') \\right]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $r$: reward  \n",
    "- $\\gamma$: discount factor  \n",
    "- $s'$: next state  \n",
    "- $a'$: next action  \n",
    "\n",
    "---\n",
    "\n",
    "## Components of a DQN\n",
    "\n",
    "### 1. Experience Replay\n",
    "\n",
    "- Stores transitions: $ (s, a, r, s', \\text{done}) $ in a buffer  \n",
    "- Random mini-batches are sampled for training  \n",
    "- Breaks correlations and improves stability\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Components of a DQN\n",
    "\n",
    "### 1. Experience Replay\n",
    "\n",
    "- Stores transitions: $ (s, a, r, s', \\text{done}) $ in a buffer\n",
    "- Random mini-batches are sampled for training\n",
    "- Breaks correlations and improves stability\n",
    "\n",
    "### 2. Target Network\n",
    "\n",
    "- A copy of the Q-network, used to compute learning targets:\n",
    "\n",
    "$$\n",
    "y = r + \\gamma \\cdot \\max_{a'} Q_{\\text{target}}(s', a')\n",
    "$$\n",
    "\n",
    "- Updated less frequently to keep targets stable\n",
    "\n",
    "### 3. Epsilon-Greedy Exploration\n",
    "\n",
    "- With probability $ \\varepsilon $, take a random action (exploration)  \n",
    "- Otherwise, select the action that maximizes $ Q(s, a) $ (exploitation)  \n",
    "- $ \\varepsilon $ decays over time to shift from exploring to exploiting\n",
    "\n",
    "---\n",
    "\n",
    "## Training with Bellman Loss\n",
    "\n",
    "The network is trained using the Bellman loss:\n",
    "\n",
    "$$\n",
    "\\text{Loss} = \\left( Q(s, a) - \\left[ r + \\gamma \\cdot \\max_{a'} Q_{\\text{target}}(s', a') \\right] \\right)^2\n",
    "$$\n",
    "\n",
    "This measures the difference between predicted Q-values and expected returns — the Bellman error.\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Mnih, V., et al. (2015). *Human-level control through deep reinforcement learning*. Nature.  \n",
    "[2] DQN PyTorch implementation by johnnycode8:  \n",
    "https://github.com/johnnycode8/dqn_pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63149c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "\n",
    "from agents import DQNAgent\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c1a68",
   "metadata": {},
   "source": [
    "Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with reward: 38.0\n",
      "Episode 2 finished with reward: 17.0\n",
      "Episode 3 finished with reward: 14.0\n",
      "Episode 4 finished with reward: 13.0\n",
      "Episode 5 finished with reward: 30.0\n",
      "Episode 6 finished with reward: 13.0\n",
      "Episode 7 finished with reward: 19.0\n",
      "Episode 8 finished with reward: 11.0\n",
      "Episode 9 finished with reward: 10.0\n",
      "Episode 10 finished with reward: 13.0\n",
      "Episode 11 finished with reward: 10.0\n",
      "Episode 12 finished with reward: 13.0\n",
      "Episode 13 finished with reward: 11.0\n",
      "Episode 14 finished with reward: 9.0\n",
      "Episode 15 finished with reward: 12.0\n",
      "Episode 16 finished with reward: 10.0\n",
      "Episode 17 finished with reward: 10.0\n",
      "Episode 18 finished with reward: 9.0\n",
      "Episode 19 finished with reward: 9.0\n",
      "Episode 20 finished with reward: 12.0\n",
      "Episode 21 finished with reward: 10.0\n",
      "Episode 22 finished with reward: 10.0\n",
      "Episode 23 finished with reward: 14.0\n",
      "Episode 24 finished with reward: 10.0\n",
      "Episode 25 finished with reward: 19.0\n",
      "Episode 26 finished with reward: 13.0\n",
      "Episode 27 finished with reward: 9.0\n",
      "Episode 28 finished with reward: 9.0\n",
      "Episode 29 finished with reward: 10.0\n",
      "Episode 30 finished with reward: 9.0\n",
      "Episode 31 finished with reward: 11.0\n",
      "Episode 32 finished with reward: 15.0\n",
      "Episode 33 finished with reward: 15.0\n",
      "Episode 34 finished with reward: 11.0\n",
      "Episode 35 finished with reward: 9.0\n",
      "Episode 36 finished with reward: 11.0\n",
      "Episode 37 finished with reward: 11.0\n",
      "Episode 38 finished with reward: 8.0\n",
      "Episode 39 finished with reward: 9.0\n",
      "Episode 40 finished with reward: 11.0\n",
      "Episode 41 finished with reward: 9.0\n",
      "Episode 42 finished with reward: 9.0\n",
      "Episode 43 finished with reward: 9.0\n",
      "Episode 44 finished with reward: 10.0\n",
      "Episode 45 finished with reward: 9.0\n",
      "Episode 46 finished with reward: 8.0\n",
      "Episode 47 finished with reward: 9.0\n",
      "Episode 48 finished with reward: 14.0\n",
      "Episode 49 finished with reward: 9.0\n",
      "Episode 50 finished with reward: 10.0\n",
      "Episode 51 finished with reward: 8.0\n",
      "Episode 52 finished with reward: 15.0\n",
      "Episode 53 finished with reward: 9.0\n",
      "Episode 54 finished with reward: 9.0\n",
      "Episode 55 finished with reward: 10.0\n",
      "Episode 56 finished with reward: 11.0\n",
      "Episode 57 finished with reward: 10.0\n",
      "Episode 58 finished with reward: 10.0\n",
      "Episode 59 finished with reward: 10.0\n",
      "Episode 60 finished with reward: 8.0\n",
      "Episode 61 finished with reward: 10.0\n",
      "Episode 62 finished with reward: 10.0\n",
      "Episode 63 finished with reward: 8.0\n",
      "Episode 64 finished with reward: 10.0\n",
      "Episode 65 finished with reward: 9.0\n",
      "Episode 66 finished with reward: 13.0\n",
      "Episode 67 finished with reward: 9.0\n",
      "Episode 68 finished with reward: 9.0\n",
      "Episode 69 finished with reward: 8.0\n",
      "Episode 70 finished with reward: 9.0\n",
      "Episode 71 finished with reward: 18.0\n",
      "Episode 72 finished with reward: 9.0\n",
      "Episode 73 finished with reward: 10.0\n",
      "Episode 74 finished with reward: 8.0\n",
      "Episode 75 finished with reward: 10.0\n",
      "Episode 76 finished with reward: 9.0\n",
      "Episode 77 finished with reward: 9.0\n",
      "Episode 78 finished with reward: 9.0\n",
      "Episode 79 finished with reward: 9.0\n",
      "Episode 80 finished with reward: 10.0\n",
      "Episode 81 finished with reward: 10.0\n",
      "Episode 82 finished with reward: 10.0\n",
      "Episode 83 finished with reward: 9.0\n",
      "Episode 84 finished with reward: 10.0\n",
      "Episode 85 finished with reward: 10.0\n",
      "Episode 86 finished with reward: 10.0\n",
      "Episode 87 finished with reward: 9.0\n",
      "Episode 88 finished with reward: 9.0\n",
      "Episode 89 finished with reward: 13.0\n",
      "Episode 90 finished with reward: 10.0\n",
      "Episode 91 finished with reward: 11.0\n",
      "Episode 92 finished with reward: 10.0\n",
      "Episode 93 finished with reward: 10.0\n",
      "Episode 94 finished with reward: 20.0\n",
      "Episode 95 finished with reward: 8.0\n",
      "Episode 96 finished with reward: 10.0\n",
      "Episode 97 finished with reward: 9.0\n",
      "Episode 98 finished with reward: 24.0\n",
      "Episode 99 finished with reward: 13.0\n",
      "Episode 100 finished with reward: 16.0\n",
      "Episode 101 finished with reward: 12.0\n",
      "Episode 102 finished with reward: 9.0\n",
      "Episode 103 finished with reward: 11.0\n",
      "Episode 104 finished with reward: 22.0\n",
      "Episode 105 finished with reward: 9.0\n",
      "Episode 106 finished with reward: 9.0\n",
      "Episode 107 finished with reward: 10.0\n",
      "Episode 108 finished with reward: 9.0\n",
      "Episode 109 finished with reward: 18.0\n",
      "Episode 110 finished with reward: 10.0\n",
      "Episode 111 finished with reward: 9.0\n",
      "Episode 112 finished with reward: 8.0\n",
      "Episode 113 finished with reward: 10.0\n",
      "Episode 114 finished with reward: 8.0\n",
      "Episode 115 finished with reward: 11.0\n",
      "Episode 116 finished with reward: 9.0\n",
      "Episode 117 finished with reward: 10.0\n",
      "Episode 118 finished with reward: 11.0\n",
      "Episode 119 finished with reward: 10.0\n",
      "Episode 120 finished with reward: 24.0\n",
      "Episode 121 finished with reward: 10.0\n",
      "Episode 122 finished with reward: 12.0\n",
      "Episode 123 finished with reward: 9.0\n",
      "Episode 124 finished with reward: 9.0\n",
      "Episode 125 finished with reward: 8.0\n",
      "Episode 126 finished with reward: 9.0\n",
      "Episode 127 finished with reward: 9.0\n",
      "Episode 128 finished with reward: 10.0\n",
      "Episode 129 finished with reward: 9.0\n",
      "Episode 130 finished with reward: 9.0\n",
      "Episode 131 finished with reward: 10.0\n",
      "Episode 132 finished with reward: 11.0\n",
      "Episode 133 finished with reward: 10.0\n",
      "Episode 134 finished with reward: 8.0\n",
      "Episode 135 finished with reward: 9.0\n",
      "Episode 136 finished with reward: 12.0\n",
      "Episode 137 finished with reward: 8.0\n",
      "Episode 138 finished with reward: 10.0\n",
      "Episode 139 finished with reward: 10.0\n",
      "Episode 140 finished with reward: 12.0\n",
      "Episode 141 finished with reward: 10.0\n",
      "Episode 142 finished with reward: 9.0\n",
      "Episode 143 finished with reward: 10.0\n",
      "Episode 144 finished with reward: 9.0\n",
      "Episode 145 finished with reward: 9.0\n",
      "Episode 146 finished with reward: 9.0\n",
      "Episode 147 finished with reward: 9.0\n",
      "Episode 148 finished with reward: 11.0\n",
      "Episode 149 finished with reward: 10.0\n",
      "Episode 150 finished with reward: 10.0\n",
      "Episode 151 finished with reward: 10.0\n",
      "Episode 152 finished with reward: 8.0\n",
      "Episode 153 finished with reward: 9.0\n",
      "Episode 154 finished with reward: 8.0\n",
      "Episode 155 finished with reward: 9.0\n",
      "Episode 156 finished with reward: 9.0\n",
      "Episode 157 finished with reward: 9.0\n",
      "Episode 158 finished with reward: 15.0\n",
      "Episode 159 finished with reward: 10.0\n",
      "Episode 160 finished with reward: 16.0\n",
      "Episode 161 finished with reward: 10.0\n",
      "Episode 162 finished with reward: 9.0\n",
      "Episode 163 finished with reward: 9.0\n",
      "Episode 164 finished with reward: 9.0\n",
      "Episode 165 finished with reward: 11.0\n",
      "Episode 166 finished with reward: 10.0\n",
      "Episode 167 finished with reward: 9.0\n",
      "Episode 168 finished with reward: 9.0\n",
      "Episode 169 finished with reward: 9.0\n",
      "Episode 170 finished with reward: 9.0\n",
      "Episode 171 finished with reward: 10.0\n",
      "Episode 172 finished with reward: 8.0\n",
      "Episode 173 finished with reward: 10.0\n",
      "Episode 174 finished with reward: 9.0\n",
      "Episode 175 finished with reward: 8.0\n",
      "Episode 176 finished with reward: 9.0\n",
      "Episode 177 finished with reward: 10.0\n",
      "Episode 178 finished with reward: 9.0\n",
      "Episode 179 finished with reward: 11.0\n",
      "Episode 180 finished with reward: 10.0\n",
      "Episode 181 finished with reward: 8.0\n",
      "Episode 182 finished with reward: 12.0\n",
      "Episode 183 finished with reward: 10.0\n",
      "Episode 184 finished with reward: 11.0\n",
      "Episode 185 finished with reward: 9.0\n",
      "Episode 186 finished with reward: 11.0\n",
      "Episode 187 finished with reward: 11.0\n",
      "Episode 188 finished with reward: 12.0\n",
      "Episode 189 finished with reward: 11.0\n",
      "Episode 190 finished with reward: 23.0\n",
      "Episode 191 finished with reward: 20.0\n",
      "Episode 192 finished with reward: 8.0\n",
      "Episode 193 finished with reward: 11.0\n",
      "Episode 194 finished with reward: 26.0\n",
      "Episode 195 finished with reward: 11.0\n",
      "Episode 196 finished with reward: 13.0\n",
      "Episode 197 finished with reward: 32.0\n",
      "Episode 198 finished with reward: 23.0\n",
      "Episode 199 finished with reward: 27.0\n",
      "Episode 200 finished with reward: 10.0\n",
      "Episode 201 finished with reward: 40.0\n",
      "Episode 202 finished with reward: 22.0\n",
      "Episode 203 finished with reward: 11.0\n",
      "Episode 204 finished with reward: 34.0\n",
      "Episode 205 finished with reward: 27.0\n",
      "Episode 206 finished with reward: 24.0\n",
      "Episode 207 finished with reward: 34.0\n",
      "Episode 208 finished with reward: 14.0\n",
      "Episode 209 finished with reward: 40.0\n",
      "Episode 210 finished with reward: 24.0\n",
      "Episode 211 finished with reward: 63.0\n",
      "Episode 212 finished with reward: 76.0\n",
      "Episode 213 finished with reward: 53.0\n",
      "Episode 214 finished with reward: 21.0\n",
      "Episode 215 finished with reward: 40.0\n",
      "Episode 216 finished with reward: 21.0\n",
      "Episode 217 finished with reward: 78.0\n",
      "Episode 218 finished with reward: 24.0\n",
      "Episode 219 finished with reward: 40.0\n",
      "Episode 220 finished with reward: 26.0\n",
      "Episode 221 finished with reward: 10.0\n",
      "Episode 222 finished with reward: 20.0\n",
      "Episode 223 finished with reward: 30.0\n",
      "Episode 224 finished with reward: 52.0\n",
      "Episode 225 finished with reward: 15.0\n",
      "Episode 226 finished with reward: 32.0\n",
      "Episode 227 finished with reward: 216.0\n",
      "Episode 228 finished with reward: 176.0\n",
      "Episode 229 finished with reward: 195.0\n",
      "Episode 230 finished with reward: 188.0\n",
      "Episode 231 finished with reward: 175.0\n",
      "Episode 232 finished with reward: 193.0\n",
      "Episode 233 finished with reward: 218.0\n",
      "Episode 234 finished with reward: 207.0\n",
      "Episode 235 finished with reward: 196.0\n",
      "Episode 236 finished with reward: 228.0\n",
      "Episode 237 finished with reward: 306.0\n",
      "Episode 238 finished with reward: 245.0\n",
      "Episode 239 finished with reward: 226.0\n",
      "Episode 240 finished with reward: 218.0\n",
      "Episode 241 finished with reward: 258.0\n",
      "Episode 242 finished with reward: 251.0\n",
      "Episode 243 finished with reward: 274.0\n",
      "Episode 244 finished with reward: 243.0\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent(env_name=\"CartPole-v1\", hidden_dim=512)\n",
    "rewards = agent.run(num_episodes=100, is_training=True, render=True)\n",
    "print(\"Rewards per episode:\", rewards)\n",
    "plt.plot(rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Rewards per Episode')\n",
    "plt.savefig(\"rewards.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
