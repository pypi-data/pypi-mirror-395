

# This file was autogenerated by some hot garbage in the `uniffi` crate.
# Trust me, you don't want to mess with it!

# Common helper code.
#
# Ideally this would live in a separate .py file where it can be unittested etc
# in isolation, and perhaps even published as a re-useable package.
#
# However, it's important that the details of how this helper code works (e.g. the
# way that different builtin types are passed across the FFI) exactly match what's
# expected by the rust code on the other side of the interface. In practice right
# now that means coming from the exact some version of `uniffi` that was used to
# compile the rust component. The easiest way to ensure this is to bundle the Python
# helpers directly inline like we're doing here.

from __future__ import annotations
import os
import sys
import ctypes
import enum
import struct
import contextlib
import datetime
import threading
import itertools
import traceback
import typing
import platform

# Used for default argument values
_DEFAULT = object() # type: typing.Any


class _UniffiRustBuffer(ctypes.Structure):
    _fields_ = [
        ("capacity", ctypes.c_uint64),
        ("len", ctypes.c_uint64),
        ("data", ctypes.POINTER(ctypes.c_char)),
    ]

    @staticmethod
    def default():
        return _UniffiRustBuffer(0, 0, None)

    @staticmethod
    def alloc(size):
        return _uniffi_rust_call(_UniffiLib.ffi_posixlake_rustbuffer_alloc, size)

    @staticmethod
    def reserve(rbuf, additional):
        return _uniffi_rust_call(_UniffiLib.ffi_posixlake_rustbuffer_reserve, rbuf, additional)

    def free(self):
        return _uniffi_rust_call(_UniffiLib.ffi_posixlake_rustbuffer_free, self)

    def __str__(self):
        return "_UniffiRustBuffer(capacity={}, len={}, data={})".format(
            self.capacity,
            self.len,
            self.data[0:self.len]
        )

    @contextlib.contextmanager
    def alloc_with_builder(*args):
        """Context-manger to allocate a buffer using a _UniffiRustBufferBuilder.

        The allocated buffer will be automatically freed if an error occurs, ensuring that
        we don't accidentally leak it.
        """
        builder = _UniffiRustBufferBuilder()
        try:
            yield builder
        except:
            builder.discard()
            raise

    @contextlib.contextmanager
    def consume_with_stream(self):
        """Context-manager to consume a buffer using a _UniffiRustBufferStream.

        The _UniffiRustBuffer will be freed once the context-manager exits, ensuring that we don't
        leak it even if an error occurs.
        """
        try:
            s = _UniffiRustBufferStream.from_rust_buffer(self)
            yield s
            if s.remaining() != 0:
                raise RuntimeError("junk data left in buffer at end of consume_with_stream")
        finally:
            self.free()

    @contextlib.contextmanager
    def read_with_stream(self):
        """Context-manager to read a buffer using a _UniffiRustBufferStream.

        This is like consume_with_stream, but doesn't free the buffer afterwards.
        It should only be used with borrowed `_UniffiRustBuffer` data.
        """
        s = _UniffiRustBufferStream.from_rust_buffer(self)
        yield s
        if s.remaining() != 0:
            raise RuntimeError("junk data left in buffer at end of read_with_stream")

class _UniffiForeignBytes(ctypes.Structure):
    _fields_ = [
        ("len", ctypes.c_int32),
        ("data", ctypes.POINTER(ctypes.c_char)),
    ]

    def __str__(self):
        return "_UniffiForeignBytes(len={}, data={})".format(self.len, self.data[0:self.len])


class _UniffiRustBufferStream:
    """
    Helper for structured reading of bytes from a _UniffiRustBuffer
    """

    def __init__(self, data, len):
        self.data = data
        self.len = len
        self.offset = 0

    @classmethod
    def from_rust_buffer(cls, buf):
        return cls(buf.data, buf.len)

    def remaining(self):
        return self.len - self.offset

    def _unpack_from(self, size, format):
        if self.offset + size > self.len:
            raise InternalError("read past end of rust buffer")
        value = struct.unpack(format, self.data[self.offset:self.offset+size])[0]
        self.offset += size
        return value

    def read(self, size):
        if self.offset + size > self.len:
            raise InternalError("read past end of rust buffer")
        data = self.data[self.offset:self.offset+size]
        self.offset += size
        return data

    def read_i8(self):
        return self._unpack_from(1, ">b")

    def read_u8(self):
        return self._unpack_from(1, ">B")

    def read_i16(self):
        return self._unpack_from(2, ">h")

    def read_u16(self):
        return self._unpack_from(2, ">H")

    def read_i32(self):
        return self._unpack_from(4, ">i")

    def read_u32(self):
        return self._unpack_from(4, ">I")

    def read_i64(self):
        return self._unpack_from(8, ">q")

    def read_u64(self):
        return self._unpack_from(8, ">Q")

    def read_float(self):
        v = self._unpack_from(4, ">f")
        return v

    def read_double(self):
        return self._unpack_from(8, ">d")

class _UniffiRustBufferBuilder:
    """
    Helper for structured writing of bytes into a _UniffiRustBuffer.
    """

    def __init__(self):
        self.rbuf = _UniffiRustBuffer.alloc(16)
        self.rbuf.len = 0

    def finalize(self):
        rbuf = self.rbuf
        self.rbuf = None
        return rbuf

    def discard(self):
        if self.rbuf is not None:
            rbuf = self.finalize()
            rbuf.free()

    @contextlib.contextmanager
    def _reserve(self, num_bytes):
        if self.rbuf.len + num_bytes > self.rbuf.capacity:
            self.rbuf = _UniffiRustBuffer.reserve(self.rbuf, num_bytes)
        yield None
        self.rbuf.len += num_bytes

    def _pack_into(self, size, format, value):
        with self._reserve(size):
            # XXX TODO: I feel like I should be able to use `struct.pack_into` here but can't figure it out.
            for i, byte in enumerate(struct.pack(format, value)):
                self.rbuf.data[self.rbuf.len + i] = byte

    def write(self, value):
        with self._reserve(len(value)):
            for i, byte in enumerate(value):
                self.rbuf.data[self.rbuf.len + i] = byte

    def write_i8(self, v):
        self._pack_into(1, ">b", v)

    def write_u8(self, v):
        self._pack_into(1, ">B", v)

    def write_i16(self, v):
        self._pack_into(2, ">h", v)

    def write_u16(self, v):
        self._pack_into(2, ">H", v)

    def write_i32(self, v):
        self._pack_into(4, ">i", v)

    def write_u32(self, v):
        self._pack_into(4, ">I", v)

    def write_i64(self, v):
        self._pack_into(8, ">q", v)

    def write_u64(self, v):
        self._pack_into(8, ">Q", v)

    def write_float(self, v):
        self._pack_into(4, ">f", v)

    def write_double(self, v):
        self._pack_into(8, ">d", v)

    def write_c_size_t(self, v):
        self._pack_into(ctypes.sizeof(ctypes.c_size_t) , "@N", v)
# A handful of classes and functions to support the generated data structures.
# This would be a good candidate for isolating in its own ffi-support lib.

class InternalError(Exception):
    pass

class _UniffiRustCallStatus(ctypes.Structure):
    """
    Error runtime.
    """
    _fields_ = [
        ("code", ctypes.c_int8),
        ("error_buf", _UniffiRustBuffer),
    ]

    # These match the values from the uniffi::rustcalls module
    CALL_SUCCESS = 0
    CALL_ERROR = 1
    CALL_UNEXPECTED_ERROR = 2

    @staticmethod
    def default():
        return _UniffiRustCallStatus(code=_UniffiRustCallStatus.CALL_SUCCESS, error_buf=_UniffiRustBuffer.default())

    def __str__(self):
        if self.code == _UniffiRustCallStatus.CALL_SUCCESS:
            return "_UniffiRustCallStatus(CALL_SUCCESS)"
        elif self.code == _UniffiRustCallStatus.CALL_ERROR:
            return "_UniffiRustCallStatus(CALL_ERROR)"
        elif self.code == _UniffiRustCallStatus.CALL_UNEXPECTED_ERROR:
            return "_UniffiRustCallStatus(CALL_UNEXPECTED_ERROR)"
        else:
            return "_UniffiRustCallStatus(<invalid code>)"

def _uniffi_rust_call(fn, *args):
    # Call a rust function
    return _uniffi_rust_call_with_error(None, fn, *args)

def _uniffi_rust_call_with_error(error_ffi_converter, fn, *args):
    # Call a rust function and handle any errors
    #
    # This function is used for rust calls that return Result<> and therefore can set the CALL_ERROR status code.
    # error_ffi_converter must be set to the _UniffiConverter for the error class that corresponds to the result.
    call_status = _UniffiRustCallStatus.default()

    args_with_error = args + (ctypes.byref(call_status),)
    result = fn(*args_with_error)
    _uniffi_check_call_status(error_ffi_converter, call_status)
    return result

def _uniffi_check_call_status(error_ffi_converter, call_status):
    if call_status.code == _UniffiRustCallStatus.CALL_SUCCESS:
        pass
    elif call_status.code == _UniffiRustCallStatus.CALL_ERROR:
        if error_ffi_converter is None:
            call_status.error_buf.free()
            raise InternalError("_uniffi_rust_call_with_error: CALL_ERROR, but error_ffi_converter is None")
        else:
            raise error_ffi_converter.lift(call_status.error_buf)
    elif call_status.code == _UniffiRustCallStatus.CALL_UNEXPECTED_ERROR:
        # When the rust code sees a panic, it tries to construct a _UniffiRustBuffer
        # with the message.  But if that code panics, then it just sends back
        # an empty buffer.
        if call_status.error_buf.len > 0:
            msg = _UniffiConverterString.lift(call_status.error_buf)
        else:
            msg = "Unknown rust panic"
        raise InternalError(msg)
    else:
        raise InternalError("Invalid _UniffiRustCallStatus code: {}".format(
            call_status.code))

def _uniffi_trait_interface_call(call_status, make_call, write_return_value):
    try:
        return write_return_value(make_call())
    except Exception as e:
        call_status.code = _UniffiRustCallStatus.CALL_UNEXPECTED_ERROR
        call_status.error_buf = _UniffiConverterString.lower(repr(e))

def _uniffi_trait_interface_call_with_error(call_status, make_call, write_return_value, error_type, lower_error):
    try:
        try:
            return write_return_value(make_call())
        except error_type as e:
            call_status.code = _UniffiRustCallStatus.CALL_ERROR
            call_status.error_buf = lower_error(e)
    except Exception as e:
        call_status.code = _UniffiRustCallStatus.CALL_UNEXPECTED_ERROR
        call_status.error_buf = _UniffiConverterString.lower(repr(e))
class _UniffiHandleMap:
    """
    A map where inserting, getting and removing data is synchronized with a lock.
    """

    def __init__(self):
        # type Handle = int
        self._map = {}  # type: Dict[Handle, Any]
        self._lock = threading.Lock()
        self._counter = itertools.count()

    def insert(self, obj):
        with self._lock:
            handle = next(self._counter)
            self._map[handle] = obj
            return handle

    def get(self, handle):
        try:
            with self._lock:
                return self._map[handle]
        except KeyError:
            raise InternalError("_UniffiHandleMap.get: Invalid handle")

    def remove(self, handle):
        try:
            with self._lock:
                return self._map.pop(handle)
        except KeyError:
            raise InternalError("_UniffiHandleMap.remove: Invalid handle")

    def __len__(self):
        return len(self._map)
# Types conforming to `_UniffiConverterPrimitive` pass themselves directly over the FFI.
class _UniffiConverterPrimitive:
    @classmethod
    def lift(cls, value):
        return value

    @classmethod
    def lower(cls, value):
        return value

class _UniffiConverterPrimitiveInt(_UniffiConverterPrimitive):
    @classmethod
    def check_lower(cls, value):
        try:
            value = value.__index__()
        except Exception:
            raise TypeError("'{}' object cannot be interpreted as an integer".format(type(value).__name__))
        if not isinstance(value, int):
            raise TypeError("__index__ returned non-int (type {})".format(type(value).__name__))
        if not cls.VALUE_MIN <= value < cls.VALUE_MAX:
            raise ValueError("{} requires {} <= value < {}".format(cls.CLASS_NAME, cls.VALUE_MIN, cls.VALUE_MAX))

class _UniffiConverterPrimitiveFloat(_UniffiConverterPrimitive):
    @classmethod
    def check_lower(cls, value):
        try:
            value = value.__float__()
        except Exception:
            raise TypeError("must be real number, not {}".format(type(value).__name__))
        if not isinstance(value, float):
            raise TypeError("__float__ returned non-float (type {})".format(type(value).__name__))

# Helper class for wrapper types that will always go through a _UniffiRustBuffer.
# Classes should inherit from this and implement the `read` and `write` static methods.
class _UniffiConverterRustBuffer:
    @classmethod
    def lift(cls, rbuf):
        with rbuf.consume_with_stream() as stream:
            return cls.read(stream)

    @classmethod
    def lower(cls, value):
        with _UniffiRustBuffer.alloc_with_builder() as builder:
            cls.write(value, builder)
            return builder.finalize()

# Contains loading, initialization code, and the FFI Function declarations.
# Define some ctypes FFI types that we use in the library

"""
Function pointer for a Rust task, which a callback function that takes a opaque pointer
"""
_UNIFFI_RUST_TASK = ctypes.CFUNCTYPE(None, ctypes.c_void_p, ctypes.c_int8)

def _uniffi_future_callback_t(return_type):
    """
    Factory function to create callback function types for async functions
    """
    return ctypes.CFUNCTYPE(None, ctypes.c_uint64, return_type, _UniffiRustCallStatus)

def _uniffi_load_indirect():
    """
    This is how we find and load the dynamic library provided by the component.
    For now we just look it up by name.
    """
    if sys.platform == "darwin":
        libname = "lib{}.dylib"
    elif sys.platform.startswith("win"):
        # As of python3.8, ctypes does not seem to search $PATH when loading DLLs.
        # We could use `os.add_dll_directory` to configure the search path, but
        # it doesn't feel right to mess with application-wide settings. Let's
        # assume that the `.dll` is next to the `.py` file and load by full path.
        libname = os.path.join(
            os.path.dirname(__file__),
            "{}.dll",
        )
    else:
        # Anything else must be an ELF platform - Linux, *BSD, Solaris/illumos
        libname = "lib{}.so"

    libname = libname.format("posixlake")
    path = os.path.join(os.path.dirname(__file__), libname)
    lib = ctypes.cdll.LoadLibrary(path)
    return lib

def _uniffi_check_contract_api_version(lib):
    # Get the bindings contract version from our ComponentInterface
    bindings_contract_version = 29
    # Get the scaffolding contract version by calling the into the dylib
    scaffolding_contract_version = lib.ffi_posixlake_uniffi_contract_version()
    if bindings_contract_version != scaffolding_contract_version:
        raise InternalError("UniFFI contract version mismatch: try cleaning and rebuilding your project")

def _uniffi_check_api_checksums(lib):
    if lib.uniffi_posixlake_checksum_func_restore() != 17475:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_func_restore_to_transaction() != 46731:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_backup() != 40091:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_backup_incremental() != 37258:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_create_user() != 52989:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_delete_rows_where() != 42512:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_flush_write_buffer() != 10531:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_get_base_path() != 47197:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_get_data_skipping_stats() != 4630:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_get_metrics() != 10926:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_get_schema() != 65268:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_health_check() != 45840:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_insert_buffered_json() != 21120:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_insert_json() != 50056:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_merge_json() != 33646:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_optimize() != 8462:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_optimize_with_filter() != 20703:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_optimize_with_target_size() != 43273:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_query() != 58339:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_query_json() != 44263:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_query_timestamp() != 27436:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_query_timestamp_json() != 23913:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_query_version() != 26283:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_query_version_json() != 6541:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_vacuum() != 65393:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_vacuum_dry_run() != 29844:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_databaseops_zorder() != 7354:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_nfsserver_get_mount_command() != 40395:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_nfsserver_get_port() != 19319:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_nfsserver_get_unmount_command() != 62307:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_nfsserver_is_ready() != 63793:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_method_nfsserver_shutdown() != 27868:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_constructor_databaseops_create() != 56590:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_constructor_databaseops_create_from_csv() != 33604:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_constructor_databaseops_create_from_parquet() != 47261:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_constructor_databaseops_create_with_auth() != 43173:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_constructor_databaseops_create_with_s3() != 9824:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_constructor_databaseops_open() != 3718:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_constructor_databaseops_open_with_credentials() != 21963:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_constructor_databaseops_open_with_s3() != 24796:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")
    if lib.uniffi_posixlake_checksum_constructor_nfsserver_new() != 18383:
        raise InternalError("UniFFI API checksum mismatch: try cleaning and rebuilding your project")

# A ctypes library to expose the extern-C FFI definitions.
# This is an implementation detail which will be called internally by the public API.

_UniffiLib = _uniffi_load_indirect()
_UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK = ctypes.CFUNCTYPE(None,ctypes.c_uint64,ctypes.c_int8,
)
_UNIFFI_FOREIGN_FUTURE_FREE = ctypes.CFUNCTYPE(None,ctypes.c_uint64,
)
_UNIFFI_CALLBACK_INTERFACE_FREE = ctypes.CFUNCTYPE(None,ctypes.c_uint64,
)
class _UniffiForeignFuture(ctypes.Structure):
    _fields_ = [
        ("handle", ctypes.c_uint64),
        ("free", _UNIFFI_FOREIGN_FUTURE_FREE),
    ]
class _UniffiForeignFutureStructU8(ctypes.Structure):
    _fields_ = [
        ("return_value", ctypes.c_uint8),
        ("call_status", _UniffiRustCallStatus),
    ]
_UNIFFI_FOREIGN_FUTURE_COMPLETE_U8 = ctypes.CFUNCTYPE(None,ctypes.c_uint64,_UniffiForeignFutureStructU8,
)
class _UniffiForeignFutureStructI8(ctypes.Structure):
    _fields_ = [
        ("return_value", ctypes.c_int8),
        ("call_status", _UniffiRustCallStatus),
    ]
_UNIFFI_FOREIGN_FUTURE_COMPLETE_I8 = ctypes.CFUNCTYPE(None,ctypes.c_uint64,_UniffiForeignFutureStructI8,
)
class _UniffiForeignFutureStructU16(ctypes.Structure):
    _fields_ = [
        ("return_value", ctypes.c_uint16),
        ("call_status", _UniffiRustCallStatus),
    ]
_UNIFFI_FOREIGN_FUTURE_COMPLETE_U16 = ctypes.CFUNCTYPE(None,ctypes.c_uint64,_UniffiForeignFutureStructU16,
)
class _UniffiForeignFutureStructI16(ctypes.Structure):
    _fields_ = [
        ("return_value", ctypes.c_int16),
        ("call_status", _UniffiRustCallStatus),
    ]
_UNIFFI_FOREIGN_FUTURE_COMPLETE_I16 = ctypes.CFUNCTYPE(None,ctypes.c_uint64,_UniffiForeignFutureStructI16,
)
class _UniffiForeignFutureStructU32(ctypes.Structure):
    _fields_ = [
        ("return_value", ctypes.c_uint32),
        ("call_status", _UniffiRustCallStatus),
    ]
_UNIFFI_FOREIGN_FUTURE_COMPLETE_U32 = ctypes.CFUNCTYPE(None,ctypes.c_uint64,_UniffiForeignFutureStructU32,
)
class _UniffiForeignFutureStructI32(ctypes.Structure):
    _fields_ = [
        ("return_value", ctypes.c_int32),
        ("call_status", _UniffiRustCallStatus),
    ]
_UNIFFI_FOREIGN_FUTURE_COMPLETE_I32 = ctypes.CFUNCTYPE(None,ctypes.c_uint64,_UniffiForeignFutureStructI32,
)
class _UniffiForeignFutureStructU64(ctypes.Structure):
    _fields_ = [
        ("return_value", ctypes.c_uint64),
        ("call_status", _UniffiRustCallStatus),
    ]
_UNIFFI_FOREIGN_FUTURE_COMPLETE_U64 = ctypes.CFUNCTYPE(None,ctypes.c_uint64,_UniffiForeignFutureStructU64,
)
class _UniffiForeignFutureStructI64(ctypes.Structure):
    _fields_ = [
        ("return_value", ctypes.c_int64),
        ("call_status", _UniffiRustCallStatus),
    ]
_UNIFFI_FOREIGN_FUTURE_COMPLETE_I64 = ctypes.CFUNCTYPE(None,ctypes.c_uint64,_UniffiForeignFutureStructI64,
)
class _UniffiForeignFutureStructF32(ctypes.Structure):
    _fields_ = [
        ("return_value", ctypes.c_float),
        ("call_status", _UniffiRustCallStatus),
    ]
_UNIFFI_FOREIGN_FUTURE_COMPLETE_F32 = ctypes.CFUNCTYPE(None,ctypes.c_uint64,_UniffiForeignFutureStructF32,
)
class _UniffiForeignFutureStructF64(ctypes.Structure):
    _fields_ = [
        ("return_value", ctypes.c_double),
        ("call_status", _UniffiRustCallStatus),
    ]
_UNIFFI_FOREIGN_FUTURE_COMPLETE_F64 = ctypes.CFUNCTYPE(None,ctypes.c_uint64,_UniffiForeignFutureStructF64,
)
class _UniffiForeignFutureStructPointer(ctypes.Structure):
    _fields_ = [
        ("return_value", ctypes.c_void_p),
        ("call_status", _UniffiRustCallStatus),
    ]
_UNIFFI_FOREIGN_FUTURE_COMPLETE_POINTER = ctypes.CFUNCTYPE(None,ctypes.c_uint64,_UniffiForeignFutureStructPointer,
)
class _UniffiForeignFutureStructRustBuffer(ctypes.Structure):
    _fields_ = [
        ("return_value", _UniffiRustBuffer),
        ("call_status", _UniffiRustCallStatus),
    ]
_UNIFFI_FOREIGN_FUTURE_COMPLETE_RUST_BUFFER = ctypes.CFUNCTYPE(None,ctypes.c_uint64,_UniffiForeignFutureStructRustBuffer,
)
class _UniffiForeignFutureStructVoid(ctypes.Structure):
    _fields_ = [
        ("call_status", _UniffiRustCallStatus),
    ]
_UNIFFI_FOREIGN_FUTURE_COMPLETE_VOID = ctypes.CFUNCTYPE(None,ctypes.c_uint64,_UniffiForeignFutureStructVoid,
)
_UniffiLib.uniffi_posixlake_fn_clone_databaseops.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_clone_databaseops.restype = ctypes.c_void_p
_UniffiLib.uniffi_posixlake_fn_free_databaseops.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_free_databaseops.restype = None
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create.argtypes = (
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create.restype = ctypes.c_void_p
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create_from_csv.argtypes = (
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create_from_csv.restype = ctypes.c_void_p
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create_from_parquet.argtypes = (
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create_from_parquet.restype = ctypes.c_void_p
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create_with_auth.argtypes = (
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    ctypes.c_int8,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create_with_auth.restype = ctypes.c_void_p
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create_with_s3.argtypes = (
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create_with_s3.restype = ctypes.c_void_p
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_open.argtypes = (
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_open.restype = ctypes.c_void_p
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_open_with_credentials.argtypes = (
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_open_with_credentials.restype = ctypes.c_void_p
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_open_with_s3.argtypes = (
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_open_with_s3.restype = ctypes.c_void_p
_UniffiLib.uniffi_posixlake_fn_method_databaseops_backup.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_backup.restype = None
_UniffiLib.uniffi_posixlake_fn_method_databaseops_backup_incremental.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_backup_incremental.restype = None
_UniffiLib.uniffi_posixlake_fn_method_databaseops_create_user.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_create_user.restype = None
_UniffiLib.uniffi_posixlake_fn_method_databaseops_delete_rows_where.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_delete_rows_where.restype = ctypes.c_uint64
_UniffiLib.uniffi_posixlake_fn_method_databaseops_flush_write_buffer.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_flush_write_buffer.restype = None
_UniffiLib.uniffi_posixlake_fn_method_databaseops_get_base_path.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_get_base_path.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_databaseops_get_data_skipping_stats.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_get_data_skipping_stats.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_databaseops_get_metrics.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_get_metrics.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_databaseops_get_schema.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_get_schema.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_databaseops_health_check.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_health_check.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_databaseops_insert_buffered_json.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_insert_buffered_json.restype = ctypes.c_uint64
_UniffiLib.uniffi_posixlake_fn_method_databaseops_insert_json.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_insert_json.restype = ctypes.c_uint64
_UniffiLib.uniffi_posixlake_fn_method_databaseops_merge_json.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_merge_json.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_databaseops_optimize.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_optimize.restype = None
_UniffiLib.uniffi_posixlake_fn_method_databaseops_optimize_with_filter.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_optimize_with_filter.restype = None
_UniffiLib.uniffi_posixlake_fn_method_databaseops_optimize_with_target_size.argtypes = (
    ctypes.c_void_p,
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_optimize_with_target_size.restype = None
_UniffiLib.uniffi_posixlake_fn_method_databaseops_query.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_query.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_json.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_json.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_timestamp.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.c_int64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_timestamp.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_timestamp_json.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.c_int64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_timestamp_json.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_version.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.c_int64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_version.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_version_json.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.c_int64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_version_json.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_databaseops_vacuum.argtypes = (
    ctypes.c_void_p,
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_vacuum.restype = None
_UniffiLib.uniffi_posixlake_fn_method_databaseops_vacuum_dry_run.argtypes = (
    ctypes.c_void_p,
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_vacuum_dry_run.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_databaseops_zorder.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_databaseops_zorder.restype = None
_UniffiLib.uniffi_posixlake_fn_clone_nfsserver.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_clone_nfsserver.restype = ctypes.c_void_p
_UniffiLib.uniffi_posixlake_fn_free_nfsserver.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_free_nfsserver.restype = None
_UniffiLib.uniffi_posixlake_fn_constructor_nfsserver_new.argtypes = (
    ctypes.c_void_p,
    ctypes.c_uint16,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_constructor_nfsserver_new.restype = ctypes.c_void_p
_UniffiLib.uniffi_posixlake_fn_method_nfsserver_get_mount_command.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_nfsserver_get_mount_command.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_nfsserver_get_port.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_nfsserver_get_port.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_fn_method_nfsserver_get_unmount_command.argtypes = (
    ctypes.c_void_p,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_nfsserver_get_unmount_command.restype = _UniffiRustBuffer
_UniffiLib.uniffi_posixlake_fn_method_nfsserver_is_ready.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_nfsserver_is_ready.restype = ctypes.c_int8
_UniffiLib.uniffi_posixlake_fn_method_nfsserver_shutdown.argtypes = (
    ctypes.c_void_p,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_method_nfsserver_shutdown.restype = None
_UniffiLib.uniffi_posixlake_fn_func_restore.argtypes = (
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_func_restore.restype = None
_UniffiLib.uniffi_posixlake_fn_func_restore_to_transaction.argtypes = (
    _UniffiRustBuffer,
    _UniffiRustBuffer,
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.uniffi_posixlake_fn_func_restore_to_transaction.restype = None
_UniffiLib.ffi_posixlake_rustbuffer_alloc.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rustbuffer_alloc.restype = _UniffiRustBuffer
_UniffiLib.ffi_posixlake_rustbuffer_from_bytes.argtypes = (
    _UniffiForeignBytes,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rustbuffer_from_bytes.restype = _UniffiRustBuffer
_UniffiLib.ffi_posixlake_rustbuffer_free.argtypes = (
    _UniffiRustBuffer,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rustbuffer_free.restype = None
_UniffiLib.ffi_posixlake_rustbuffer_reserve.argtypes = (
    _UniffiRustBuffer,
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rustbuffer_reserve.restype = _UniffiRustBuffer
_UniffiLib.ffi_posixlake_rust_future_poll_u8.argtypes = (
    ctypes.c_uint64,
    _UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK,
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_poll_u8.restype = None
_UniffiLib.ffi_posixlake_rust_future_cancel_u8.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_cancel_u8.restype = None
_UniffiLib.ffi_posixlake_rust_future_free_u8.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_free_u8.restype = None
_UniffiLib.ffi_posixlake_rust_future_complete_u8.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rust_future_complete_u8.restype = ctypes.c_uint8
_UniffiLib.ffi_posixlake_rust_future_poll_i8.argtypes = (
    ctypes.c_uint64,
    _UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK,
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_poll_i8.restype = None
_UniffiLib.ffi_posixlake_rust_future_cancel_i8.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_cancel_i8.restype = None
_UniffiLib.ffi_posixlake_rust_future_free_i8.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_free_i8.restype = None
_UniffiLib.ffi_posixlake_rust_future_complete_i8.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rust_future_complete_i8.restype = ctypes.c_int8
_UniffiLib.ffi_posixlake_rust_future_poll_u16.argtypes = (
    ctypes.c_uint64,
    _UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK,
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_poll_u16.restype = None
_UniffiLib.ffi_posixlake_rust_future_cancel_u16.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_cancel_u16.restype = None
_UniffiLib.ffi_posixlake_rust_future_free_u16.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_free_u16.restype = None
_UniffiLib.ffi_posixlake_rust_future_complete_u16.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rust_future_complete_u16.restype = ctypes.c_uint16
_UniffiLib.ffi_posixlake_rust_future_poll_i16.argtypes = (
    ctypes.c_uint64,
    _UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK,
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_poll_i16.restype = None
_UniffiLib.ffi_posixlake_rust_future_cancel_i16.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_cancel_i16.restype = None
_UniffiLib.ffi_posixlake_rust_future_free_i16.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_free_i16.restype = None
_UniffiLib.ffi_posixlake_rust_future_complete_i16.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rust_future_complete_i16.restype = ctypes.c_int16
_UniffiLib.ffi_posixlake_rust_future_poll_u32.argtypes = (
    ctypes.c_uint64,
    _UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK,
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_poll_u32.restype = None
_UniffiLib.ffi_posixlake_rust_future_cancel_u32.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_cancel_u32.restype = None
_UniffiLib.ffi_posixlake_rust_future_free_u32.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_free_u32.restype = None
_UniffiLib.ffi_posixlake_rust_future_complete_u32.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rust_future_complete_u32.restype = ctypes.c_uint32
_UniffiLib.ffi_posixlake_rust_future_poll_i32.argtypes = (
    ctypes.c_uint64,
    _UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK,
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_poll_i32.restype = None
_UniffiLib.ffi_posixlake_rust_future_cancel_i32.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_cancel_i32.restype = None
_UniffiLib.ffi_posixlake_rust_future_free_i32.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_free_i32.restype = None
_UniffiLib.ffi_posixlake_rust_future_complete_i32.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rust_future_complete_i32.restype = ctypes.c_int32
_UniffiLib.ffi_posixlake_rust_future_poll_u64.argtypes = (
    ctypes.c_uint64,
    _UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK,
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_poll_u64.restype = None
_UniffiLib.ffi_posixlake_rust_future_cancel_u64.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_cancel_u64.restype = None
_UniffiLib.ffi_posixlake_rust_future_free_u64.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_free_u64.restype = None
_UniffiLib.ffi_posixlake_rust_future_complete_u64.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rust_future_complete_u64.restype = ctypes.c_uint64
_UniffiLib.ffi_posixlake_rust_future_poll_i64.argtypes = (
    ctypes.c_uint64,
    _UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK,
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_poll_i64.restype = None
_UniffiLib.ffi_posixlake_rust_future_cancel_i64.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_cancel_i64.restype = None
_UniffiLib.ffi_posixlake_rust_future_free_i64.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_free_i64.restype = None
_UniffiLib.ffi_posixlake_rust_future_complete_i64.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rust_future_complete_i64.restype = ctypes.c_int64
_UniffiLib.ffi_posixlake_rust_future_poll_f32.argtypes = (
    ctypes.c_uint64,
    _UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK,
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_poll_f32.restype = None
_UniffiLib.ffi_posixlake_rust_future_cancel_f32.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_cancel_f32.restype = None
_UniffiLib.ffi_posixlake_rust_future_free_f32.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_free_f32.restype = None
_UniffiLib.ffi_posixlake_rust_future_complete_f32.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rust_future_complete_f32.restype = ctypes.c_float
_UniffiLib.ffi_posixlake_rust_future_poll_f64.argtypes = (
    ctypes.c_uint64,
    _UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK,
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_poll_f64.restype = None
_UniffiLib.ffi_posixlake_rust_future_cancel_f64.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_cancel_f64.restype = None
_UniffiLib.ffi_posixlake_rust_future_free_f64.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_free_f64.restype = None
_UniffiLib.ffi_posixlake_rust_future_complete_f64.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rust_future_complete_f64.restype = ctypes.c_double
_UniffiLib.ffi_posixlake_rust_future_poll_pointer.argtypes = (
    ctypes.c_uint64,
    _UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK,
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_poll_pointer.restype = None
_UniffiLib.ffi_posixlake_rust_future_cancel_pointer.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_cancel_pointer.restype = None
_UniffiLib.ffi_posixlake_rust_future_free_pointer.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_free_pointer.restype = None
_UniffiLib.ffi_posixlake_rust_future_complete_pointer.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rust_future_complete_pointer.restype = ctypes.c_void_p
_UniffiLib.ffi_posixlake_rust_future_poll_rust_buffer.argtypes = (
    ctypes.c_uint64,
    _UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK,
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_poll_rust_buffer.restype = None
_UniffiLib.ffi_posixlake_rust_future_cancel_rust_buffer.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_cancel_rust_buffer.restype = None
_UniffiLib.ffi_posixlake_rust_future_free_rust_buffer.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_free_rust_buffer.restype = None
_UniffiLib.ffi_posixlake_rust_future_complete_rust_buffer.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rust_future_complete_rust_buffer.restype = _UniffiRustBuffer
_UniffiLib.ffi_posixlake_rust_future_poll_void.argtypes = (
    ctypes.c_uint64,
    _UNIFFI_RUST_FUTURE_CONTINUATION_CALLBACK,
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_poll_void.restype = None
_UniffiLib.ffi_posixlake_rust_future_cancel_void.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_cancel_void.restype = None
_UniffiLib.ffi_posixlake_rust_future_free_void.argtypes = (
    ctypes.c_uint64,
)
_UniffiLib.ffi_posixlake_rust_future_free_void.restype = None
_UniffiLib.ffi_posixlake_rust_future_complete_void.argtypes = (
    ctypes.c_uint64,
    ctypes.POINTER(_UniffiRustCallStatus),
)
_UniffiLib.ffi_posixlake_rust_future_complete_void.restype = None
_UniffiLib.uniffi_posixlake_checksum_func_restore.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_func_restore.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_func_restore_to_transaction.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_func_restore_to_transaction.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_backup.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_backup.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_backup_incremental.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_backup_incremental.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_create_user.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_create_user.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_delete_rows_where.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_delete_rows_where.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_flush_write_buffer.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_flush_write_buffer.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_get_base_path.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_get_base_path.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_get_data_skipping_stats.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_get_data_skipping_stats.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_get_metrics.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_get_metrics.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_get_schema.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_get_schema.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_health_check.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_health_check.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_insert_buffered_json.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_insert_buffered_json.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_insert_json.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_insert_json.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_merge_json.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_merge_json.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_optimize.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_optimize.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_optimize_with_filter.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_optimize_with_filter.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_optimize_with_target_size.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_optimize_with_target_size.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_query.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_query.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_query_json.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_query_json.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_query_timestamp.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_query_timestamp.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_query_timestamp_json.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_query_timestamp_json.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_query_version.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_query_version.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_query_version_json.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_query_version_json.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_vacuum.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_vacuum.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_vacuum_dry_run.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_vacuum_dry_run.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_zorder.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_databaseops_zorder.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_nfsserver_get_mount_command.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_nfsserver_get_mount_command.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_nfsserver_get_port.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_nfsserver_get_port.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_nfsserver_get_unmount_command.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_nfsserver_get_unmount_command.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_nfsserver_is_ready.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_nfsserver_is_ready.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_method_nfsserver_shutdown.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_method_nfsserver_shutdown.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_create.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_create.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_create_from_csv.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_create_from_csv.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_create_from_parquet.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_create_from_parquet.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_create_with_auth.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_create_with_auth.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_create_with_s3.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_create_with_s3.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_open.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_open.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_open_with_credentials.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_open_with_credentials.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_open_with_s3.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_constructor_databaseops_open_with_s3.restype = ctypes.c_uint16
_UniffiLib.uniffi_posixlake_checksum_constructor_nfsserver_new.argtypes = (
)
_UniffiLib.uniffi_posixlake_checksum_constructor_nfsserver_new.restype = ctypes.c_uint16
_UniffiLib.ffi_posixlake_uniffi_contract_version.argtypes = (
)
_UniffiLib.ffi_posixlake_uniffi_contract_version.restype = ctypes.c_uint32

_uniffi_check_contract_api_version(_UniffiLib)
# _uniffi_check_api_checksums(_UniffiLib)

# Public interface members begin here.


class _UniffiConverterUInt16(_UniffiConverterPrimitiveInt):
    CLASS_NAME = "u16"
    VALUE_MIN = 0
    VALUE_MAX = 2**16

    @staticmethod
    def read(buf):
        return buf.read_u16()

    @staticmethod
    def write(value, buf):
        buf.write_u16(value)

class _UniffiConverterUInt64(_UniffiConverterPrimitiveInt):
    CLASS_NAME = "u64"
    VALUE_MIN = 0
    VALUE_MAX = 2**64

    @staticmethod
    def read(buf):
        return buf.read_u64()

    @staticmethod
    def write(value, buf):
        buf.write_u64(value)

class _UniffiConverterInt64(_UniffiConverterPrimitiveInt):
    CLASS_NAME = "i64"
    VALUE_MIN = -2**63
    VALUE_MAX = 2**63

    @staticmethod
    def read(buf):
        return buf.read_i64()

    @staticmethod
    def write(value, buf):
        buf.write_i64(value)

class _UniffiConverterDouble(_UniffiConverterPrimitiveFloat):
    @staticmethod
    def read(buf):
        return buf.read_double()

    @staticmethod
    def write(value, buf):
        buf.write_double(value)

class _UniffiConverterBool:
    @classmethod
    def check_lower(cls, value):
        return not not value

    @classmethod
    def lower(cls, value):
        return 1 if value else 0

    @staticmethod
    def lift(value):
        return value != 0

    @classmethod
    def read(cls, buf):
        return cls.lift(buf.read_u8())

    @classmethod
    def write(cls, value, buf):
        buf.write_u8(value)

class _UniffiConverterString:
    @staticmethod
    def check_lower(value):
        if not isinstance(value, str):
            raise TypeError("argument must be str, not {}".format(type(value).__name__))
        return value

    @staticmethod
    def read(buf):
        size = buf.read_i32()
        if size < 0:
            raise InternalError("Unexpected negative string length")
        utf8_bytes = buf.read(size)
        return utf8_bytes.decode("utf-8")

    @staticmethod
    def write(value, buf):
        utf8_bytes = value.encode("utf-8")
        buf.write_i32(len(utf8_bytes))
        buf.write(utf8_bytes)

    @staticmethod
    def lift(buf):
        with buf.consume_with_stream() as stream:
            return stream.read(stream.remaining()).decode("utf-8")

    @staticmethod
    def lower(value):
        with _UniffiRustBuffer.alloc_with_builder() as builder:
            builder.write(value.encode("utf-8"))
            return builder.finalize()






class DataSkippingStats:
    """
    Data skipping statistics
    """

    total_files: "int"
    files_read: "int"
    files_skipped: "int"
    bytes_scanned: "int"
    bytes_skipped: "int"
    def __init__(self, *, total_files: "int", files_read: "int", files_skipped: "int", bytes_scanned: "int", bytes_skipped: "int"):
        self.total_files = total_files
        self.files_read = files_read
        self.files_skipped = files_skipped
        self.bytes_scanned = bytes_scanned
        self.bytes_skipped = bytes_skipped

    def __str__(self):
        return "DataSkippingStats(total_files={}, files_read={}, files_skipped={}, bytes_scanned={}, bytes_skipped={})".format(self.total_files, self.files_read, self.files_skipped, self.bytes_scanned, self.bytes_skipped)

    def __eq__(self, other):
        if self.total_files != other.total_files:
            return False
        if self.files_read != other.files_read:
            return False
        if self.files_skipped != other.files_skipped:
            return False
        if self.bytes_scanned != other.bytes_scanned:
            return False
        if self.bytes_skipped != other.bytes_skipped:
            return False
        return True

class _UniffiConverterTypeDataSkippingStats(_UniffiConverterRustBuffer):
    @staticmethod
    def read(buf):
        return DataSkippingStats(
            total_files=_UniffiConverterUInt64.read(buf),
            files_read=_UniffiConverterUInt64.read(buf),
            files_skipped=_UniffiConverterUInt64.read(buf),
            bytes_scanned=_UniffiConverterUInt64.read(buf),
            bytes_skipped=_UniffiConverterUInt64.read(buf),
        )

    @staticmethod
    def check_lower(value):
        _UniffiConverterUInt64.check_lower(value.total_files)
        _UniffiConverterUInt64.check_lower(value.files_read)
        _UniffiConverterUInt64.check_lower(value.files_skipped)
        _UniffiConverterUInt64.check_lower(value.bytes_scanned)
        _UniffiConverterUInt64.check_lower(value.bytes_skipped)

    @staticmethod
    def write(value, buf):
        _UniffiConverterUInt64.write(value.total_files, buf)
        _UniffiConverterUInt64.write(value.files_read, buf)
        _UniffiConverterUInt64.write(value.files_skipped, buf)
        _UniffiConverterUInt64.write(value.bytes_scanned, buf)
        _UniffiConverterUInt64.write(value.bytes_skipped, buf)


class DatabaseMetrics:
    """
    Database metrics for monitoring
    """

    total_queries: "int"
    total_inserts: "int"
    total_deletes: "int"
    total_transactions: "int"
    total_errors: "int"
    avg_query_latency_ms: "float"
    max_query_latency_ms: "float"
    uptime_seconds: "float"
    def __init__(self, *, total_queries: "int", total_inserts: "int", total_deletes: "int", total_transactions: "int", total_errors: "int", avg_query_latency_ms: "float", max_query_latency_ms: "float", uptime_seconds: "float"):
        self.total_queries = total_queries
        self.total_inserts = total_inserts
        self.total_deletes = total_deletes
        self.total_transactions = total_transactions
        self.total_errors = total_errors
        self.avg_query_latency_ms = avg_query_latency_ms
        self.max_query_latency_ms = max_query_latency_ms
        self.uptime_seconds = uptime_seconds

    def __str__(self):
        return "DatabaseMetrics(total_queries={}, total_inserts={}, total_deletes={}, total_transactions={}, total_errors={}, avg_query_latency_ms={}, max_query_latency_ms={}, uptime_seconds={})".format(self.total_queries, self.total_inserts, self.total_deletes, self.total_transactions, self.total_errors, self.avg_query_latency_ms, self.max_query_latency_ms, self.uptime_seconds)

    def __eq__(self, other):
        if self.total_queries != other.total_queries:
            return False
        if self.total_inserts != other.total_inserts:
            return False
        if self.total_deletes != other.total_deletes:
            return False
        if self.total_transactions != other.total_transactions:
            return False
        if self.total_errors != other.total_errors:
            return False
        if self.avg_query_latency_ms != other.avg_query_latency_ms:
            return False
        if self.max_query_latency_ms != other.max_query_latency_ms:
            return False
        if self.uptime_seconds != other.uptime_seconds:
            return False
        return True

class _UniffiConverterTypeDatabaseMetrics(_UniffiConverterRustBuffer):
    @staticmethod
    def read(buf):
        return DatabaseMetrics(
            total_queries=_UniffiConverterUInt64.read(buf),
            total_inserts=_UniffiConverterUInt64.read(buf),
            total_deletes=_UniffiConverterUInt64.read(buf),
            total_transactions=_UniffiConverterUInt64.read(buf),
            total_errors=_UniffiConverterUInt64.read(buf),
            avg_query_latency_ms=_UniffiConverterDouble.read(buf),
            max_query_latency_ms=_UniffiConverterDouble.read(buf),
            uptime_seconds=_UniffiConverterDouble.read(buf),
        )

    @staticmethod
    def check_lower(value):
        _UniffiConverterUInt64.check_lower(value.total_queries)
        _UniffiConverterUInt64.check_lower(value.total_inserts)
        _UniffiConverterUInt64.check_lower(value.total_deletes)
        _UniffiConverterUInt64.check_lower(value.total_transactions)
        _UniffiConverterUInt64.check_lower(value.total_errors)
        _UniffiConverterDouble.check_lower(value.avg_query_latency_ms)
        _UniffiConverterDouble.check_lower(value.max_query_latency_ms)
        _UniffiConverterDouble.check_lower(value.uptime_seconds)

    @staticmethod
    def write(value, buf):
        _UniffiConverterUInt64.write(value.total_queries, buf)
        _UniffiConverterUInt64.write(value.total_inserts, buf)
        _UniffiConverterUInt64.write(value.total_deletes, buf)
        _UniffiConverterUInt64.write(value.total_transactions, buf)
        _UniffiConverterUInt64.write(value.total_errors, buf)
        _UniffiConverterDouble.write(value.avg_query_latency_ms, buf)
        _UniffiConverterDouble.write(value.max_query_latency_ms, buf)
        _UniffiConverterDouble.write(value.uptime_seconds, buf)


class Field:
    """
    Schema field definition
    """

    name: "str"
    data_type: "str"
    nullable: "bool"
    def __init__(self, *, name: "str", data_type: "str", nullable: "bool"):
        self.name = name
        self.data_type = data_type
        self.nullable = nullable

    def __str__(self):
        return "Field(name={}, data_type={}, nullable={})".format(self.name, self.data_type, self.nullable)

    def __eq__(self, other):
        if self.name != other.name:
            return False
        if self.data_type != other.data_type:
            return False
        if self.nullable != other.nullable:
            return False
        return True

class _UniffiConverterTypeField(_UniffiConverterRustBuffer):
    @staticmethod
    def read(buf):
        return Field(
            name=_UniffiConverterString.read(buf),
            data_type=_UniffiConverterString.read(buf),
            nullable=_UniffiConverterBool.read(buf),
        )

    @staticmethod
    def check_lower(value):
        _UniffiConverterString.check_lower(value.name)
        _UniffiConverterString.check_lower(value.data_type)
        _UniffiConverterBool.check_lower(value.nullable)

    @staticmethod
    def write(value, buf):
        _UniffiConverterString.write(value.name, buf)
        _UniffiConverterString.write(value.data_type, buf)
        _UniffiConverterBool.write(value.nullable, buf)


class HealthStatus:
    """
    Health status
    """

    status: "str"
    uptime_seconds: "float"
    total_files: "int"
    total_rows: "int"
    total_size_bytes: "int"
    def __init__(self, *, status: "str", uptime_seconds: "float", total_files: "int", total_rows: "int", total_size_bytes: "int"):
        self.status = status
        self.uptime_seconds = uptime_seconds
        self.total_files = total_files
        self.total_rows = total_rows
        self.total_size_bytes = total_size_bytes

    def __str__(self):
        return "HealthStatus(status={}, uptime_seconds={}, total_files={}, total_rows={}, total_size_bytes={})".format(self.status, self.uptime_seconds, self.total_files, self.total_rows, self.total_size_bytes)

    def __eq__(self, other):
        if self.status != other.status:
            return False
        if self.uptime_seconds != other.uptime_seconds:
            return False
        if self.total_files != other.total_files:
            return False
        if self.total_rows != other.total_rows:
            return False
        if self.total_size_bytes != other.total_size_bytes:
            return False
        return True

class _UniffiConverterTypeHealthStatus(_UniffiConverterRustBuffer):
    @staticmethod
    def read(buf):
        return HealthStatus(
            status=_UniffiConverterString.read(buf),
            uptime_seconds=_UniffiConverterDouble.read(buf),
            total_files=_UniffiConverterUInt64.read(buf),
            total_rows=_UniffiConverterUInt64.read(buf),
            total_size_bytes=_UniffiConverterUInt64.read(buf),
        )

    @staticmethod
    def check_lower(value):
        _UniffiConverterString.check_lower(value.status)
        _UniffiConverterDouble.check_lower(value.uptime_seconds)
        _UniffiConverterUInt64.check_lower(value.total_files)
        _UniffiConverterUInt64.check_lower(value.total_rows)
        _UniffiConverterUInt64.check_lower(value.total_size_bytes)

    @staticmethod
    def write(value, buf):
        _UniffiConverterString.write(value.status, buf)
        _UniffiConverterDouble.write(value.uptime_seconds, buf)
        _UniffiConverterUInt64.write(value.total_files, buf)
        _UniffiConverterUInt64.write(value.total_rows, buf)
        _UniffiConverterUInt64.write(value.total_size_bytes, buf)


class Row:
    """
    Query result row
    """

    values: "dict[str, str]"
    def __init__(self, *, values: "dict[str, str]"):
        self.values = values

    def __str__(self):
        return "Row(values={})".format(self.values)

    def __eq__(self, other):
        if self.values != other.values:
            return False
        return True

class _UniffiConverterTypeRow(_UniffiConverterRustBuffer):
    @staticmethod
    def read(buf):
        return Row(
            values=_UniffiConverterMapStringString.read(buf),
        )

    @staticmethod
    def check_lower(value):
        _UniffiConverterMapStringString.check_lower(value.values)

    @staticmethod
    def write(value, buf):
        _UniffiConverterMapStringString.write(value.values, buf)


class S3Config:
    """
    S3 configuration
    """

    endpoint: "str"
    access_key_id: "str"
    secret_access_key: "str"
    region: "str"
    def __init__(self, *, endpoint: "str", access_key_id: "str", secret_access_key: "str", region: "str"):
        self.endpoint = endpoint
        self.access_key_id = access_key_id
        self.secret_access_key = secret_access_key
        self.region = region

    def __str__(self):
        return "S3Config(endpoint={}, access_key_id={}, secret_access_key={}, region={})".format(self.endpoint, self.access_key_id, self.secret_access_key, self.region)

    def __eq__(self, other):
        if self.endpoint != other.endpoint:
            return False
        if self.access_key_id != other.access_key_id:
            return False
        if self.secret_access_key != other.secret_access_key:
            return False
        if self.region != other.region:
            return False
        return True

class _UniffiConverterTypeS3Config(_UniffiConverterRustBuffer):
    @staticmethod
    def read(buf):
        return S3Config(
            endpoint=_UniffiConverterString.read(buf),
            access_key_id=_UniffiConverterString.read(buf),
            secret_access_key=_UniffiConverterString.read(buf),
            region=_UniffiConverterString.read(buf),
        )

    @staticmethod
    def check_lower(value):
        _UniffiConverterString.check_lower(value.endpoint)
        _UniffiConverterString.check_lower(value.access_key_id)
        _UniffiConverterString.check_lower(value.secret_access_key)
        _UniffiConverterString.check_lower(value.region)

    @staticmethod
    def write(value, buf):
        _UniffiConverterString.write(value.endpoint, buf)
        _UniffiConverterString.write(value.access_key_id, buf)
        _UniffiConverterString.write(value.secret_access_key, buf)
        _UniffiConverterString.write(value.region, buf)


class Schema:
    """
    Database schema
    """

    fields: "typing.List[Field]"
    def __init__(self, *, fields: "typing.List[Field]"):
        self.fields = fields

    def __str__(self):
        return "Schema(fields={})".format(self.fields)

    def __eq__(self, other):
        if self.fields != other.fields:
            return False
        return True

class _UniffiConverterTypeSchema(_UniffiConverterRustBuffer):
    @staticmethod
    def read(buf):
        return Schema(
            fields=_UniffiConverterSequenceTypeField.read(buf),
        )

    @staticmethod
    def check_lower(value):
        _UniffiConverterSequenceTypeField.check_lower(value.fields)

    @staticmethod
    def write(value, buf):
        _UniffiConverterSequenceTypeField.write(value.fields, buf)


# PosixLakeError
# We want to define each variant as a nested class that's also a subclass,
# which is tricky in Python.  To accomplish this we're going to create each
# class separately, then manually add the child classes to the base class's
# __dict__.  All of this happens in dummy class to avoid polluting the module
# namespace.
class PosixLakeError(Exception):
    """
    Error types for posixlake Python bindings
    """

    pass

_UniffiTempPosixLakeError = PosixLakeError

class PosixLakeError:  # type: ignore
    """
    Error types for posixlake Python bindings
    """

    class IoError(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.IoError({})".format(str(self))
    _UniffiTempPosixLakeError.IoError = IoError # type: ignore
    class SerializationError(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.SerializationError({})".format(str(self))
    _UniffiTempPosixLakeError.SerializationError = SerializationError # type: ignore
    class ObjectStoreError(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.ObjectStoreError({})".format(str(self))
    _UniffiTempPosixLakeError.ObjectStoreError = ObjectStoreError # type: ignore
    class ArrowError(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.ArrowError({})".format(str(self))
    _UniffiTempPosixLakeError.ArrowError = ArrowError # type: ignore
    class ParquetError(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.ParquetError({})".format(str(self))
    _UniffiTempPosixLakeError.ParquetError = ParquetError # type: ignore
    class DatabaseNotFound(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.DatabaseNotFound({})".format(str(self))
    _UniffiTempPosixLakeError.DatabaseNotFound = DatabaseNotFound # type: ignore
    class RecordNotFound(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.RecordNotFound({})".format(str(self))
    _UniffiTempPosixLakeError.RecordNotFound = RecordNotFound # type: ignore
    class DatabaseAlreadyExists(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.DatabaseAlreadyExists({})".format(str(self))
    _UniffiTempPosixLakeError.DatabaseAlreadyExists = DatabaseAlreadyExists # type: ignore
    class InvalidOperation(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.InvalidOperation({})".format(str(self))
    _UniffiTempPosixLakeError.InvalidOperation = InvalidOperation # type: ignore
    class TransactionConflict(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.TransactionConflict({})".format(str(self))
    _UniffiTempPosixLakeError.TransactionConflict = TransactionConflict # type: ignore
    class WalError(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.WalError({})".format(str(self))
    _UniffiTempPosixLakeError.WalError = WalError # type: ignore
    class BincodeError(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.BincodeError({})".format(str(self))
    _UniffiTempPosixLakeError.BincodeError = BincodeError # type: ignore
    class DeltaLakeError(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.DeltaLakeError({})".format(str(self))
    _UniffiTempPosixLakeError.DeltaLakeError = DeltaLakeError # type: ignore
    class Other(_UniffiTempPosixLakeError):
        def __init__(self, message):
            super().__init__(", ".join([
                "message={!r}".format(message),
            ]))
            self.message = message

        def __repr__(self):
            return "PosixLakeError.Other({})".format(str(self))
    _UniffiTempPosixLakeError.Other = Other # type: ignore

PosixLakeError = _UniffiTempPosixLakeError # type: ignore
del _UniffiTempPosixLakeError


class _UniffiConverterTypePosixLakeError(_UniffiConverterRustBuffer):
    @staticmethod
    def read(buf):
        variant = buf.read_i32()
        if variant == 1:
            return PosixLakeError.IoError(
                _UniffiConverterString.read(buf),
            )
        if variant == 2:
            return PosixLakeError.SerializationError(
                _UniffiConverterString.read(buf),
            )
        if variant == 3:
            return PosixLakeError.ObjectStoreError(
                _UniffiConverterString.read(buf),
            )
        if variant == 4:
            return PosixLakeError.ArrowError(
                _UniffiConverterString.read(buf),
            )
        if variant == 5:
            return PosixLakeError.ParquetError(
                _UniffiConverterString.read(buf),
            )
        if variant == 6:
            return PosixLakeError.DatabaseNotFound(
                _UniffiConverterString.read(buf),
            )
        if variant == 7:
            return PosixLakeError.RecordNotFound(
                _UniffiConverterString.read(buf),
            )
        if variant == 8:
            return PosixLakeError.DatabaseAlreadyExists(
                _UniffiConverterString.read(buf),
            )
        if variant == 9:
            return PosixLakeError.InvalidOperation(
                _UniffiConverterString.read(buf),
            )
        if variant == 10:
            return PosixLakeError.TransactionConflict(
                _UniffiConverterString.read(buf),
            )
        if variant == 11:
            return PosixLakeError.WalError(
                _UniffiConverterString.read(buf),
            )
        if variant == 12:
            return PosixLakeError.BincodeError(
                _UniffiConverterString.read(buf),
            )
        if variant == 13:
            return PosixLakeError.DeltaLakeError(
                _UniffiConverterString.read(buf),
            )
        if variant == 14:
            return PosixLakeError.Other(
                _UniffiConverterString.read(buf),
            )
        raise InternalError("Raw enum value doesn't match any cases")

    @staticmethod
    def check_lower(value):
        if isinstance(value, PosixLakeError.IoError):
            _UniffiConverterString.check_lower(value.message)
            return
        if isinstance(value, PosixLakeError.SerializationError):
            _UniffiConverterString.check_lower(value.message)
            return
        if isinstance(value, PosixLakeError.ObjectStoreError):
            _UniffiConverterString.check_lower(value.message)
            return
        if isinstance(value, PosixLakeError.ArrowError):
            _UniffiConverterString.check_lower(value.message)
            return
        if isinstance(value, PosixLakeError.ParquetError):
            _UniffiConverterString.check_lower(value.message)
            return
        if isinstance(value, PosixLakeError.DatabaseNotFound):
            _UniffiConverterString.check_lower(value.message)
            return
        if isinstance(value, PosixLakeError.RecordNotFound):
            _UniffiConverterString.check_lower(value.message)
            return
        if isinstance(value, PosixLakeError.DatabaseAlreadyExists):
            _UniffiConverterString.check_lower(value.message)
            return
        if isinstance(value, PosixLakeError.InvalidOperation):
            _UniffiConverterString.check_lower(value.message)
            return
        if isinstance(value, PosixLakeError.TransactionConflict):
            _UniffiConverterString.check_lower(value.message)
            return
        if isinstance(value, PosixLakeError.WalError):
            _UniffiConverterString.check_lower(value.message)
            return
        if isinstance(value, PosixLakeError.BincodeError):
            _UniffiConverterString.check_lower(value.message)
            return
        if isinstance(value, PosixLakeError.DeltaLakeError):
            _UniffiConverterString.check_lower(value.message)
            return
        if isinstance(value, PosixLakeError.Other):
            _UniffiConverterString.check_lower(value.message)
            return

    @staticmethod
    def write(value, buf):
        if isinstance(value, PosixLakeError.IoError):
            buf.write_i32(1)
            _UniffiConverterString.write(value.message, buf)
        if isinstance(value, PosixLakeError.SerializationError):
            buf.write_i32(2)
            _UniffiConverterString.write(value.message, buf)
        if isinstance(value, PosixLakeError.ObjectStoreError):
            buf.write_i32(3)
            _UniffiConverterString.write(value.message, buf)
        if isinstance(value, PosixLakeError.ArrowError):
            buf.write_i32(4)
            _UniffiConverterString.write(value.message, buf)
        if isinstance(value, PosixLakeError.ParquetError):
            buf.write_i32(5)
            _UniffiConverterString.write(value.message, buf)
        if isinstance(value, PosixLakeError.DatabaseNotFound):
            buf.write_i32(6)
            _UniffiConverterString.write(value.message, buf)
        if isinstance(value, PosixLakeError.RecordNotFound):
            buf.write_i32(7)
            _UniffiConverterString.write(value.message, buf)
        if isinstance(value, PosixLakeError.DatabaseAlreadyExists):
            buf.write_i32(8)
            _UniffiConverterString.write(value.message, buf)
        if isinstance(value, PosixLakeError.InvalidOperation):
            buf.write_i32(9)
            _UniffiConverterString.write(value.message, buf)
        if isinstance(value, PosixLakeError.TransactionConflict):
            buf.write_i32(10)
            _UniffiConverterString.write(value.message, buf)
        if isinstance(value, PosixLakeError.WalError):
            buf.write_i32(11)
            _UniffiConverterString.write(value.message, buf)
        if isinstance(value, PosixLakeError.BincodeError):
            buf.write_i32(12)
            _UniffiConverterString.write(value.message, buf)
        if isinstance(value, PosixLakeError.DeltaLakeError):
            buf.write_i32(13)
            _UniffiConverterString.write(value.message, buf)
        if isinstance(value, PosixLakeError.Other):
            buf.write_i32(14)
            _UniffiConverterString.write(value.message, buf)



class _UniffiConverterSequenceString(_UniffiConverterRustBuffer):
    @classmethod
    def check_lower(cls, value):
        for item in value:
            _UniffiConverterString.check_lower(item)

    @classmethod
    def write(cls, value, buf):
        items = len(value)
        buf.write_i32(items)
        for item in value:
            _UniffiConverterString.write(item, buf)

    @classmethod
    def read(cls, buf):
        count = buf.read_i32()
        if count < 0:
            raise InternalError("Unexpected negative sequence length")

        return [
            _UniffiConverterString.read(buf) for i in range(count)
        ]



class _UniffiConverterSequenceTypeField(_UniffiConverterRustBuffer):
    @classmethod
    def check_lower(cls, value):
        for item in value:
            _UniffiConverterTypeField.check_lower(item)

    @classmethod
    def write(cls, value, buf):
        items = len(value)
        buf.write_i32(items)
        for item in value:
            _UniffiConverterTypeField.write(item, buf)

    @classmethod
    def read(cls, buf):
        count = buf.read_i32()
        if count < 0:
            raise InternalError("Unexpected negative sequence length")

        return [
            _UniffiConverterTypeField.read(buf) for i in range(count)
        ]



class _UniffiConverterSequenceTypeRow(_UniffiConverterRustBuffer):
    @classmethod
    def check_lower(cls, value):
        for item in value:
            _UniffiConverterTypeRow.check_lower(item)

    @classmethod
    def write(cls, value, buf):
        items = len(value)
        buf.write_i32(items)
        for item in value:
            _UniffiConverterTypeRow.write(item, buf)

    @classmethod
    def read(cls, buf):
        count = buf.read_i32()
        if count < 0:
            raise InternalError("Unexpected negative sequence length")

        return [
            _UniffiConverterTypeRow.read(buf) for i in range(count)
        ]



class _UniffiConverterMapStringString(_UniffiConverterRustBuffer):
    @classmethod
    def check_lower(cls, items):
        for (key, value) in items.items():
            _UniffiConverterString.check_lower(key)
            _UniffiConverterString.check_lower(value)

    @classmethod
    def write(cls, items, buf):
        buf.write_i32(len(items))
        for (key, value) in items.items():
            _UniffiConverterString.write(key, buf)
            _UniffiConverterString.write(value, buf)

    @classmethod
    def read(cls, buf):
        count = buf.read_i32()
        if count < 0:
            raise InternalError("Unexpected negative map size")

        # It would be nice to use a dict comprehension,
        # but in Python 3.7 and before the evaluation order is not according to spec,
        # so we we're reading the value before the key.
        # This loop makes the order explicit: first reading the key, then the value.
        d = {}
        for i in range(count):
            key = _UniffiConverterString.read(buf)
            val = _UniffiConverterString.read(buf)
            d[key] = val
        return d

# objects.
class DatabaseOpsProtocol(typing.Protocol):
    """
    Main DatabaseOps wrapper for Python
    """

    def backup(self, backup_path: "str"):
        """
        Create a full backup
        """

        raise NotImplementedError
    def backup_incremental(self, base_backup_path: "str",incremental_path: "str"):
        """
        Create an incremental backup
        """

        raise NotImplementedError
    def create_user(self, username: "str",password: "str",roles: "typing.List[str]"):
        """
        Create a new user with roles
        """

        raise NotImplementedError
    def delete_rows_where(self, predicate: "str"):
        """
        Delete rows matching a WHERE clause
        """

        raise NotImplementedError
    def flush_write_buffer(self, ):
        """
        Flush any buffered writes to Delta Lake immediately

        Forces all buffered data from insert_buffered_json() to be committed.
        Call this before reading data to ensure consistency, or at shutdown.
        """

        raise NotImplementedError
    def get_base_path(self, ):
        """
        Get database base path
        """

        raise NotImplementedError
    def get_data_skipping_stats(self, ):
        """
        Get data skipping statistics
        """

        raise NotImplementedError
    def get_metrics(self, ):
        """
        Get database metrics
        """

        raise NotImplementedError
    def get_schema(self, ):
        """
        Get database schema
        """

        raise NotImplementedError
    def health_check(self, ):
        """
        Get health status
        """

        raise NotImplementedError
    def insert_buffered_json(self, json_data: "str"):
        """
        Insert data from JSON string with buffering for better performance

        This method buffers small writes and automatically flushes when the buffer
        reaches 1000 rows (default). Use this for many small inserts to reduce
        transaction overhead.

        Returns the number of rows buffered (not necessarily committed yet).
        Call flush_write_buffer() to force a commit.
        """

        raise NotImplementedError
    def insert_json(self, json_data: "str"):
        """
        Insert data from JSON string
        """

        raise NotImplementedError
    def merge_json(self, json_data: "str",join_column: "str"):
        """
        Execute MERGE (UPSERT) operation from JSON data

        JSON must be an array of objects with an "_op" field specifying the operation:
        - "INSERT": Insert new rows
        - "UPDATE": Update existing rows
        - "DELETE": Delete existing rows

        The join is performed on the specified join_column (typically "id").

        Returns a JSON string with merge metrics: rows_inserted, rows_updated, rows_deleted
        """

        raise NotImplementedError
    def optimize(self, ):
        """
        Run OPTIMIZE to compact files
        """

        raise NotImplementedError
    def optimize_with_filter(self, filter: "str"):
        """
        Run OPTIMIZE with a filter
        """

        raise NotImplementedError
    def optimize_with_target_size(self, target_size_bytes: "int"):
        """
        Run OPTIMIZE with a target file size
        """

        raise NotImplementedError
    def query(self, sql: "str"):
        """
        Query data with SQL
        """

        raise NotImplementedError
    def query_json(self, sql: "str"):
        """
        Query data and return as JSON string
        """

        raise NotImplementedError
    def query_timestamp(self, sql: "str",timestamp_ms: "int"):
        """
        Query data at a specific timestamp (milliseconds since epoch)
        """

        raise NotImplementedError
    def query_timestamp_json(self, sql: "str",timestamp_ms: "int"):
        """
        Query data at a specific timestamp and return as JSON
        """

        raise NotImplementedError
    def query_version(self, sql: "str",version: "int"):
        """
        Query data at a specific version
        """

        raise NotImplementedError
    def query_version_json(self, sql: "str",version: "int"):
        """
        Query data at a specific version and return as JSON
        """

        raise NotImplementedError
    def vacuum(self, retention_hours: "int"):
        """
        Run VACUUM to remove old files
        """

        raise NotImplementedError
    def vacuum_dry_run(self, retention_hours: "int"):
        """
        Run VACUUM dry run to see what would be deleted
        """

        raise NotImplementedError
    def zorder(self, columns: "typing.List[str]"):
        """
        Run Z-ORDER on specified columns
        """

        raise NotImplementedError
# DatabaseOps is a Rust-only trait - it's a wrapper around a Rust implementation.
class DatabaseOps():
    """
    Main DatabaseOps wrapper for Python
    """

    _pointer: ctypes.c_void_p
    
    def __init__(self, *args, **kwargs):
        raise ValueError("This class has no default constructor")

    def __del__(self):
        # In case of partial initialization of instances.
        pointer = getattr(self, "_pointer", None)
        if pointer is not None:
            _uniffi_rust_call(_UniffiLib.uniffi_posixlake_fn_free_databaseops, pointer)

    def _uniffi_clone_pointer(self):
        return _uniffi_rust_call(_UniffiLib.uniffi_posixlake_fn_clone_databaseops, self._pointer)

    # Used by alternative constructors or any methods which return this type.
    @classmethod
    def _make_instance_(cls, pointer):
        # Lightly yucky way to bypass the usual __init__ logic
        # and just create a new instance with the required pointer.
        inst = cls.__new__(cls)
        inst._pointer = pointer
        return inst
    @classmethod
    def create(cls, path: "str",schema: "Schema"):
        """
        Create a new database with the given schema
        """

        _UniffiConverterString.check_lower(path)
        
        _UniffiConverterTypeSchema.check_lower(schema)
        
        # Call the (fallible) function before creating any half-baked object instances.
        pointer = _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create,
        _UniffiConverterString.lower(path),
        _UniffiConverterTypeSchema.lower(schema))
        return cls._make_instance_(pointer)

    @classmethod
    def create_from_csv(cls, db_path: "str",csv_path: "str"):
        """
        Create a new database by importing from a CSV file

        Schema is automatically inferred from the CSV:
        - Column names from header row
        - Types inferred from first 10 data rows (Int64, Float64, Boolean, or String)
        - All columns nullable
        """

        _UniffiConverterString.check_lower(db_path)
        
        _UniffiConverterString.check_lower(csv_path)
        
        # Call the (fallible) function before creating any half-baked object instances.
        pointer = _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create_from_csv,
        _UniffiConverterString.lower(db_path),
        _UniffiConverterString.lower(csv_path))
        return cls._make_instance_(pointer)

    @classmethod
    def create_from_parquet(cls, db_path: "str",parquet_path: "str"):
        """
        Create a new database by importing from Parquet file(s)

        Schema is read directly from Parquet metadata.
        Supports single file or glob patterns (e.g., "data/*.parquet").
        """

        _UniffiConverterString.check_lower(db_path)
        
        _UniffiConverterString.check_lower(parquet_path)
        
        # Call the (fallible) function before creating any half-baked object instances.
        pointer = _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create_from_parquet,
        _UniffiConverterString.lower(db_path),
        _UniffiConverterString.lower(parquet_path))
        return cls._make_instance_(pointer)

    @classmethod
    def create_with_auth(cls, path: "str",schema: "Schema",auth_enabled: "bool"):
        """
        Create a new database with authentication enabled
        """

        _UniffiConverterString.check_lower(path)
        
        _UniffiConverterTypeSchema.check_lower(schema)
        
        _UniffiConverterBool.check_lower(auth_enabled)
        
        # Call the (fallible) function before creating any half-baked object instances.
        pointer = _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create_with_auth,
        _UniffiConverterString.lower(path),
        _UniffiConverterTypeSchema.lower(schema),
        _UniffiConverterBool.lower(auth_enabled))
        return cls._make_instance_(pointer)

    @classmethod
    def create_with_s3(cls, s3_path: "str",schema: "Schema",s3_config: "S3Config"):
        """
        Create a new database on S3
        """

        _UniffiConverterString.check_lower(s3_path)
        
        _UniffiConverterTypeSchema.check_lower(schema)
        
        _UniffiConverterTypeS3Config.check_lower(s3_config)
        
        # Call the (fallible) function before creating any half-baked object instances.
        pointer = _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_create_with_s3,
        _UniffiConverterString.lower(s3_path),
        _UniffiConverterTypeSchema.lower(schema),
        _UniffiConverterTypeS3Config.lower(s3_config))
        return cls._make_instance_(pointer)

    @classmethod
    def open(cls, path: "str"):
        """
        Open an existing database
        """

        _UniffiConverterString.check_lower(path)
        
        # Call the (fallible) function before creating any half-baked object instances.
        pointer = _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_open,
        _UniffiConverterString.lower(path))
        return cls._make_instance_(pointer)

    @classmethod
    def open_with_credentials(cls, path: "str",username: "str",password: "str"):
        """
        Open an existing database with credentials
        """

        _UniffiConverterString.check_lower(path)
        
        _UniffiConverterString.check_lower(username)
        
        _UniffiConverterString.check_lower(password)
        
        # Call the (fallible) function before creating any half-baked object instances.
        pointer = _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_open_with_credentials,
        _UniffiConverterString.lower(path),
        _UniffiConverterString.lower(username),
        _UniffiConverterString.lower(password))
        return cls._make_instance_(pointer)

    @classmethod
    def open_with_s3(cls, s3_path: "str",s3_config: "S3Config"):
        """
        Open an existing database on S3
        """

        _UniffiConverterString.check_lower(s3_path)
        
        _UniffiConverterTypeS3Config.check_lower(s3_config)
        
        # Call the (fallible) function before creating any half-baked object instances.
        pointer = _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_constructor_databaseops_open_with_s3,
        _UniffiConverterString.lower(s3_path),
        _UniffiConverterTypeS3Config.lower(s3_config))
        return cls._make_instance_(pointer)



    def backup(self, backup_path: "str") -> None:
        """
        Create a full backup
        """

        _UniffiConverterString.check_lower(backup_path)
        
        _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_backup,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(backup_path))






    def backup_incremental(self, base_backup_path: "str",incremental_path: "str") -> None:
        """
        Create an incremental backup
        """

        _UniffiConverterString.check_lower(base_backup_path)
        
        _UniffiConverterString.check_lower(incremental_path)
        
        _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_backup_incremental,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(base_backup_path),
        _UniffiConverterString.lower(incremental_path))






    def create_user(self, username: "str",password: "str",roles: "typing.List[str]") -> None:
        """
        Create a new user with roles
        """

        _UniffiConverterString.check_lower(username)
        
        _UniffiConverterString.check_lower(password)
        
        _UniffiConverterSequenceString.check_lower(roles)
        
        _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_create_user,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(username),
        _UniffiConverterString.lower(password),
        _UniffiConverterSequenceString.lower(roles))






    def delete_rows_where(self, predicate: "str") -> "int":
        """
        Delete rows matching a WHERE clause
        """

        _UniffiConverterString.check_lower(predicate)
        
        return _UniffiConverterUInt64.lift(
            _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_delete_rows_where,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(predicate))
        )





    def flush_write_buffer(self, ) -> None:
        """
        Flush any buffered writes to Delta Lake immediately

        Forces all buffered data from insert_buffered_json() to be committed.
        Call this before reading data to ensure consistency, or at shutdown.
        """

        _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_flush_write_buffer,self._uniffi_clone_pointer(),)






    def get_base_path(self, ) -> "str":
        """
        Get database base path
        """

        return _UniffiConverterString.lift(
            _uniffi_rust_call(_UniffiLib.uniffi_posixlake_fn_method_databaseops_get_base_path,self._uniffi_clone_pointer(),)
        )





    def get_data_skipping_stats(self, ) -> "DataSkippingStats":
        """
        Get data skipping statistics
        """

        return _UniffiConverterTypeDataSkippingStats.lift(
            _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_get_data_skipping_stats,self._uniffi_clone_pointer(),)
        )





    def get_metrics(self, ) -> "DatabaseMetrics":
        """
        Get database metrics
        """

        return _UniffiConverterTypeDatabaseMetrics.lift(
            _uniffi_rust_call(_UniffiLib.uniffi_posixlake_fn_method_databaseops_get_metrics,self._uniffi_clone_pointer(),)
        )





    def get_schema(self, ) -> "Schema":
        """
        Get database schema
        """

        return _UniffiConverterTypeSchema.lift(
            _uniffi_rust_call(_UniffiLib.uniffi_posixlake_fn_method_databaseops_get_schema,self._uniffi_clone_pointer(),)
        )





    def health_check(self, ) -> "HealthStatus":
        """
        Get health status
        """

        return _UniffiConverterTypeHealthStatus.lift(
            _uniffi_rust_call(_UniffiLib.uniffi_posixlake_fn_method_databaseops_health_check,self._uniffi_clone_pointer(),)
        )





    def insert_buffered_json(self, json_data: "str") -> "int":
        """
        Insert data from JSON string with buffering for better performance

        This method buffers small writes and automatically flushes when the buffer
        reaches 1000 rows (default). Use this for many small inserts to reduce
        transaction overhead.

        Returns the number of rows buffered (not necessarily committed yet).
        Call flush_write_buffer() to force a commit.
        """

        _UniffiConverterString.check_lower(json_data)
        
        return _UniffiConverterUInt64.lift(
            _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_insert_buffered_json,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(json_data))
        )





    def insert_json(self, json_data: "str") -> "int":
        """
        Insert data from JSON string
        """

        _UniffiConverterString.check_lower(json_data)
        
        return _UniffiConverterUInt64.lift(
            _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_insert_json,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(json_data))
        )





    def merge_json(self, json_data: "str",join_column: "str") -> "str":
        """
        Execute MERGE (UPSERT) operation from JSON data

        JSON must be an array of objects with an "_op" field specifying the operation:
        - "INSERT": Insert new rows
        - "UPDATE": Update existing rows
        - "DELETE": Delete existing rows

        The join is performed on the specified join_column (typically "id").

        Returns a JSON string with merge metrics: rows_inserted, rows_updated, rows_deleted
        """

        _UniffiConverterString.check_lower(json_data)
        
        _UniffiConverterString.check_lower(join_column)
        
        return _UniffiConverterString.lift(
            _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_merge_json,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(json_data),
        _UniffiConverterString.lower(join_column))
        )





    def optimize(self, ) -> None:
        """
        Run OPTIMIZE to compact files
        """

        _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_optimize,self._uniffi_clone_pointer(),)






    def optimize_with_filter(self, filter: "str") -> None:
        """
        Run OPTIMIZE with a filter
        """

        _UniffiConverterString.check_lower(filter)
        
        _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_optimize_with_filter,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(filter))






    def optimize_with_target_size(self, target_size_bytes: "int") -> None:
        """
        Run OPTIMIZE with a target file size
        """

        _UniffiConverterUInt64.check_lower(target_size_bytes)
        
        _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_optimize_with_target_size,self._uniffi_clone_pointer(),
        _UniffiConverterUInt64.lower(target_size_bytes))






    def query(self, sql: "str") -> "typing.List[Row]":
        """
        Query data with SQL
        """

        _UniffiConverterString.check_lower(sql)
        
        return _UniffiConverterSequenceTypeRow.lift(
            _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_query,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(sql))
        )





    def query_json(self, sql: "str") -> "str":
        """
        Query data and return as JSON string
        """

        _UniffiConverterString.check_lower(sql)
        
        return _UniffiConverterString.lift(
            _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_json,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(sql))
        )





    def query_timestamp(self, sql: "str",timestamp_ms: "int") -> "typing.List[Row]":
        """
        Query data at a specific timestamp (milliseconds since epoch)
        """

        _UniffiConverterString.check_lower(sql)
        
        _UniffiConverterInt64.check_lower(timestamp_ms)
        
        return _UniffiConverterSequenceTypeRow.lift(
            _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_timestamp,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(sql),
        _UniffiConverterInt64.lower(timestamp_ms))
        )





    def query_timestamp_json(self, sql: "str",timestamp_ms: "int") -> "str":
        """
        Query data at a specific timestamp and return as JSON
        """

        _UniffiConverterString.check_lower(sql)
        
        _UniffiConverterInt64.check_lower(timestamp_ms)
        
        return _UniffiConverterString.lift(
            _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_timestamp_json,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(sql),
        _UniffiConverterInt64.lower(timestamp_ms))
        )





    def query_version(self, sql: "str",version: "int") -> "typing.List[Row]":
        """
        Query data at a specific version
        """

        _UniffiConverterString.check_lower(sql)
        
        _UniffiConverterInt64.check_lower(version)
        
        return _UniffiConverterSequenceTypeRow.lift(
            _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_version,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(sql),
        _UniffiConverterInt64.lower(version))
        )





    def query_version_json(self, sql: "str",version: "int") -> "str":
        """
        Query data at a specific version and return as JSON
        """

        _UniffiConverterString.check_lower(sql)
        
        _UniffiConverterInt64.check_lower(version)
        
        return _UniffiConverterString.lift(
            _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_query_version_json,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(sql),
        _UniffiConverterInt64.lower(version))
        )





    def vacuum(self, retention_hours: "int") -> None:
        """
        Run VACUUM to remove old files
        """

        _UniffiConverterUInt64.check_lower(retention_hours)
        
        _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_vacuum,self._uniffi_clone_pointer(),
        _UniffiConverterUInt64.lower(retention_hours))






    def vacuum_dry_run(self, retention_hours: "int") -> "typing.List[str]":
        """
        Run VACUUM dry run to see what would be deleted
        """

        _UniffiConverterUInt64.check_lower(retention_hours)
        
        return _UniffiConverterSequenceString.lift(
            _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_vacuum_dry_run,self._uniffi_clone_pointer(),
        _UniffiConverterUInt64.lower(retention_hours))
        )





    def zorder(self, columns: "typing.List[str]") -> None:
        """
        Run Z-ORDER on specified columns
        """

        _UniffiConverterSequenceString.check_lower(columns)
        
        _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_databaseops_zorder,self._uniffi_clone_pointer(),
        _UniffiConverterSequenceString.lower(columns))







class _UniffiConverterTypeDatabaseOps:

    @staticmethod
    def lift(value: int):
        return DatabaseOps._make_instance_(value)

    @staticmethod
    def check_lower(value: DatabaseOps):
        if not isinstance(value, DatabaseOps):
            raise TypeError("Expected DatabaseOps instance, {} found".format(type(value).__name__))

    @staticmethod
    def lower(value: DatabaseOpsProtocol):
        if not isinstance(value, DatabaseOps):
            raise TypeError("Expected DatabaseOps instance, {} found".format(type(value).__name__))
        return value._uniffi_clone_pointer()

    @classmethod
    def read(cls, buf: _UniffiRustBuffer):
        ptr = buf.read_u64()
        if ptr == 0:
            raise InternalError("Raw pointer value was null")
        return cls.lift(ptr)

    @classmethod
    def write(cls, value: DatabaseOpsProtocol, buf: _UniffiRustBuffer):
        buf.write_u64(cls.lower(value))
class NfsServerProtocol(typing.Protocol):
    """
    NFS Server for exposing database as POSIX filesystem
    """

    def get_mount_command(self, mount_point: "str"):
        """
        Get mount command for this platform
        """

        raise NotImplementedError
    def get_port(self, ):
        """
        Get the port the server is listening on
        """

        raise NotImplementedError
    def get_unmount_command(self, mount_point: "str"):
        """
        Get unmount command for this platform
        """

        raise NotImplementedError
    def is_ready(self, ):
        """
        Check if server is ready
        """

        raise NotImplementedError
    def shutdown(self, ):
        """
        Shutdown the NFS server
        """

        raise NotImplementedError
# NfsServer is a Rust-only trait - it's a wrapper around a Rust implementation.
class NfsServer():
    """
    NFS Server for exposing database as POSIX filesystem
    """

    _pointer: ctypes.c_void_p
    def __init__(self, db: "DatabaseOps",port: "int"):
        """
        Create and start a new NFS server
        """

        _UniffiConverterTypeDatabaseOps.check_lower(db)
        
        _UniffiConverterUInt16.check_lower(port)
        
        self._pointer = _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_constructor_nfsserver_new,
        _UniffiConverterTypeDatabaseOps.lower(db),
        _UniffiConverterUInt16.lower(port))

    def __del__(self):
        # In case of partial initialization of instances.
        pointer = getattr(self, "_pointer", None)
        if pointer is not None:
            _uniffi_rust_call(_UniffiLib.uniffi_posixlake_fn_free_nfsserver, pointer)

    def _uniffi_clone_pointer(self):
        return _uniffi_rust_call(_UniffiLib.uniffi_posixlake_fn_clone_nfsserver, self._pointer)

    # Used by alternative constructors or any methods which return this type.
    @classmethod
    def _make_instance_(cls, pointer):
        # Lightly yucky way to bypass the usual __init__ logic
        # and just create a new instance with the required pointer.
        inst = cls.__new__(cls)
        inst._pointer = pointer
        return inst


    def get_mount_command(self, mount_point: "str") -> "typing.List[str]":
        """
        Get mount command for this platform
        """

        _UniffiConverterString.check_lower(mount_point)
        
        return _UniffiConverterSequenceString.lift(
            _uniffi_rust_call(_UniffiLib.uniffi_posixlake_fn_method_nfsserver_get_mount_command,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(mount_point))
        )





    def get_port(self, ) -> "int":
        """
        Get the port the server is listening on
        """

        return _UniffiConverterUInt16.lift(
            _uniffi_rust_call(_UniffiLib.uniffi_posixlake_fn_method_nfsserver_get_port,self._uniffi_clone_pointer(),)
        )





    def get_unmount_command(self, mount_point: "str") -> "typing.List[str]":
        """
        Get unmount command for this platform
        """

        _UniffiConverterString.check_lower(mount_point)
        
        return _UniffiConverterSequenceString.lift(
            _uniffi_rust_call(_UniffiLib.uniffi_posixlake_fn_method_nfsserver_get_unmount_command,self._uniffi_clone_pointer(),
        _UniffiConverterString.lower(mount_point))
        )





    def is_ready(self, ) -> "bool":
        """
        Check if server is ready
        """

        return _UniffiConverterBool.lift(
            _uniffi_rust_call(_UniffiLib.uniffi_posixlake_fn_method_nfsserver_is_ready,self._uniffi_clone_pointer(),)
        )





    def shutdown(self, ) -> None:
        """
        Shutdown the NFS server
        """

        _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_method_nfsserver_shutdown,self._uniffi_clone_pointer(),)







class _UniffiConverterTypeNfsServer:

    @staticmethod
    def lift(value: int):
        return NfsServer._make_instance_(value)

    @staticmethod
    def check_lower(value: NfsServer):
        if not isinstance(value, NfsServer):
            raise TypeError("Expected NfsServer instance, {} found".format(type(value).__name__))

    @staticmethod
    def lower(value: NfsServerProtocol):
        if not isinstance(value, NfsServer):
            raise TypeError("Expected NfsServer instance, {} found".format(type(value).__name__))
        return value._uniffi_clone_pointer()

    @classmethod
    def read(cls, buf: _UniffiRustBuffer):
        ptr = buf.read_u64()
        if ptr == 0:
            raise InternalError("Raw pointer value was null")
        return cls.lift(ptr)

    @classmethod
    def write(cls, value: NfsServerProtocol, buf: _UniffiRustBuffer):
        buf.write_u64(cls.lower(value))

# Async support

def restore(backup_path: "str",restore_path: "str") -> None:
    _UniffiConverterString.check_lower(backup_path)
    
    _UniffiConverterString.check_lower(restore_path)
    
    _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_func_restore,
        _UniffiConverterString.lower(backup_path),
        _UniffiConverterString.lower(restore_path))


def restore_to_transaction(backup_path: "str",restore_path: "str",transaction_id: "int") -> None:
    _UniffiConverterString.check_lower(backup_path)
    
    _UniffiConverterString.check_lower(restore_path)
    
    _UniffiConverterUInt64.check_lower(transaction_id)
    
    _uniffi_rust_call_with_error(_UniffiConverterTypePosixLakeError,_UniffiLib.uniffi_posixlake_fn_func_restore_to_transaction,
        _UniffiConverterString.lower(backup_path),
        _UniffiConverterString.lower(restore_path),
        _UniffiConverterUInt64.lower(transaction_id))


__all__ = [
    "InternalError",
    "PosixLakeError",
    "DataSkippingStats",
    "DatabaseMetrics",
    "Field",
    "HealthStatus",
    "Row",
    "S3Config",
    "Schema",
    "restore",
    "restore_to_transaction",
    "DatabaseOps",
    "NfsServer",
]

