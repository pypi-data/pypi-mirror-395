#!/usr/bin/env python3
# examples/zero_config_examples_optimized.py
"""
ChukMCPServer Zero Configuration Examples - Async & Performance Optimized

Same zero config magic, but with async tools and logging optimized for maximum performance.
Demonstrates true async capabilities for maximum concurrency and throughput.
"""

# ============================================================================
# Example 1: The Ultimate Zero Config - Async & Performance Optimized
# ============================================================================

import asyncio
import time

from chuk_mcp_server import resource, run, tool


# âœ¨ CLEAN: No server creation, no configuration needed!
@tool
async def hello(name: str = "World") -> str:
    """
    Say hello to someone (async).

    ðŸ§  Auto-inferred: category=general, tags=["tool", "general"]
    âš¡ Async for maximum concurrency
    """
    # Simulate some async work (database lookup, API call, etc.)
    await asyncio.sleep(0.001)  # 1ms simulated async operation
    return f"Hello, {name}! (async response)"


@tool
async def calculate(expression: str) -> str:
    """
    Calculate mathematical expressions (async).

    ðŸ§  Auto-inferred: category=mathematics, tags=["tool", "mathematics"]
    âš¡ Async for non-blocking computation
    """
    try:
        # Simulate async computation (maybe hitting a math service)
        await asyncio.sleep(0.0005)  # 0.5ms simulated async work
        result = eval(expression)  # Note: Use safely in production
        return f"{expression} = {result} (async computed)"
    except Exception as e:
        return f"Error: {str(e)}"


@tool
async def fetch_data(url: str = "https://httpbin.org/json") -> dict:
    """
    Fetch data from a URL (truly async).

    ðŸ§  Auto-inferred: category=network, tags=["tool", "network"]
    ðŸŒ Real async HTTP client for maximum performance
    """
    try:
        import httpx

        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get(url)
            data = response.json()
            return {
                "url": url,
                "status": response.status_code,
                "data": data,
                "async": True,
                "performance_optimized": True,
            }
    except Exception as e:
        return {"url": url, "error": str(e), "async": True}


@tool
async def process_data_async(data: list, operation: str = "sum") -> dict:
    """
    Process data asynchronously with different operations.

    ðŸ§  Auto-inferred: category=data_processing, tags=["tool", "data_processing"]
    âš¡ Async processing for large datasets
    """
    start_time = time.time()

    # Simulate async data processing
    await asyncio.sleep(0.001)  # Simulated async I/O

    if operation == "sum":
        result = sum(data) if all(isinstance(x, int | float) for x in data) else 0
    elif operation == "count":
        result = len(data)
    elif operation == "average":
        result = sum(data) / len(data) if data and all(isinstance(x, int | float) for x in data) else 0
    else:
        result = f"Unknown operation: {operation}"

    processing_time = time.time() - start_time

    return {
        "operation": operation,
        "input_size": len(data),
        "result": result,
        "processing_time_ms": round(processing_time * 1000, 2),
        "async": True,
    }


@tool
async def database_query_async(table: str = "users", limit: int = 10) -> dict:
    """
    Simulate async database query.

    ðŸ§  Auto-inferred: category=database, tags=["tool", "database"]
    ðŸ—„ï¸ Async database operations for scalability
    """
    # Simulate async database connection and query
    await asyncio.sleep(0.002)  # 2ms simulated DB query time

    # Generate mock data
    data = [{"id": i, "table": table, "name": f"user_{i}", "active": i % 2 == 0} for i in range(1, limit + 1)]

    return {
        "table": table,
        "limit": limit,
        "rows": data,
        "query_time_ms": 2,
        "async": True,
        "performance_optimized": True,
    }


@resource("config://settings")
async def get_settings() -> dict:
    """
    Server configuration (async resource).

    ðŸ§  Auto-inferred: mime_type=application/json, tags=["resource", "config"]
    âš¡ Async resource loading for non-blocking access
    """
    # Simulate async config loading (maybe from distributed config service)
    await asyncio.sleep(0.0005)  # 0.5ms simulated async config load

    return {
        "app": "Zero Config Demo",
        "version": "1.0.0",
        "magic": True,
        "performance_optimized": True,
        "async_resources": True,
        "max_rps": "38,000+",
        "features": [
            "async_tools",
            "async_resources",
            "zero_configuration",
            "auto_inference",
            "performance_optimization",
        ],
    }


@resource("docs://readme")
async def get_readme() -> str:
    """
    Project documentation (async resource).

    ðŸ§  Auto-inferred: mime_type=text/markdown, tags=["resource", "docs"]
    ðŸ“š Async documentation loading
    """
    # Simulate async documentation loading
    await asyncio.sleep(0.001)  # 1ms simulated async doc load

    return """# Zero Configuration MCP Server - Async & Performance Optimized

This server was created with **ZERO** configuration and optimized for maximum async performance!

## Features
- âœ¨ Auto-detected project name
- ðŸ§  Smart type inference
- âš¡ Performance optimization (38,000+ RPS!)
- ðŸŒ Intelligent networking
- ðŸ“Š Environment detection
- ðŸš€ Logging optimized for speed
- ðŸŒŠ **Async tools and resources**

## Performance Results (Async Optimized)
- MCP Ping: 38,000+ RPS
- Async Tool Calls: 33,000+ RPS
- Async Resource Reads: 35,000+ RPS
- Perfect concurrency scaling

## Async Benefits
- **Non-blocking operations**: Tools don't block each other
- **Maximum concurrency**: Handle 1000+ simultaneous requests
- **Scalable architecture**: Async I/O for database, network, file operations
- **Performance**: 38,000+ RPS with async optimization

## Example Async Tools
- `hello`: Async greeting with simulated I/O
- `calculate`: Async computation
- `fetch_data`: Real async HTTP requests
- `process_data_async`: Async data processing
- `database_query_async`: Async database simulation

All tools are async-optimized for maximum performance and concurrency!
"""


@resource("metrics://performance")
async def get_performance_metrics() -> dict:
    """
    Real-time performance metrics (async resource).

    ðŸ§  Auto-inferred: mime_type=application/json, tags=["resource", "metrics"]
    ðŸ“Š Async performance monitoring
    """
    # Simulate async metrics collection
    await asyncio.sleep(0.001)  # 1ms simulated metrics gathering

    return {
        "timestamp": time.time(),
        "performance": {
            "mcp_ping_rps": "38,000+",
            "tool_calls_rps": "33,000+",
            "resource_reads_rps": "35,000+",
            "avg_latency_ms": 3.0,
            "max_concurrency": 1000,
            "success_rate": "100%",
        },
        "async_benefits": {
            "non_blocking": True,
            "concurrent_execution": True,
            "scalable_architecture": True,
            "optimal_resource_usage": True,
        },
        "optimization": {
            "logging_level": "WARNING",
            "debug_mode": False,
            "async_tools": True,
            "zero_config_overhead": True,
        },
        "async": True,
        "real_time": True,
    }


if __name__ == "__main__":
    # âœ¨ ASYNC PERFORMANCE MODE: Maximum async performance
    import logging

    print("ðŸŒŠ ChukMCPServer - Async Zero Config Performance Mode")
    print("=" * 70)
    print("âš¡ Async tools & resources for maximum concurrency")
    print("ðŸŽ¯ Target: 38,000+ RPS with perfect async scaling")
    print("ðŸŒŠ Non-blocking operations for ultimate performance")
    print()

    print("ðŸš€ Async Features Enabled:")
    print("   ðŸŒŠ Async tools: Non-blocking execution")
    print("   ðŸ“‚ Async resources: Concurrent loading")
    print("   ðŸ”„ Async I/O: Database, network, file operations")
    print("   âš¡ Performance: Zero blocking, maximum throughput")
    print()

    # Set optimal logging level (WARNING = minimal overhead)
    logging.basicConfig(level=logging.WARNING)

    # Run with async performance optimizations
    run(debug=False)  # Explicitly disable debug mode for maximum async performance
