Metadata-Version: 2.4
Name: autoriskml
Version: 0.1.0
Summary: A Fully Automated Risk & Trading Intelligence Engine
Home-page: https://github.com/idrissbado/AutoRiskML
Author: Idriss Bado
Author-email: Idriss Bado <idrissbadoolivier@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/idrissbado/AutoRiskML
Project-URL: Documentation, https://github.com/idrissbado/AutoRiskML#readme
Project-URL: Repository, https://github.com/idrissbado/AutoRiskML
Project-URL: Bug Tracker, https://github.com/idrissbado/AutoRiskML/issues
Keywords: risk-management,machine-learning,credit-scoring,trading,fintech,psi,woe,iv,scorecard,drift-detection,mlops,automl,explainability
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Financial and Insurance Industry
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Provides-Extra: perf
Requires-Dist: numpy>=1.20.0; extra == "perf"
Requires-Dist: numba>=0.55.0; extra == "perf"
Requires-Dist: pyarrow>=10.0.0; extra == "perf"
Provides-Extra: ml
Requires-Dist: scikit-learn>=1.0.0; extra == "ml"
Requires-Dist: xgboost>=1.7.0; extra == "ml"
Requires-Dist: lightgbm>=3.3.0; extra == "ml"
Provides-Extra: explain
Requires-Dist: shap>=0.41.0; extra == "explain"
Requires-Dist: lime>=0.2.0; extra == "explain"
Provides-Extra: distributed
Requires-Dist: dask[complete]>=2023.1.0; extra == "distributed"
Requires-Dist: ray>=2.0.0; extra == "distributed"
Provides-Extra: connectors
Requires-Dist: sqlalchemy>=2.0.0; extra == "connectors"
Requires-Dist: boto3>=1.26.0; extra == "connectors"
Requires-Dist: azure-storage-blob>=12.0.0; extra == "connectors"
Provides-Extra: azure
Requires-Dist: azureml-sdk>=1.50.0; extra == "azure"
Requires-Dist: azure-identity>=1.12.0; extra == "azure"
Provides-Extra: monitoring
Requires-Dist: prometheus-client>=0.16.0; extra == "monitoring"
Provides-Extra: reporting
Requires-Dist: matplotlib>=3.5.0; extra == "reporting"
Requires-Dist: seaborn>=0.12.0; extra == "reporting"
Requires-Dist: plotly>=5.10.0; extra == "reporting"
Provides-Extra: dev
Requires-Dist: pytest>=7.2.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Provides-Extra: all
Requires-Dist: numpy>=1.20.0; extra == "all"
Requires-Dist: numba>=0.55.0; extra == "all"
Requires-Dist: pyarrow>=10.0.0; extra == "all"
Requires-Dist: scikit-learn>=1.0.0; extra == "all"
Requires-Dist: xgboost>=1.7.0; extra == "all"
Requires-Dist: lightgbm>=3.3.0; extra == "all"
Requires-Dist: shap>=0.41.0; extra == "all"
Requires-Dist: lime>=0.2.0; extra == "all"
Requires-Dist: matplotlib>=3.5.0; extra == "all"
Requires-Dist: plotly>=5.10.0; extra == "all"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# ğŸš€ AutoRiskML - The First Fully Automated Risk & Trading Intelligence Engine

[![PyPI version](https://badge.fury.io/py/autoriskml.svg)](https://pypi.org/project/autoriskml/)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **The only Python package that acts like a Senior Risk Data Scientist**

AutoRiskML automates the entire risk modeling pipeline from data ingestion to Azure deployment. Built for banks, fintechs, trading firms, and hedge funds.

## ğŸ¯ Why AutoRiskML is Revolutionary

### âŒ **The Problem**

Risk data scientists spend 80% of their time on:
- Manual data cleaning and binning
- Computing WOE/IV tables
- Monitoring PSI and drift
- Building scorecards
- Setting up model monitoring
- Creating deployment pipelines

### âœ… **The Solution: AutoRiskML**

```python
from autoriskml import AutoRisk

# ONE command does EVERYTHING a senior risk DS would do:
ar = AutoRisk(project="loan_scoring")
ar.register_source("train", csv="data/loans.csv")
result = ar.run(
    source="train",
    target="default_flag",
    explain=True,
    deploy={"provider": "azure_ml"}
)

# You now have:
# âœ… Data profile & recommendations
# âœ… Automated cleaning
# âœ… Optimal binning & WOE/IV tables
# âœ… Trained scorecard model
# âœ… PSI & drift monitoring
# âœ… SHAP explainability
# âœ… Production-ready Azure deployment
# âœ… PDF/HTML reports
```

## ğŸ† Unique Features (No Other Package Has These)

| Feature | Pandas | Scikit-learn | H2O | PyCaret | **AutoRiskML** |
|---------|--------|--------------|-----|---------|----------------|
| **Auto WOE/IV** | âŒ | âŒ | âŒ | âŒ | âœ… |
| **Auto PSI** | âŒ | âŒ | âŒ | âŒ | âœ… |
| **Scorecard Generation** | âŒ | âŒ | âŒ | âŒ | âœ… |
| **Drift Detection for Trading** | âŒ | âŒ | âŒ | âŒ | âœ… |
| **Risk-specific Binning** | âŒ | âŒ | Partial | âŒ | âœ… |
| **Azure ML Auto-deploy** | âŒ | âŒ | âŒ | âŒ | âœ… |
| **Built-in Monitoring** | âŒ | âŒ | âŒ | âŒ | âœ… |
| **Audit Trail** | âŒ | âŒ | âŒ | âŒ | âœ… |
| **Pure Python** | âœ… | âœ… | âŒ | âœ… | âœ… |

## ğŸ”¥ What AutoRiskML Does

### A. Automated Risk ML Pipeline

```python
# 1. DATA PROFILING - Like a senior DS would analyze
ar.profile()
# â†’ Column types, missing %, distributions, recommendations

# 2. AUTO-CLEANING - Handles all edge cases
ar.autoclean()
# â†’ Missing values, outliers, type coercion, date parsing

# 3. FEATURE ENGINEERING - Risk-specific features
ar.auto_features()
# â†’ Binning, WOE encoding, interaction features

# 4. MODEL TRAINING - Multiple algorithms
ar.train(models=["logistic", "xgboost", "lightgbm"])
# â†’ Auto hyperparameter tuning, walk-forward validation

# 5. SCORECARD GENERATION - Convert to points
ar.scorecard(pdo=20, base_score=600)
# â†’ Industry-standard credit scoring
```

### B. Risk Scoring Engine (WOE/IV/PSI)

```python
# Weight of Evidence & Information Value
woe_iv = ar.compute_woe_iv(feature="credit_utilization", target="default")
print(f"IV: {woe_iv['iv']:.3f}")  # Predictive power
print(woe_iv['woe_table'])         # Bin-level WOE

# Population Stability Index
psi = ar.compute_psi(
    baseline_data="train.csv",
    current_data="production_data.csv"
)
print(f"PSI: {psi:.3f}")  # <0.1: stable, >0.25: significant drift

# Characteristic Stability Index
csi = ar.compute_csi(feature="income", current_data="latest.csv")
```

### C. Monitoring & Drift Detection

```python
# Continuous monitoring
monitor = ar.monitor(
    production_data="s3://bucket/prod_scores.parquet",
    baseline="train.csv",
    alert_threshold=0.2
)

print(monitor.summary())
# â†’ PSI per feature
# â†’ Score distribution shift
# â†’ Prediction drift
# â†’ Retrain recommendations
```

### D. Explainability (SHAP + Custom)

```python
# Global explainability
ar.explain_global()
# â†’ Top features driving risk
# â†’ SHAP summary plots

# Local explainability (per-record)
explanation = ar.explain_record(customer_id=12345)
print(explanation.reason_codes)
# â†’ "High credit utilization (+45 pts)"
# â†’ "Recent late payments (+30 pts)"
```

### E. Deployment to Azure

```python
# One-command deployment
endpoint = ar.deploy(
    provider="azure_ml",
    workspace="RiskWS",
    resource_group="risk-rg",
    compute_type="aks",  # or "aci" for quick tests
    instance_count=3
)

print(f"Endpoint: {endpoint.scoring_uri}")
print(f"Key: {endpoint.primary_key}")

# Score new data via REST API
scores = endpoint.score(new_customers_df)
```

### F. Backtesting (Trading Mode)

```python
# Time-series walk-forward validation
backtest = ar.backtest(
    data="trading_signals.csv",
    strategy="long_short",
    walk_forward_windows=12,
    refit_frequency="monthly"
)

print(backtest.sharpe_ratio)
print(backtest.max_drawdown)
print(backtest.cumulative_returns)
```

### G. Auto-Reporting

```python
# Generate comprehensive reports
ar.report(
    output="risk_report.html",
    include=[
        "data_profile",
        "woe_iv_tables",
        "model_performance",
        "psi_monitoring",
        "shap_explanations",
        "scorecard",
        "recommendations"
    ]
)

# PDF for regulators
ar.report(output="regulatory_report.pdf", template="basel")
```

## ğŸ“¦ Installation

### Basic (Pure Python, zero dependencies)
```bash
pip install autoriskml
```

### With Machine Learning
```bash
pip install autoriskml[ml]
```

### With Explainability
```bash
pip install autoriskml[explain]
```

### With Azure Deployment
```bash
pip install autoriskml[azure]
```

### Full Installation (Everything)
```bash
pip install autoriskml[all]
```

## ğŸš€ Quick Start (30 Seconds)

### Example 1: Credit Scoring

```python
from autoriskml import AutoRisk

# Initialize
ar = AutoRisk(project="credit_scoring")

# Register data
ar.register_source("train", csv="loans_train.csv")
ar.register_source("test", csv="loans_test.csv")

# Run full pipeline
result = ar.run(
    source="train",
    validation_source="test",
    target="default_flag",
    config="configs/credit_config.yaml"
)

# Access artifacts
print(f"Model AUC: {result.metrics['auc']:.3f}")
print(f"Model PSI: {result.metrics['psi']:.3f}")
print(f"Scorecard: {result.scorecard_path}")
print(f"Report: {result.report_html}")
```

### Example 2: Fraud Detection

```python
ar = AutoRisk(project="fraud_detection")
ar.register_source("transactions", sql_query="""
    SELECT * FROM transactions 
    WHERE date >= '2024-01-01'
""", connection_string="postgresql://...")

result = ar.run(
    source="transactions",
    target="is_fraud",
    models=["logistic", "xgboost"],
    explain=True,
    monitor={"psi_threshold": 0.15}
)
```

### Example 3: Trading Risk

```python
ar = AutoRisk(project="trading_risk", mode="trading")
ar.register_source("signals", parquet="s3://bucket/signals.parquet")

result = ar.run(
    source="signals",
    target="return_next_day",
    backtest=True,
    walk_forward=True,
    deploy={"provider": "azure_ml"}
)

print(f"Sharpe Ratio: {result.backtest['sharpe']:.2f}")
print(f"Max Drawdown: {result.backtest['max_dd']:.2%}")
```

## ğŸ“ Complete Example: End-to-End Loan Scoring

```python
from autoriskml import AutoRisk
import pandas as pd

# 1. Initialize project
ar = AutoRisk(
    project="personal_loans",
    output_dir="artifacts/loans",
    log_level="INFO"
)

# 2. Register data sources
ar.register_source("train", csv="data/loans_2022_2023.csv")
ar.register_source("valid", csv="data/loans_2024_Q1.csv")
ar.register_source("prod", s3="s3://bucket/prod/loans.parquet")

# 3. Profile data (optional but recommended)
profile = ar.profile(source="train")
print(profile.summary())
# â†’ 50,000 rows Ã— 45 features
# â†’ Missing: income (5%), employment_length (12%)
# â†’ Recommendations: 8 features to drop, 3 to engineer

# 4. Run full automated pipeline
result = ar.run(
    source="train",
    validation_source="valid",
    target="default_flag",
    
    # Cleaning options
    clean={
        "missing_strategy": "auto",  # smart imputation
        "outlier_method": "iqr",
        "date_formats": ["%Y-%m-%d", "%d/%m/%Y"]
    },
    
    # Binning options
    binning={
        "numeric_method": "monotonic",  # monotonic bad rate
        "max_bins": 6,
        "min_bin_size": 0.05
    },
    
    # Feature selection
    features={
        "min_iv": 0.02,  # minimum information value
        "max_features": 20,
        "auto_interactions": True
    },
    
    # Model options
    models=[
        {"type": "logistic", "penalty": 0.1},
        {"type": "xgboost", "params": {"max_depth": 6, "eta": 0.05}}
    ],
    
    # Scorecard conversion
    scorecard={
        "pdo": 20,        # points to double odds
        "base_score": 600,
        "base_odds": 50
    },
    
    # Explainability
    explain=True,
    
    # Monitoring
    monitor={
        "compute_psi": True,
        "psi_threshold": 0.2,
        "drift_features": "auto",
        "retrain_trigger": "drift_or_performance"
    },
    
    # Reporting
    report={
        "formats": ["html", "pdf"],
        "template": "executive"
    },
    
    # Deployment
    deploy={
        "provider": "azure_ml",
        "workspace": "RiskWS",
        "resource_group": "risk-prod-rg",
        "compute": "aks-cluster",
        "auth": "key"
    }
)

# 5. Access results
print("\n" + "="*70)
print("ğŸ“Š RESULTS")
print("="*70)
print(f"âœ… Model: {result.best_model}")
print(f"âœ… AUC: {result.metrics['auc']:.3f}")
print(f"âœ… KS: {result.metrics['ks']:.3f}")
print(f"âœ… Gini: {result.metrics['gini']:.3f}")
print(f"âœ… PSI (validation): {result.metrics['psi']:.3f}")
print(f"\nğŸ“ Artifacts:")
print(f"   â€¢ Model: {result.model_path}")
print(f"   â€¢ Scorecard: {result.scorecard_path}")
print(f"   â€¢ Binning spec: {result.binning_spec_path}")
print(f"   â€¢ WOE tables: {result.woe_tables_path}")
print(f"   â€¢ Report: {result.report_html}")
print(f"\nğŸŒ Deployment:")
print(f"   â€¢ Endpoint: {result.endpoint.scoring_uri}")
print(f"   â€¢ Key: {result.endpoint.primary_key[:20]}...")

# 6. Score new customers
new_customers = pd.read_csv("data/new_applications.csv")
scores = ar.score(new_customers, output="with_reasons")

print(f"\nâœ… Scored {len(scores)} new customers")
print(scores[['customer_id', 'score', 'probability', 'risk_tier', 'top_reason']].head())

# 7. Monitor production data
monitor_result = ar.monitor(source="prod")
if monitor_result.alert:
    print(f"\nâš ï¸  ALERT: {monitor_result.message}")
    print(f"   PSI: {monitor_result.psi:.3f} (threshold: 0.20)")
    print(f"   Drifted features: {', '.join(monitor_result.drifted_features)}")
    print(f"   Recommendation: {monitor_result.recommendation}")
```

## ğŸ“š Advanced Features

### Custom Binning Strategy

```python
from autoriskml.binning import CustomBinner

class MyBinner(CustomBinner):
    def fit(self, values, target):
        # Your custom binning logic
        bins = self.compute_custom_bins(values, target)
        return bins

ar.register_binner("my_method", MyBinner())
result = ar.run(..., binning={"method": "my_method"})
```

### Custom Model Adapter

```python
from autoriskml.models import ModelAdapter

class MyModelAdapter(ModelAdapter):
    def train(self, X, y):
        # Train your model
        self.model = YourModel().fit(X, y)
    
    def predict_proba(self, X):
        return self.model.predict_proba(X)

ar.register_model("my_model", MyModelAdapter())
```

### Streaming Scoring

```python
# Score large datasets in chunks
for chunk_scores in ar.score_stream(
    source="s3://bucket/huge_file.csv",
    chunk_size=100_000,
    output="s3://bucket/scores/"
):
    print(f"Scored {len(chunk_scores)} records")
```

### Real-time Monitoring

```python
# Set up continuous monitoring
ar.monitor_continuously(
    source_stream="kafka://topic/transactions",
    baseline="train_data.csv",
    check_interval="hourly",
    alert_email="risk-team@company.com"
)
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AutoRisk API                              â”‚
â”‚  (Simple high-level interface: run(), score(), monitor())       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Core Pipeline Orchestrator                    â”‚
â”‚  â€¢ Stage execution  â€¢ Artifact management  â€¢ Provenance tracking â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚       â”‚        â”‚         â”‚          â”‚           â”‚
     â–¼       â–¼        â–¼         â–¼          â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Connectorâ”‚Profilâ”‚Cleaningâ”‚ Binning â”‚  Models    â”‚   Scoring    â”‚
â”‚CSV/SQL/ â”‚-ing  â”‚Auto    â”‚WOE/IV   â”‚Logistic/   â”‚  Scorecard   â”‚
â”‚S3/Kafka â”‚      â”‚Clean   â”‚Monotonicâ”‚XGB/LightGBMâ”‚  Generation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â–¼                    â–¼                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Metrics â”‚         â”‚ Explain  â”‚        â”‚ Monitoring â”‚
            â”‚PSI/CSI/ â”‚         â”‚SHAP/LIME â”‚        â”‚Drift/Alert â”‚
            â”‚KS/Gini  â”‚         â”‚Reasons   â”‚        â”‚PSI Tracker â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â–¼                                          â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Export  â”‚                               â”‚Deploymentâ”‚
            â”‚ONNX/    â”‚                               â”‚Azure ML/ â”‚
            â”‚Joblib   â”‚                               â”‚AKS/API   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Use Cases

### 1. **Banks & Credit Unions**
- Personal loan scoring
- Credit card approvals
- Mortgage risk assessment
- SME lending

### 2. **Fintechs**
- BNPL (Buy Now Pay Later) scoring
- Micro-lending
- Alternative credit scoring
- KYC risk assessment

### 3. **Insurance**
- Claims fraud detection
- Underwriting risk
- Policyholder lifetime value

### 4. **Trading Firms**
- Strategy risk monitoring
- Position sizing
- Counterparty risk
- Market regime detection

### 5. **E-commerce**
- Transaction fraud
- Account takeover detection
- Chargeback prediction

## ğŸ“Š Performance

- **Speed**: 10x faster than manual process
- **Accuracy**: Comparable to senior DS work
- **Scalability**: Handles 100M+ records with distributed mode
- **Memory**: Streaming support for datasets > RAM

## ğŸ”’ Security & Compliance

- âœ… Local-first (no external calls by default)
- âœ… Audit trail for all transformations
- âœ… PII detection and scrubbing
- âœ… Explainable AI for regulatory compliance
- âœ… Reproducible pipelines (version control)
- âœ… GDPR-compliant data handling

## ğŸ“– Documentation

- [Quick Start Guide](docs/quickstart.md)
- [API Reference](docs/api.md)
- [Architecture](docs/architecture.md)
- [Azure Deployment](docs/azure_deployment.md)
- [Cookbook](docs/cookbook.md)
- [Best Practices](docs/best_practices.md)

## ğŸ¤ Contributing

Contributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md)

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file

## ğŸ™ Acknowledgments

Built with inspiration from years of risk modeling in banking and fintech.

## ğŸ“§ Contact

- **Author**: Idriss Bado
- **Email**: idrissbadoolivier@gmail.com
- **GitHub**: [idrissbado](https://github.com/idrissbado)

---

**â­ If AutoRiskML helps you, please star the repo!**

**ğŸš€ Built for the future of automated risk intelligence**
