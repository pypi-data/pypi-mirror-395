"""
# SOTA模型导出：多轮半监督学习 + 6种融合策略

## 🏆 概览

**最终性能**: AUC = **0.66901** 🏆  
**性能提升**: vs Baseline(0.66147) = **+0.0754pp (+0.114%)**  

| 维度        | 突破                         |
| --------- | -------------------------- |
| **特征工程**  | Log/Square变换 + 分组聚合 + 分布统计 |
| **模型融合**  | 三强树模型 + 网格搜索权重 + 秩平均       |
| **伪标签增强** | 多轮迭代 + 早停回滚 + 质量控制         |

## 🔬 AUC计算方法

#### Overall AUC (OOF AUC) - 核心评估指标

**定义**: 在整个训练集上的全局AUC评分，反映模型的真实泛化能力。

**计算过程**:
```
Step 1: 5折交叉验证划分

├─ 使用 StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

├─ 保证每折中正负样本比例一致

└─ 总样本数 = 约 36000 个


Step 2: OOF预测生成 (Out-of-Fold)

├─ 初始化: oof_preds = np.zeros(len(X))

├─ 对每个fold (i=1 to 5):

│  ├─ train_idx: fold i的训练数据(4份数据)

│  ├─ val_idx: fold i的验证数据(1份数据)

│  ├─ 训练LightGBM模型 (默认参数或调优参数)

│  ├─ 在val_idx上预测: val_preds = model.predict_proba()[:, 1]

│  └─ 保存: oof_preds[val_idx] = val_preds  ✓ 关键步骤

└─ 最终 oof_preds 包含所有36000个样本的预测概率

  
Step 3: Overall AUC 计算

└─ Overall AUC = roc_auc_score(y_true=全部样本标签, y_score=oof_preds)

   └─ 公式: AUC = P(预测为正 > 预测为负)

   └─ 范围: [0, 1], 越接近1越好

```

## 📊 特征工程

**特征总数**: EXP001基础特征(~80) + 新增特征(~125) = **~205个特征**

| 特征类别      | 来源实验      | 方法                              | 新增特征数    | AUC提升         |
| --------- | --------- | ------------------------------- | -------- | ------------- |
| **非线性变换** | EXP010    | Log1p + Square                  | ~30      | +0.0404pp     |
| **聚合统计**  | EXP009    | Z-Score + Rank + Combo          | ~40      | +0.0035pp     |
| **分布形状**  | EXP021    | Skewness + Kurtosis + Quantiles | ~20      | +0.0015pp     |
| **时间分层**  | EXP021    | 多窗口聚合                           | ~25      | +0.0010pp     |
| **交互特征**  | EXP005    | 利率×额度 + 收入×账户数                  | ~5       | +0.0008pp     |
| **WOE编码** | EXP005_v5 | 5个分类变量                          | 5        | +0.0047pp     |
| **总计**    | -         | -                               | **~125** | **+0.0519pp** |

## 🎯 模型融合策略

**基础模型**: LightGBM(0.66730) + XGBoost(0.66527) + CatBoost(0.66573)  
**特征规模**: ~205个(基础80 + 工程125)  
**样本利用**: 36000标记样本 + 1979伪标签(9.9%)  
**融合方式**: Weighted Ensemble (秩平均)  
**最优权重**: LGB=0.50, XGB=0.10, CAT=0.40

| 融合方式                    | 最终AUC          | 优劣分析                   |
| ----------------------- | -------------- | ---------------------- |
| **① Weighted Ensemble** | **0.66901** 🏆 | ✅ 简单有效，秩平均融合应对概率校准差异   |
| **② LR Stacking**       | 0.66890        | ✅ 接近最优，Logit变换后线性模型表现好 |
| **③ Ridge Stacking**    | 0.66844        | ⚠️ L2正则化防过拟合，性能略低      |
| **④ BayesianRidge**     | 0.66846        | ⚠️ 概率线性回归，贝叶斯框架稳定性好    |
| **⑤ Lasso Stacking**    | 0.66845        | ⚠️ L1正则化特征选择，性能略低      |
| **⑥ LGB Stacking**      | 0.66618        | ❌ 树模型Stacking过复杂，性能下降  |

**核心发现**: 简单加权融合优于复杂Stacking，秩平均+网格搜索权重最优

## 核心训练模块

| 步骤  | 模块        | 技术                       | 描述                                                                                                                                                                                                                                                                                                                                                                       |
| --- | --------- | ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| 1️⃣ | **秩平均融合** | **Rank Average** (伪标签基础) | 🔑 **最关键技术**：将概率转换为秩次 `rank(pred) / n_samples`，然后加权融合。<br><br>**为什么是伪标签的前提**:<br>1. **概率预测结果集中**且大多在**0.5以下**，不利于半监督学习<br>2. **概率校准差异**: LGB/XGB/CAT的概率分布差异<br>3. **秩次鲁棒**: 秩次无视绝对值，只看相对排序，天然对齐三个模型<br>4. **高置信度保留**: 秩次融合后，>0.95的样本真正代表三个模型的**共识**<br><br>**伪标签生成逻辑**:<br>`high_conf_mask = (rank_ensemble > 0.95) \| (rank_ensemble < 0.05)`<br>这样选出的伪标签质量高，重训练时不会污染模型 |
| 2️⃣ | **权重优化**  | **网格搜索**                 | 穷举搜索权重(step=0.1)使**秩平均OOF** AUC最大。公式: `rank_ensemble = w_lgb*rank_lgb + w_xgb*rank_xgb + w_cat*rank_cat`。最优权重: LGB=0.50, XGB=0.10, CAT=0.40。**必须基于秩平均**，否则权重无法对齐三个模型                                                                                                                                                                                                     |
| 3️⃣ | **堆叠融合**  | **Logit变换**              | 对OOF概率应用`log(p/(1-p))`变换，将[0,1]范围映射到(-∞,+∞)。用于6种Stacking方式(LGB/LR/Lasso/Ridge/BayesianRidge)。通过对比发现: 秩平均简单有效 > 所有复杂Stacking                                                                                                                                                                                                                                              |
| 4️⃣ | **早停机制**  | **EarlyStopping + 回滚**   | best_fusion_auc连续3轮无提升时停止迭代，**无条件恢复**历史最佳迭代状态。防止后期伪标签污染。在迭代循环中监测融合AUC，触发回滚                                                                                                                                                                                                                                                                                               |
| 5️⃣ | **伪标签策略** | **置信度过滤**                | 仅使用**秩平均**后 > 0.95 或 < 0.05的测试集样本，保证伪标签质量。Round 1共选出1979个样本(9.9%)，正样本比例0.510。**关键**: 必须使用秩平均后的结果，不能用原始概率                                                                                                                                                                                                                                                                 |
| 6️⃣ | **伪标签质控** | **每轮重新筛选**               | 每轮迭代重新计算**秩平均**，重新评估高置信度样本，添加新样本，移除不满足阈值的旧样本。从1979个 → 2018个(Round 2) → 触发早停，回滚到1979个                                                                                                                                                                                                                                                                                     |
| 🔒  | **防泄露措施** | **严格CV设计**               | ✅ Grid Search仅在OOF(原始y_train)执行; ✅ 伪标签基于**未见数据**(测试集秩平均)生成; ✅ 重训练OOF仅覆盖原始训练集(无伪标签污染); ✅ 权重重优化基于干净y_train。**贯穿全程**                                                                                                                                                                                                                                                        |

## 📈 性能演进路径

```
基线 (EXP001)                   0.66147
  ↓ +特征选择(0.12pp)
特征筛选 (EXP003)               0.66265
  ↓ +WOE编码(0.17pp)
WOE增强 (EXP005_v5)             0.66318
  ↓ +聚合特征(0.35pp)
组合聚合 (EXP009_v2)            0.66496
  ↓ +非线性变换(0.40pp)
多项式特征 (EXP010)             0.66551
  ↓ +LGB超参调优(0.58pp)
单模型最优 (EXP014)             0.66730
  ↓ +权重融合优化(0.18pp)
加权融合优化 (EXP017b)          0.66748
  ↓ +多轮伪标签(0.153pp)
⭐ 多轮半监督学习 (EXP023)      0.66901 🏆
```

**关键里程碑**:
- **0.66147 → 0.66551**: 特征工程黄金阶段 (+0.0404pp，非线性变换)
- **0.66551 → 0.66730**: 单模型优化 (+0.0179pp，LGB超参调优)
- **0.66730 → 0.66748**: 融合权重优化 (+0.0018pp，网格搜索)
- **0.66748 → 0.66901**: 伪标签增强 (**+0.0153pp**，多轮迭代) ✅ **最大突破**

**总累计提升**: +0.0754pp (+0.114%，从基线到最终SOTA)

---

## 📊 特征工程详解

| 步骤           | 方法        | 核心特征                                                                                                                                                                                                                                   | 新增数量 | 说明         |
| ------------ | --------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---- | ---------- |
| **Step 1-2** | 基础+增强特征   | 静态特征处理 + 流水聚合 + 增强特征<br> <br>- **静态特征**: 类别编码 (性别/婚姻/教育/行业/居住地)<br>- **流水聚合**: 收入/支出/交易总数/平均金额/方差等基础统计<br>- **增强特征**: <br>  - 邮编编码 (3位/5位前缀)<br>  - 金融比率 (贷款/分期、余额/额度利用率、利率×期限成本)<br>  - 时间差 (历史天数、贷款年龄)<br>  - 短窗口特征 (7/30天收入/支出/净流量) | ~80  | 基础汇总统计     |
| **Step 3**   | 短窗口聚合     | 7/30天收入/支出/净流量/储蓄率                                                                                                                                                                                                                     | ~15  | 短期行为捕捉     |
| **Step 4**   | **WOE编码** | 5个分类变量(title/career/residence/level/syndicated)                                                                                                                                                                                        | 5    | 风险权重编码     |
| **Step 5**   | **分组聚合**  | Z-Score + Rank Pct + Diff + Ratio (按level/loan_bin/residence)                                                                                                                                                                          | ~40  | 客户群体相对位置   |
| **Step 6**   | **多项式变换** | Log1p(金额) + Square(费率) + 交互(利率×额度)                                                                                                                                                                                                     | ~30  | 非线性关系      |
| **Step 7**   | **分布形状**  | Skewness/Kurtosis/Q25/Q50/Q75 + 时间窗口(7/30/90d)                                                                                                                                                                                         | ~35  | 交易分布特性     |
| **Step 8**   | **最终筛选**  | 剔除对象列 + 低质量特征<br>**方法1 - 对象类型剔除**:<br>  - 剔除所有 'object' dtype 列（树模型需要数值）<br>  - 只保留 id 和 label 识别列，其他全转为数值<br><br>**方法2 - 低质量特征处理**:<br>  - 剔除 NaN 填充0后无信息的列<br>  - 剔除方差<1e-10的常数列<br>  - 剔除 inf 值列                                    | -    | **模型前置处理** |

SOTA模型的性能提升离不开**系统的特征工程**。本模型综合了多个实验的最优特征方案：

### 1️⃣ **非线性特征变换** 

**实验背景**: 通过非线性变换突破了0.665的性能瓶颈，达到 **0.66551** (+0.0404pp)

**核心方法**:

#### A. 对数变换 (Log1p)
应用于**严重右偏斜的金额类特征**，使分布更接近正态分布

**变换公式**: `feature_log = np.log1p(feature)`

**适用特征** (金额类):
- `total_interest_cost` - 总利息成本
- `balance_accounts` - 账户余额数量
- `total_balance` - 总余额
- `total_credit_limit` - 总信用额度
- 所有以`_amount`, `_sum`, `_total`结尾的金额特征

**为什么有效**: 
- 原始金额数据通常呈长尾分布（少数大额，大量小额）
- Log变换将指数关系转为线性，便于树模型捕捉
- 降低异常值对模型的影响

#### B. 平方变换 (Square)
应用于**百分比/费率类特征**，捕捉二阶效应

**变换公式**: `feature_sq = feature ** 2`

**适用特征** (费率类):
- `interest_rate` - 利率
- `balance_utilization_rate` - 余额使用率
- `credit_utilization_ratio` - 信用使用率
- 所有介于0-1之间的百分比特征

**为什么有效**:
- 费率特征与风险的关系通常是非线性的（高利率 → 指数级风险上升）
- 平方变换增强了高值区域的差异，改善模型对极端费率的识别
- 在树模型中创造了额外的"特征分裂"机会

---

### 2️⃣ **聚合统计特征**

**实验背景**: 通过分组聚合创新特征，实现 **0.66496** (+0.0035pp)

**核心思想**: 基于交易流水数据，按不同维度分组计算统计量

#### A. Z-Score标准化 (异常度度量)
衡量**单个客户在群体中的异常程度**

**计算公式**:
```python
z_score = (value - group_mean) / group_std
```

**应用场景**:
- 客户总收入 vs 同行业平均收入的偏差
- 客户最大交易额 vs 历史平均的偏差
- 客户账户数 vs 同类客户平均值的偏差

**特征名称示例**:
- `income_zscore_by_industry` - 按行业分组的收入Z-Score
- `expense_zscore_by_residence` - 按居住地分组的支出Z-Score

#### B. 排名特征 (Rank Percentile)
衡量**客户在同类客户中的排名百分位数**

**计算公式**:
```python
rank_pct = rank(value) / total_count * 100
```

**应用维度**:
- 按行业分组
- 按地区/省份分组
- 按年龄段分组
- 按账户类型分组

**特征名称示例**:
- `income_rank_pct_by_industry` - 按行业的收入百分位排名
- `max_transaction_rank_pct_by_residence` - 按地区的最大交易排名

#### C. 多维组合键 (Combo Keys)
**关键发现**: 不同维度组合产生不同的客户分层

最有效的组合 (相关性>0.90):
- **Residence × Level** - 居住地 × 信用等级
  - 同一地区不同等级客户的风险差异显著
  - 高等级地区客户风险更低

**产生的特征**:
- `income_mean_residence_level` - 按居住地×等级分组的平均收入
- `expense_median_residence_level` - 按居住地×等级的中位支出
- `transaction_count_zscore_residence_level` - 按居住地×等级的交易数Z-Score

---

### 3️⃣ **高级统计聚合特征**

**新增方向**: 捕捉交易数据的**分布形状**特征（不仅仅是中心位置）

#### A. 偏度 (Skewness)
衡量交易金额分布的**非对称性**

**公式意义**: 
- 偏度 > 0: 长右尾（少数大额交易），表示异常支出倾向
- 偏度 < 0: 长左尾（少数小额交易），表示稳定支出模式
- 偏度 ≈ 0: 对称分布，支出习惯规律

**计算维度**:
- 收入交易金额的偏度
- 支出交易金额的偏度
- 按交易类型分组的偏度

**特征名称**:
- `income_amount_skewness` - 收入交易额偏度
- `expense_amount_skewness` - 支出交易额偏度

#### B. 峰度 (Kurtosis)
衡量交易金额分布的**尾部厚度**（极端值频率）

**公式意义**:
- 高峰度: 更多极端值（巨大或微小的交易），风险更高
- 低峰度: 交易额分布均匀，风险更稳定

**适用场景**:
- 风险客户往往有高峰度（偶发大额交易）
- 稳定客户峰度较低（交易金额在预期范围内）

**特征名称**:
- `income_amount_kurtosis` - 收入交易额峰度
- `expense_amount_kurtosis` - 支出交易额峰度

#### C. 分位数 (Quantiles: Q25, Q50, Q75)
更加稳健的**分布位置度量**（相比于均值）

**为什么优于均值**:
- 均值容易被极端值拉动
- 分位数对异常值更加鲁棒

**计算示例**:
```python
q25 = np.percentile(amounts, 25)  # 25%的交易额在此值以下
q50 = np.percentile(amounts, 50)  # 中位数
q75 = np.percentile(amounts, 75)  # 75%的交易额在此值以下
```

**特征名称**:
- `income_amount_q25`, `income_amount_q50`, `income_amount_q75`
- `expense_amount_q25`, `expense_amount_q50`, `expense_amount_q75`

#### D. 方向性分离统计 (Directional Separation)
**关键洞察**: 收入和支出的模式差异很大，应**分别计算**

**拆分维度**:
1. **收入特征** (所有入账交易):
   - 平均收入、最大收入、收入方差
   - 收入频率、收入稳定性
   
2. **支出特征** (所有出账交易):
   - 平均支出、最大支出、支出方差
   - 支出频率、支出波动性

3. **收支差异特征**:
   - `income_expense_ratio` - 收入支出比
   - `expense_frequency_to_income_ratio` - 支出频率与收入比
   - `expense_variability_zscore` - 支出变异性Z-Score

#### E. 时间窗口分层统计 (Time-Window Aggregation)
**思想**: 最近行为比历史行为更能预测违约

**时间窗口划分**:
- **全量** - 所有历史数据（基准）
- **最近90天** - 中期趋势
- **最近30天** - 短期异常
- **最近7天** - 即时风险信号

**分层特征示例**:
```
全量级别:
  - income_mean_all
  - expense_std_all
  
90天级别 (中期):
  - income_median_90d      ← 中期收入水平
  - expense_count_90d      ← 最近交易频率
  
30天级别 (近期):
  - income_max_30d         ← 近期大额收入
  - expense_mean_30d       ← 近期平均支出
  
7天级别 (即时):
  - transaction_count_7d   ← 最近交易活跃度
  - income_variance_7d     ← 最近收入波动
```

**为什么有效**:
- 近期违约者通常在申请前30-90天有异常交易模式
- 时间衰减权重：最近行为权重更高
- 不同时间窗口捕捉不同的风险信号

---

### 4️⃣ **WOE编码**

对**5个分类变量**进行WOE(Weight of Evidence)编码 (+0.0047pp):

**编码的分类变量**:
1. `gender` - 性别
2. `marital_status` - 婚姻状态
3. `education` - 教育程度
4. `industry` - 所在行业
5. `residence` - 居住地/省份

**WOE计算公式**:
```
WOE = ln(% 正样本 / % 负样本)
```

**WOE的价值**:
- 将分类变量转换为**单调递增的数值**
- 易于树模型学习分类特征的风险等级
- 编码后的特征对默认风险的预测性更强

**示例**:
- 某行业的默认率高 → WOE值大（更高风险信号）
- 某行业的默认率低 → WOE值小（更低风险信号）

---

## 🏗️ 模型融合详解

### 🎯 Rank Average: 伪标签的基石

**为什么选择Rank Average而不是直接相加概率？**

三个模型的概率分布特性：
```
LightGBM   → 概率偏向左侧(保守)  [多个样本聚集在0.4-0.6]
XGBoost    → 概率偏向中间(均衡)  [分散在0-1之间]
CatBoost   → 概率偏向右侧(激进)  [多个样本聚集在0.5-0.7]
```

**直接相加的问题**:
- 无法对齐三个模型的预测尺度
- 某个模型会主导融合结果
- 伪标签质量差，重训练时污染模型

**Rank Average的解决方案**:
```python
# Step 1: 转换为秩次
rank_lgb = rankdata(lgb_pred) / len(lgb_pred)    # [0, 1]
rank_xgb = rankdata(xgb_pred) / len(xgb_pred)    # [0, 1]
rank_cat = rankdata(cat_pred) / len(cat_pred)    # [0, 1]

# Step 2: 加权融合
rank_ensemble = w_lgb * rank_lgb + w_xgb * rank_xgb + w_cat * rank_cat

# Step 3: 伪标签生成（三个模型共识）
high_conf_mask = (rank_ensemble > 0.95) | (rank_ensemble < 0.05)
# 只有当所有模型都强烈认同时，才生成伪标签
```

**Rank Average的优势**:
✅ **模型无关性**: 秩次天然对齐，不受概率绝对值影响  
✅ **高置信度保证**: >0.95表示三个模型的强烈**共识**  
✅ **伪标签质量**: 低噪声，重训练时稳定有效  
✅ **迭代稳健**: 每轮迭代都基于可靠的伪标签

---

### 整体流程

```
PHASE 1: 基础模型训练 (5-Fold CV)
├─ LightGBM: 0.66730 (单模型SOTA)
├─ XGBoost: 0.66527
├─ CatBoost: 0.66573
└─ 生成OOF预测用于权重优化

PHASE 2: 权重优化 (Grid Search + Rank Average)
├─ 将OOF转换为秩次: rank_lgb, rank_xgb, rank_cat
├─ 搜索最优权重: w_lgb + w_xgb + w_cat = 1
├─ 目标: 最大化 rank_ensemble AUC
├─ 最优权重: LGB=0.50, XGB=0.10, CAT=0.40
└─ 初始融合AUC: 0.66833

PHASE 3: 多轮伪标签迭代 (Rank Average生成伪标签)
├─ Round 1: 
│  ├─ 用秩平均得到rank_ensemble
│  ├─ 选取 rank_ensemble > 0.95 或 < 0.05 的样本
│  ├─ 生成1979伪标签(9.9%)，正样本比例0.510
│  └─ Weighted AUC: 0.66890 ✅ (新高)
├─ Round 2:
│  ├─ 新增2018伪标签，总计新增39个
│  ├─ 早停触发 (连续3轮无提升)
│  └─ 无条件回滚到Round 1最佳状态
└─ 最终伪标签: 1979个样本(9.9%)

PHASE 4: 6种融合方式对比评估
├─ ① Weighted Ensemble (Rank Average): **0.66901** 🏆
├─ ② LR Stacking (Logit变换): 0.66890
├─ ③ Ridge Stacking: 0.66844
├─ ④ BayesianRidge: 0.66846
├─ ⑤ Lasso Stacking: 0.66845
└─ ⑥ LGB Stacking: 0.66618 (过复杂)

🔑 核心发现: Rank Average简单有效，胜过所有复杂Stacking
```

### 核心防泄露设计

✅ **迭代OOF验证**: 仅在原始训练集K-fold评估，无伪标签污染  
✅ **权重优化**: Grid Search仅基于干净OOF(原始y_train)  
✅ **伪标签生成**: 基于未见数据(测试集)的高置信度预测  
✅ **早停机制**: best_auc连续3轮无提升→无条件恢复最佳迭代  
✅ **伪标签质控**: 每轮重新筛选，添加新+移除不满足样本


## 💾 依赖

- `lightgbm`, `xgboost`, `catboost`
- `scikit-learn`, `pandas`, `numpy`, `scipy`
- **无需外部实验模块** - 所有逻辑完全自包含在 `run.py` 中
"""