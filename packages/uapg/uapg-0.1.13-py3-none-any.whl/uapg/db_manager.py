"""
–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö PostgreSQL –¥–ª—è OPC UA History —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π TimescaleDB.

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¥–ª—è:
1. –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
2. –£–ø—Ä–∞–≤–ª–µ–Ω–∏—è —É—á–µ—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (—Å —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ–º)
3. –ú–∏–≥—Ä–∞—Ü–∏–∏ —Å—Ö–µ–º—ã –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∫ TimescaleDB –≥–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü–∞–º
4. –†–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
5. –û—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏ —Ç–∞–±–ª–∏—Ü
6. –£–ø—Ä–∞–≤–ª–µ–Ω–∏—è TimescaleDB –≥–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü–∞–º–∏ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —á–∞–Ω–∫–∏–Ω–≥–æ–º
"""

import asyncio
import json
import logging
import os
import subprocess
import tempfile
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import base64
import asyncpg
import psycopg
#from psycopg.extensions import ISOLATION_LEVEL_AUTOCOMMIT


class DatabaseManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è OPC UA History —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π TimescaleDB.
    
    –≠—Ç–æ—Ç –∫–ª–∞—Å—Å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö PostgreSQL
    –≤–Ω–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞ HistoryTimescale.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç TimescaleDB –≥–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü—ã —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —á–∞–Ω–∫–∏–Ω–≥–æ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    –≤–º–µ—Å—Ç–æ PostgreSQL –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
    """
    
    def __init__(
        self,
        master_password: str = None,
        config_file: str = "db_config.enc",
        key_file: str = ".db_key",
        encrypted_config: str = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            master_password: –ì–ª–∞–≤–Ω—ã–π –ø–∞—Ä–æ–ª—å –¥–ª—è —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è/–¥–µ—à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
            config_file: –§–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            key_file: –§–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–ª—é—á–∞ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
            encrypted_config: –ó–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏
        """
        self.master_password = master_password
        self.config_file = Path(config_file)
        self.key_file = Path(key_file)
        self.encrypted_config = encrypted_config
        self.logger = logging.getLogger('uapg.db_manager')
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
        if master_password:
            self._init_encryption()
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            self.config = self._load_config()
        elif encrypted_config:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            self.config = self._decrypt_encrypted_config(encrypted_config)
        else:
            self.config = {}
    
    def _init_encryption(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è."""
        if self.key_file.exists():
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–ª—é—á
            with open(self.key_file, 'rb') as f:
                self.key = f.read()
        else:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∫–ª—é—á –Ω–∞ –æ—Å–Ω–æ–≤–µ master_password
            salt = os.urandom(16)
            kdf = PBKDF2HMAC(
                algorithm=hashes.SHA256(),
                length=32,
                salt=salt,
                iterations=100000,
            )
            key = base64.urlsafe_b64encode(kdf.derive(self.master_password.encode()))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª—é—á –∏ —Å–æ–ª—å
            with open(self.key_file, 'wb') as f:
                f.write(salt + key)
            
            self.key = salt + key
        
        self.cipher = Fernet(self.key[16:])  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∫–ª—é—á, –±–µ–∑ —Å–æ–ª–∏
    
    def _decrypt_encrypted_config(self, encrypted_config: str) -> Dict[str, Any]:
        """–î–µ—à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Å—Ç—Ä–æ–∫–∏."""
        try:
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64
            encrypted_data = base64.b64decode(encrypted_config)
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–ª—é—á –¥–ª—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏
            # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∑–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–ª—é—á–∞
            temp_key = Fernet.generate_key()
            temp_cipher = Fernet(temp_key)
            
            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞—Ç—å
            decrypted_data = temp_cipher.decrypt(encrypted_data)
            return json.loads(decrypted_data.decode())
        except Exception as e:
            self.logger.error(f"Failed to decrypt encrypted config: {e}")
            return {}
    
    def _encrypt_config(self, config: Dict[str, Any]) -> bytes:
        """–®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
        config_str = json.dumps(config, ensure_ascii=False)
        return self.cipher.encrypt(config_str.encode())
    
    def _decrypt_config(self, encrypted_data: bytes) -> Dict[str, Any]:
        """–î–µ—à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
        decrypted_data = self.cipher.decrypt(encrypted_data)
        return json.loads(decrypted_data.decode())
    
    def _save_config(self, config: Dict[str, Any]) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
        if hasattr(self, 'cipher'):
            encrypted_data = self._encrypt_config(config)
            with open(self.config_file, 'wb') as f:
                f.write(encrypted_data)
            self.config = config
    
    def _load_config(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞."""
        if not self.config_file.exists():
            return {}
        
        try:
            with open(self.config_file, 'rb') as f:
                encrypted_data = f.read()
            return self._decrypt_config(encrypted_data)
        except Exception as e:
            self.logger.warning(f"Failed to load config: {e}")
            return {}
    
    def get_connection_params(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –±–µ–∑ —Å–ª—É–∂–µ–±–Ω—ã—Ö –ø–æ–ª–µ–π."""
        if not self.config:
            return {}
        
        return {
            'host': self.config['host'],
            'port': self.config['port'],
            'user': self.config['user'],
            'password': self.config['password'],
            'database': self.config['database']
        }

    async def create_database(
        self,
        user: str,
        password: str,
        database: str,
        host: str = "localhost",
        port: int = 5432,
        superuser: str = "postgres",
        superuser_password: str = None,
        enable_timescaledb: bool = True
    ) -> bool:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π TimescaleDB.
        
        Args:
            user: –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è
            password: –ü–∞—Ä–æ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            database: –ò–º—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            host: –•–æ—Å—Ç PostgreSQL
            port: –ü–æ—Ä—Ç PostgreSQL
            superuser: –°—É–ø–µ—Ä–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ë–î
            superuser_password: –ü–∞—Ä–æ–ª—å —Å—É–ø–µ—Ä–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            enable_timescaledb: –í–∫–ª—é—á–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É TimescaleDB
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–æ
        """
        try:
            # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL –∫–∞–∫ —Å—É–ø–µ—Ä–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
            if superuser_password:
                conn_params = {
                    'host': host,
                    'port': port,
                    'user': superuser,
                    'password': superuser_password,
                    'database': 'postgres'
                }
            else:
                # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –±–µ–∑ –ø–∞—Ä–æ–ª—è (–¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏)
                conn_params = {
                    'host': host,
                    'port': port,
                    'user': superuser,
                    'database': 'postgres'
                }
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            conn = psycopg.connect(**conn_params)
            conn.set_isolation_level(psycopg.ISOLATION_LEVEL_AUTOCOMMIT)
            cursor = conn.cursor()
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            try:
                cursor.execute(f"CREATE USER {user} WITH PASSWORD '{password}'")
                self.logger.info(f"User {user} created successfully")
            except psycopg.errors.DuplicateObject:
                self.logger.info(f"User {user} already exists")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            try:
                cursor.execute(f"CREATE DATABASE {database} OWNER {user}")
                self.logger.info(f"Database {database} created successfully")
            except psycopg.errors.DuplicateDatabase:
                self.logger.info(f"Database {database} already exists")
            
            cursor.close()
            conn.close()
            
            # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –Ω–æ–≤–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            new_conn_params = {
                'host': host,
                'port': port,
                'user': user,
                'password': password,
                'database': database
            }
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º—ã –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π (—Ç–æ–ª—å–∫–æ TimescaleDB –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
            await self._setup_timescale_schema(new_conn_params, enable_timescaledb)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            config = {
                'user': user,
                'password': password,
                'database': database,
                'host': host,
                'port': port,
                'created_at': datetime.now().isoformat(),
                'version': '2.0',
                'architecture': 'timescale_hypertables',
                'timescaledb_enabled': enable_timescaledb
            }
            
            if hasattr(self, 'cipher'):
                self._save_config(config)
            
            self.config = config
            
            self.logger.info(f"Database {database} setup completed successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to create database: {e}")
            return False
    
    async def _setup_timescale_schema(
        self,
        conn_params: Dict[str, Any],
        enable_timescaledb: bool
    ) -> None:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ö–µ–º—ã –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å TimescaleDB –∏ –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ç–∞–±–ª–∏—Ü–∞–º–∏."""
        try:
            conn = await asyncpg.connect(**conn_params)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
            if enable_timescaledb:
                try:
                    await conn.execute('CREATE EXTENSION IF NOT EXISTS timescaledb')
                    self.logger.info("‚úÖ TimescaleDB extension enabled")
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è  TimescaleDB extension not available: {e}")
                    enable_timescaledb = False
            
            await conn.execute('CREATE EXTENSION IF NOT EXISTS "uuid-ossp"')
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü
            await self._create_timescale_tables(conn, enable_timescaledb)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö —Ç–∞–±–ª–∏—Ü –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            await self._create_timescale_metadata_tables(conn)
            
            await conn.close()
            
        except Exception as e:
            self.logger.error(f"Failed to setup TimescaleDB schema: {e}")
            raise
    
    # –£–¥–∞–ª–µ–Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ legacy-—Å—Ö–µ–º—ã —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Ç–∞–±–ª–∏—Ü–∞–º–∏
    
    async def _create_timescale_tables(self, conn: asyncpg.Connection, enable_timescaledb: bool) -> None:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≥–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü TimescaleDB –±–µ–∑ PostgreSQL –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è."""
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (–æ–±—ã—á–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –±–µ–∑ PARTITION BY)
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS variables_data (
                variable_id INTEGER NOT NULL,
                time TIMESTAMPTZ NOT NULL,
                value DOUBLE PRECISION NOT NULL,
                quality SMALLINT,
                source_time TIMESTAMPTZ,
                server_time TIMESTAMPTZ DEFAULT NOW()
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å–æ–±—ã—Ç–∏–π (–æ–±—ã—á–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –±–µ–∑ PARTITION BY)
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS events_data (
                node_id INTEGER NOT NULL,
                event_type_id INTEGER NOT NULL,
                time TIMESTAMPTZ NOT NULL,
                event_data JSONB NOT NULL,
                source_time TIMESTAMPTZ,
                server_time TIMESTAMPTZ DEFAULT NOW()
            )
        ''')
        
        if enable_timescaledb:
            # –°–æ–∑–¥–∞–Ω–∏–µ –≥–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü TimescaleDB —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —á–∞–Ω–∫–∏–Ω–≥–æ–º
            try:
                # –ì–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
                await conn.execute('''
                    SELECT create_hypertable(
                        'variables_data', 
                        'time',
                        chunk_time_interval => INTERVAL '1 day',
                        if_not_exists => TRUE
                    )
                ''')
                
                # –ì–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å–æ–±—ã—Ç–∏–π
                await conn.execute('''
                    SELECT create_hypertable(
                        'events_data', 
                        'time',
                        chunk_time_interval => INTERVAL '1 day',
                        if_not_exists => TRUE
                    )
                ''')
                
                # –í–∫–ª—é—á–∞–µ–º columnstore –¥–ª—è —Å–∂–∞—Ç–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
                await conn.execute('''
                    ALTER TABLE variables_data SET (
                        timescaledb.compress,
                        timescaledb.compress_orderby = 'time DESC'
                    )
                ''')
                
                # –í–∫–ª—é—á–∞–µ–º columnstore –¥–ª—è —Å–∂–∞—Ç–∏—è —Å–æ–±—ã—Ç–∏–π
                await conn.execute('''
                    ALTER TABLE events_data SET (
                        timescaledb.compress,
                        timescaledb.compress_orderby = 'time DESC'
                    )
                ''')
                
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–∂–∞—Ç–∏—è
                await conn.execute('''
                    SELECT add_compression_policy(
                        'variables_data', 
                        INTERVAL '7 days',
                        if_not_exists => TRUE
                    )
                ''')
                
                await conn.execute('''
                    SELECT add_compression_policy(
                        'events_data', 
                        INTERVAL '7 days',
                        if_not_exists => TRUE
                    )
                ''')
                
                self.logger.info("‚úÖ –ì–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü—ã TimescaleDB —Å–æ–∑–¥–∞–Ω—ã —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —á–∞–Ω–∫–∏–Ω–≥–æ–º")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü—ã TimescaleDB: {e}")
                self.logger.info("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ–±—ã—á–Ω—ã–º–∏ —Ç–∞–±–ª–∏—Ü–∞–º–∏ PostgreSQL")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_variables_time ON variables_data (time DESC)')
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_variables_variable_time ON variables_data (variable_id, time DESC)')
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_events_time ON events_data (time DESC)')
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_events_node_time ON events_data (node_id, time DESC)')
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_events_event_data ON events_data USING GIN (event_data)')
        
        self.logger.info("‚úÖ –¢–∞–±–ª–∏—Ü—ã TimescaleDB —Å–æ–∑–¥–∞–Ω—ã —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏")
    
    async def _create_timescale_metadata_tables(self, conn: asyncpg.Connection) -> None:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è TimescaleDB –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã."""
        # –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS variable_metadata (
                id SERIAL PRIMARY KEY,
                variable_id INTEGER NOT NULL UNIQUE,
                node_id TEXT NOT NULL,
                node_name TEXT,
                data_type TEXT,
                created_at TIMESTAMPTZ DEFAULT NOW(),
                retention_period INTERVAL DEFAULT '365 days',
                max_records BIGINT,
                partition_group INTEGER,
                is_active BOOLEAN DEFAULT TRUE
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Å–æ–±—ã—Ç–∏–π
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS event_type_metadata (
                id SERIAL PRIMARY KEY,
                event_type_id INTEGER NOT NULL,
                event_type_name TEXT,
                source_node_id TEXT NOT NULL,
                fields JSONB NOT NULL,
                created_at TIMESTAMPTZ DEFAULT NOW(),
                retention_period INTERVAL DEFAULT '365 days',
                max_records BIGINT,
                partition_group INTEGER,
                is_active BOOLEAN DEFAULT TRUE,
                UNIQUE(event_type_id, source_node_id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –≤–µ—Ä—Å–∏–π —Å—Ö–µ–º—ã
        await conn.execute('''
            CREATE TABLE IF NOT EXISTS schema_version (
                id SERIAL PRIMARY KEY,
                version TEXT NOT NULL UNIQUE,
                applied_at TIMESTAMPTZ DEFAULT NOW(),
                description TEXT,
                migration_script TEXT,
                architecture TEXT DEFAULT 'timescale_hypertables'
            )
        ''')
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_variable_metadata_variable_id ON variable_metadata(variable_id)')
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_event_type_metadata_source ON event_type_metadata(source_node_id)')
        await conn.execute('CREATE INDEX IF NOT EXISTS idx_event_type_metadata_type ON event_type_metadata(event_type_id)')
        
        # –í—Å—Ç–∞–≤–∫–∞ –Ω–∞—á–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏ —Å—Ö–µ–º—ã
        await conn.execute('''
            INSERT INTO schema_version (version, description, architecture) 
            VALUES ('2.0', 'TimescaleDB hypertables schema', 'timescale_hypertables') 
            ON CONFLICT (version) DO NOTHING
        ''')
        
        self.logger.info("‚úÖ –¢–∞–±–ª–∏—Ü—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö TimescaleDB —Å–æ–∑–¥–∞–Ω—ã")
    
    # –£–¥–∞–ª–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑–æ–≤—ã—Ö —Ç–∞–±–ª–∏—Ü –¥–ª—è legacy-—Å—Ö–µ–º—ã
    
    async def migrate_to_timescale(self) -> bool:
        """
        –ú–∏–≥—Ä–∞—Ü–∏—è –æ—Ç —Å—Ç–∞—Ä–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∫ TimescaleDB.
        
        Returns:
            True –µ—Å–ª–∏ –º–∏–≥—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞
        """
        if not self.config:
            self.logger.error("No database configuration found")
            return False
        
        try:
            conn_params = self.get_connection_params()
            conn = await asyncpg.connect(**conn_params)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—É—â–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            current_architecture = await conn.fetchval('''
                SELECT architecture FROM schema_version 
                ORDER BY applied_at DESC LIMIT 1
            ''')
            
            if current_architecture == 'timescale_hypertables':
                self.logger.info("Database already uses TimescaleDB architecture")
                await conn.close()
                return True
            
            self.logger.info("Starting migration to TimescaleDB architecture...")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–∞–±–ª–∏—Ü
            await self._create_timescale_tables(conn, True)
            await self._create_timescale_metadata_tables(conn)
            
            # –ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (–±–∞–∑–æ–≤–∞—è –≤–µ—Ä—Å–∏—è)
            await self._migrate_data_to_timescale(conn)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ —Å—Ö–µ–º—ã
            await conn.execute('''
                INSERT INTO schema_version (version, description, architecture) 
                VALUES ('2.0', 'Migrated to TimescaleDB hypertables', 'timescale_hypertables')
                ON CONFLICT (version) DO NOTHING
            ''')
            
            await conn.close()
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            self.config['version'] = '2.0'
            self.config['architecture'] = 'timescale_hypertables'
            if hasattr(self, 'cipher'):
                self._save_config(self.config)
            
            self.logger.info("‚úÖ Migration to TimescaleDB completed successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"Migration to TimescaleDB failed: {e}")
            return False
    
    async def _migrate_data_to_timescale(self, conn: asyncpg.Connection) -> None:
        """–ë–∞–∑–æ–≤–∞—è –º–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∫ TimescaleDB –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ."""
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            variable_tables = await conn.fetch('''
                SELECT table_name, node_id FROM variable_metadata 
                WHERE table_name IS NOT NULL
            ''')
            
            for table in variable_tables:
                table_name = table['table_name']
                node_id = table['node_id']
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
                exists = await conn.fetchval(f'''
                    SELECT 1 FROM information_schema.tables 
                    WHERE table_name = '{table_name}'
                ''')
                
                if exists:
                    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Ç–∏—Ü–∏–∏ –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
                    await self._create_variable_partition(conn, int(node_id) if node_id.isdigit() else 1)
                    
                    # –ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (–±–∞–∑–æ–≤–∞—è –≤–µ—Ä—Å–∏—è)
                    await self._migrate_variable_data(conn, table_name, int(node_id) if node_id.isdigit() else 1)
            
            self.logger.info("‚úÖ Basic data migration completed")
            
        except Exception as e:
            self.logger.error(f"Data migration failed: {e}")
            raise
    
    async def _create_variable_partition(self, conn: asyncpg.Connection, variable_id: int) -> None:
        """TimescaleDB –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç —á–∞–Ω–∫–∞–º–∏ - –ø–∞—Ä—Ç–∏—Ü–∏–∏ –Ω–µ –Ω—É–∂–Ω—ã."""
        # TimescaleDB –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–µ—Ç —á–∞–Ω–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è
        self.logger.info(f"‚ÑπÔ∏è  TimescaleDB –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç —á–∞–Ω–∫–∞–º–∏ –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π {variable_id}")
        pass
    
    async def _migrate_variable_data(self, conn: asyncpg.Connection, source_table: str, variable_id: int) -> None:
        """–ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏–∑ —Å—Ç–∞—Ä–æ–π —Ç–∞–±–ª–∏—Ü—ã."""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏—Å—Ö–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
            columns = await conn.fetch(f'''
                SELECT column_name, data_type 
                FROM information_schema.columns 
                WHERE table_name = '{source_table}'
                ORDER BY ordinal_position
            ''')
            
            # –ü—Ä–æ—Å—Ç–∞—è –º–∏–≥—Ä–∞—Ü–∏—è (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å)
            self.logger.info(f"üìä –ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ {source_table} –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π {variable_id}")
            
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
            # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {source_table}: {e}")
    
    async def backup_database(
        self,
        backup_path: str = None,
        backup_format: str = "custom",
        compression: bool = True
    ) -> Optional[str]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            backup_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±—ç–∫–∞–ø–∞
            backup_format: –§–æ—Ä–º–∞—Ç –±—ç–∫–∞–ø–∞ (custom, plain, directory)
            compression: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∂–∞—Ç–∏–µ
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –±—ç–∫–∞–ø—É –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        if not self.config:
            self.logger.error("No database configuration found")
            return None
        
        try:
            if not backup_path:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_path = f"backup_{self.config['database']}_{timestamp}.backup"
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã pg_dump
            cmd = [
                'pg_dump',
                f'--host={self.config["host"]}',
                f'--port={self.config["port"]}',
                f'--username={self.config["user"]}',
                f'--dbname={self.config["database"]}',
                f'--format={backup_format}',
                f'--file={backup_path}'
            ]
            
            if compression:
                cmd.append('--compress=9')
            
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –ø–∞—Ä–æ–ª—è
            env = os.environ.copy()
            env['PGPASSWORD'] = self.config['password']
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã
            result = subprocess.run(
                cmd,
                env=env,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                self.logger.info(f"Database backup created: {backup_path}")
                return backup_path
            else:
                self.logger.error(f"Backup failed: {result.stderr}")
                return None
                
        except Exception as e:
            self.logger.error(f"Backup creation failed: {e}")
            return None
    
    async def restore_database(
        self,
        backup_path: str,
        drop_existing: bool = False
    ) -> bool:
        """
        –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏.
        
        Args:
            backup_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±—ç–∫–∞–ø–∞
            drop_existing: –£–¥–∞–ª–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ë–î –ø–µ—Ä–µ–¥ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º
            
        Returns:
            True –µ—Å–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ
        """
        if not self.config:
            self.logger.error("No database configuration found")
            return False
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –±—ç–∫–∞–ø–∞
            if backup_path.endswith('.backup') or backup_path.endswith('.dump'):
                format_flag = '--format=custom'
            elif backup_path.endswith('.sql'):
                format_flag = '--format=plain'
            else:
                format_flag = '--format=custom'
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã pg_restore
            cmd = [
                'pg_restore',
                f'--host={self.config["host"]}',
                f'--port={self.config["port"]}',
                f'--username={self.config["user"]}',
                f'--dbname={self.config["database"]}',
                format_flag,
                '--clean',  # –û—á–∏—Å—Ç–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                '--if-exists',  # –ü—Ä–æ–¥–æ–ª–∂–∞—Ç—å –µ—Å–ª–∏ –æ–±—ä–µ–∫—Ç –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                backup_path
            ]
            
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –ø–∞—Ä–æ–ª—è
            env = os.environ.copy()
            env['PGPASSWORD'] = self.config['password']
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã
            result = subprocess.run(
                cmd,
                env=env,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                self.logger.info(f"Database restored from: {backup_path}")
                return True
            else:
                self.logger.error(f"Restore failed: {result.stderr}")
                return False
                
        except Exception as e:
            self.logger.error(f"Database restore failed: {e}")
            return False
    
    async def cleanup_old_data(
        self,
        retention_days: int = 365,
        variable_ids: List[int] = None,
        event_types: List[int] = None
    ) -> bool:
        """
        –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.
        
        Args:
            retention_days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
            variable_ids: –°–ø–∏—Å–æ–∫ ID –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ (None - –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ)
            event_types: –°–ø–∏—Å–æ–∫ —Ç–∏–ø–æ–≤ —Å–æ–±—ã—Ç–∏–π –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ (None - –≤—Å–µ —Ç–∏–ø—ã)
            
        Returns:
            True –µ—Å–ª–∏ –æ—á–∏—Å—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞
        """
        if not self.config:
            self.logger.error("No database configuration found")
            return False
        
        try:
            conn_params = self.get_connection_params()
            conn = await asyncpg.connect(**conn_params)
            
            cutoff_date = datetime.now() - timedelta(days=retention_days)
            
            if self.config.get('architecture') == 'timescale_hypertables':
                # –û—á–∏—Å—Ç–∫–∞ –¥–ª—è TimescaleDB –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
                if variable_ids:
                    for variable_id in variable_ids:
                        deleted = await conn.execute('''
                            DELETE FROM variables_data 
                            WHERE variable_id = $1 AND time < $2
                        ''', variable_id, cutoff_date)
                        self.logger.info(f"Cleaned old data for variable {variable_id}")
                else:
                    # –û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
                    deleted = await conn.execute('''
                        DELETE FROM variables_data WHERE time < $1
                    ''', cutoff_date)
                    self.logger.info(f"Cleaned all old data from variables_data")
                
                if event_types:
                    for event_type in event_types:
                        deleted = await conn.execute('''
                            DELETE FROM events_data 
                            WHERE event_type_id = $1 AND time < $2
                        ''', event_type, cutoff_date)
                        self.logger.info(f"Cleaned old data for event type {event_type}")
                else:
                    # –û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
                    deleted = await conn.execute('''
                        DELETE FROM events_data WHERE time < $1
                    ''', cutoff_date)
                    self.logger.info(f"Cleaned all old data from events_data")
            else:
                # –ï—Å–ª–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—á–∏—â–∞–µ–º Timescale —Ç–∞–±–ª–∏—Ü—ã
                if variable_ids:
                    for variable_id in variable_ids:
                        deleted = await conn.execute('''
                            DELETE FROM variables_data 
                            WHERE variable_id = $1 AND time < $2
                        ''', variable_id, cutoff_date)
                        self.logger.info(f"Cleaned old data for variable {variable_id}")
                else:
                    # –û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
                    deleted = await conn.execute('''
                        DELETE FROM variables_data WHERE time < $1
                    ''', cutoff_date)
                    self.logger.info(f"Cleaned all old data from variables_data")
                
                if event_types:
                    for event_type in event_types:
                        deleted = await conn.execute('''
                            DELETE FROM events_data 
                            WHERE event_type_id = $1 AND time < $2
                        ''', event_type, cutoff_date)
                        self.logger.info(f"Cleaned old data for event type {event_type}")
                else:
                    # –û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
                    deleted = await conn.execute('''
                        DELETE FROM events_data WHERE time < $1
                    ''', cutoff_date)
                    self.logger.info(f"Cleaned all old data from events_data")
            
            await conn.close()
            
            self.logger.info(f"Data cleanup completed for records older than {retention_days} days")
            return True
            
        except Exception as e:
            self.logger.error(f"Data cleanup failed: {e}")
            return False
    
    # –£–¥–∞–ª–µ–Ω–∞ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö legacy-—Å—Ö–µ–º—ã
    
    async def remove_node_tables(self, node_ids: List[str]) -> bool:
        """
        –£–¥–∞–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü —É–∑–ª–æ–≤ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            node_ids: –°–ø–∏—Å–æ–∫ ID —É–∑–ª–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            
        Returns:
            True –µ—Å–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ
        """
        if not self.config:
            self.logger.error("No database configuration found")
            return False
        
        try:
            conn_params = self.get_connection_params()
            conn = await asyncpg.connect(**conn_params)
            
            if self.config.get('architecture') == 'timescale_hypertables':
                # –î–ª—è TimescaleDB –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã - –¥–µ–∞–∫—Ç–∏–≤–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
                for node_id in node_ids:
                    await conn.execute('''
                        UPDATE variable_metadata 
                        SET is_active = FALSE 
                        WHERE node_id = $1
                    ''', node_id)
                    self.logger.info(f"Deactivated variable metadata for node {node_id}")
            else:
                # –î–ª—è —Å—Ç–∞—Ä–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã - —É–¥–∞–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
                for node_id in node_ids:
                    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–∞–±–ª–∏—Ü–µ
                    metadata = await conn.fetchrow(
                        'SELECT table_name FROM variable_metadata WHERE node_id = $1',
                        node_id
                    )
                    
                    if metadata:
                        # –£–¥–∞–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –¥–∞–Ω–Ω—ã—Ö
                        await conn.execute(f'DROP TABLE IF EXISTS "{metadata["table_name"]}"')
                        
                        # –£–¥–∞–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                        await conn.execute(
                            'DELETE FROM variable_metadata WHERE node_id = $1',
                            node_id
                        )
                        
                        self.logger.info(f"Removed table and metadata for node {node_id}")
            
            await conn.close()
            
            self.logger.info(f"Processed {len(node_ids)} node tables successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to remove node tables: {e}")
            return False
    
    async def clear_all_data(self) -> bool:
        """
        –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –æ—Ç –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Returns:
            True –µ—Å–ª–∏ –æ—á–∏—Å—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞
        """
        if not self.config:
            self.logger.error("No database configuration found")
            return False
        
        try:
            conn_params = self.get_connection_params()
            conn = await asyncpg.connect(**conn_params)
            
            if self.config.get('architecture') == 'timescale_hypertables':
                # –û—á–∏—Å—Ç–∫–∞ –¥–ª—è TimescaleDB –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
                await conn.execute('TRUNCATE TABLE variables_data')
                await conn.execute('TRUNCATE TABLE events_data')
                await conn.execute('DELETE FROM variable_metadata')
                await conn.execute('DELETE FROM event_type_metadata')
                
                self.logger.info("Cleared all data from TimescaleDB tables")
            else:
                # –ï—Å–ª–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—á–∏—â–∞–µ–º Timescale —Ç–∞–±–ª–∏—Ü—ã
                await conn.execute('TRUNCATE TABLE variables_data')
                await conn.execute('TRUNCATE TABLE events_data')
                await conn.execute('DELETE FROM variable_metadata')
                await conn.execute('DELETE FROM event_type_metadata')
            
            await conn.close()
            
            self.logger.info("All data cleared from database")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to clear all data: {e}")
            return False
    
    async def get_database_info(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        """
        if not self.config:
            return {"error": "No database configuration found"}
        
        try:
            conn_params = self.get_connection_params()
            conn = await asyncpg.connect(**conn_params)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ —Å—Ö–µ–º—ã
            schema_version = await conn.fetchrow('''
                SELECT version, architecture, applied_at, description 
                FROM schema_version 
                ORDER BY applied_at DESC LIMIT 1
            ''')
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü
            tables_exist = await conn.fetch('''
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name IN ('variables_data', 'events_data', 'variable_metadata', 'event_type_metadata')
            ''')
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö
            record_counts = {}
            for table in ['variables_data', 'events_data', 'variable_metadata', 'event_type_metadata']:
                try:
                    count = await conn.fetchval(f'SELECT COUNT(*) FROM {table}')
                    record_counts[table] = count
                except Exception:
                    record_counts[table] = "table not found"
            
            await conn.close()
            
            return {
                "schema_version": dict(schema_version) if schema_version else None,
                "tables_exist": [dict(t) for t in tables_exist],
                "record_counts": record_counts,
                "architecture": schema_version['architecture'] if schema_version else "unknown"
            }
            
        except Exception as e:
            self.logger.error(f"Failed to get database info: {e}")
            return {"error": str(e)}
    
    async def get_timescale_info(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ TimescaleDB —Ç–∞–±–ª–∏—Ü–∞—Ö –∏ –ø–∞—Ä—Ç–∏—Ü–∏—è—Ö.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ TimescaleDB
        """
        if not self.config or self.config.get('architecture') != 'timescale_hypertables':
            return {"error": "Database does not use TimescaleDB architecture"}
        
        try:
            conn_params = self.get_connection_params()
            conn = await asyncpg.connect(**conn_params)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü–∞—Ö
            hypertables = await conn.fetch('''
                SELECT 
                    hypertable_name,
                    num_chunks,
                    compression_enabled,
                    is_compressed
                FROM timescaledb_information.hypertables
            ''')
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —á–∞–Ω–∫–∞—Ö
            chunks = await conn.fetch('''
                SELECT 
                    chunk_name,
                    chunk_schema,
                    range_start,
                    range_end,
                    is_compressed
                FROM timescaledb_information.chunks 
                WHERE hypertable_name IN ('variables_data', 'events_data')
                ORDER BY range_start DESC
                LIMIT 20
            ''')
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∂–∞—Ç–∏—è
            compression_stats = await conn.fetch('''
                SELECT 
                    hypertable_name,
                    compression_status,
                    uncompressed_total_chunks,
                    compressed_total_chunks
                FROM timescaledb_information.compression_settings
            ''')
            
            await conn.close()
            
            return {
                "hypertables": [dict(h) for h in hypertables],
                "chunks": [dict(c) for c in chunks],
                "compression_stats": [dict(cs) for cs in compression_stats]
            }
            
        except Exception as e:
            self.logger.error(f"Failed to get TimescaleDB info: {e}")
            return {"error": str(e)}
    
    async def create_variable_partition(self, variable_id: int) -> bool:
        """
        TimescaleDB –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç —á–∞–Ω–∫–∞–º–∏ - –ø–∞—Ä—Ç–∏—Ü–∏–∏ –Ω–µ –Ω—É–∂–Ω—ã.
        
        Args:
            variable_id: ID –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            
        Returns:
            True (TimescaleDB –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç —á–∞–Ω–∫–∞–º–∏)
        """
        # TimescaleDB –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–µ—Ç —á–∞–Ω–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è
        self.logger.info(f"‚ÑπÔ∏è  TimescaleDB –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç —á–∞–Ω–∫–∞–º–∏ –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π {variable_id}")
        return True
    
    async def create_event_partition(self, node_id: int) -> bool:
        """
        TimescaleDB –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç —á–∞–Ω–∫–∞–º–∏ - –ø–∞—Ä—Ç–∏—Ü–∏–∏ –Ω–µ –Ω—É–∂–Ω—ã.
        
        Args:
            node_id: ID —É–∑–ª–∞
            
        Returns:
            True (TimescaleDB –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç —á–∞–Ω–∫–∞–º–∏)
        """
        # TimescaleDB –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–µ—Ç —á–∞–Ω–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è
        self.logger.info(f"‚ÑπÔ∏è  TimescaleDB –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç —á–∞–Ω–∫–∞–º–∏ –¥–ª—è —É–∑–ª–∞ {node_id}")
        return True
    
    async def enable_compression(self, table_name: str, chunk_time_interval: str = '1 day') -> bool:
        """
        –í–∫–ª—é—á–µ–Ω–∏–µ —Å–∂–∞—Ç–∏—è –¥–ª—è TimescaleDB –≥–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü—ã.
        
        Args:
            table_name: –ò–º—è —Ç–∞–±–ª–∏—Ü—ã
            chunk_time_interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è —á–∞–Ω–∫–æ–≤
            
        Returns:
            True –µ—Å–ª–∏ —Å–∂–∞—Ç–∏–µ –≤–∫–ª—é—á–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            conn_params = self.get_connection_params()
            conn = await asyncpg.connect(**conn_params)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –≥–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü–µ–π TimescaleDB
            is_hypertable = await conn.fetchval(f'''
                SELECT 1 FROM timescaledb_information.hypertables 
                WHERE hypertable_name = $1
            ''', table_name)
            
            if not is_hypertable:
                self.logger.warning(f"–¢–∞–±–ª–∏—Ü–∞ {table_name} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≥–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü–µ–π TimescaleDB")
                await conn.close()
                return False
            
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ —á–∞–Ω–∫–æ–≤
            await conn.execute(f'''
                SELECT set_chunk_time_interval('{table_name}', INTERVAL '{chunk_time_interval}')
            ''')
            
            # –í–∫–ª—é—á–µ–Ω–∏–µ —Å–∂–∞—Ç–∏—è
            await conn.execute(f'''
                ALTER TABLE {table_name} SET (
                    timescaledb.compress,
                    timescaledb.compress_orderby = 'time DESC'
                )
            ''')
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª–∏—Ç–∏–∫–∏ —Å–∂–∞—Ç–∏—è
            await conn.execute(f'''
                SELECT add_compression_policy('{table_name}', INTERVAL '30 days')
            ''')
            
            await conn.close()
            
            self.logger.info(f"‚úÖ –°–∂–∞—Ç–∏–µ –≤–∫–ª—é—á–µ–Ω–æ –¥–ª—è –≥–∏–ø–µ—Ä—Ç–∞–±–ª–∏—Ü—ã {table_name}")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to enable compression: {e}")
            return False
    
    def change_master_password(self, new_master_password: str) -> bool:
        """
        –ò–∑–º–µ–Ω–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ –ø–∞—Ä–æ–ª—è.
        
        Args:
            new_master_password: –ù–æ–≤—ã–π –≥–ª–∞–≤–Ω—ã–π –ø–∞—Ä–æ–ª—å
            
        Returns:
            True –µ—Å–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫–ª—é—á–∞
            salt = os.urandom(16)
            kdf = PBKDF2HMAC(
                algorithm=hashes.SHA256(),
                length=32,
                salt=salt,
                iterations=100000,
            )
            new_key = base64.urlsafe_b64encode(kdf.derive(new_master_password.encode()))
            
            # –ü–µ—Ä–µ—à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            if self.config:
                new_cipher = Fernet(new_key)
                encrypted_data = new_cipher.encrypt(json.dumps(self.config, ensure_ascii=False).encode())
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫–ª—é—á–∞
                with open(self.key_file, 'wb') as f:
                    f.write(salt + new_key)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                with open(self.config_file, 'wb') as f:
                    f.write(encrypted_data)
                
                self.key = salt + new_key
                self.cipher = new_cipher
                self.master_password = new_master_password
                
                self.logger.info("Master password changed successfully")
                return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"Failed to change master password: {e}")
            return False
    
    def export_config(self, export_path: str) -> bool:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≤ –æ—Ç–∫—Ä—ã—Ç–æ–º –≤–∏–¥–µ.
        
        Args:
            export_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            
        Returns:
            True –µ—Å–ª–∏ —ç–∫—Å–ø–æ—Ä—Ç —É—Å–ø–µ—à–µ–Ω
        """
        try:
            if self.config:
                with open(export_path, 'w', encoding='utf-8') as f:
                    json.dump(self.config, f, indent=2, ensure_ascii=False)
                
                self.logger.info(f"Configuration exported to {export_path}")
                return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"Failed to export configuration: {e}")
            return False
    
    def import_config(self, import_path: str) -> bool:
        """
        –ò–º–ø–æ—Ä—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞.
        
        Args:
            import_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            
        Returns:
            True –µ—Å–ª–∏ –∏–º–ø–æ—Ä—Ç —É—Å–ø–µ—à–µ–Ω
        """
        try:
            with open(import_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            if hasattr(self, 'cipher'):
                self._save_config(config)
            
            self.config = config
            
            self.logger.info(f"Configuration imported from {import_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to import configuration: {e}")
            return False


# –£—Ç–∏–ª–∏—Ç–∞—Ä–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –∫–ª–∞—Å—Å–∞
async def create_database_standalone(
    user: str,
    password: str,
    database: str,
    host: str = "localhost",
    port: int = 5432,
    superuser: str = "postgres",
    superuser_password: str = None,
    master_password: str = "default_master_password"
) -> bool:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ DatabaseManager.
    
    Args:
        user: –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è
        password: –ü–∞—Ä–æ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        database: –ò–º—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        host: –•–æ—Å—Ç PostgreSQL
        port: –ü–æ—Ä—Ç PostgreSQL
        superuser: –°—É–ø–µ—Ä–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ë–î
        superuser_password: –ü–∞—Ä–æ–ª—å —Å—É–ø–µ—Ä–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        master_password: –ì–ª–∞–≤–Ω—ã–π –ø–∞—Ä–æ–ª—å –¥–ª—è —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
        
    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–æ
    """
    manager = DatabaseManager(master_password)
    return await manager.create_database(
        user, password, database, host, port, superuser, superuser_password
    )


async def backup_database_standalone(
    user: str,
    password: str,
    database: str,
    host: str = "localhost",
    port: int = 5432,
    backup_path: str = None,
    master_password: str = "default_master_password"
) -> Optional[str]:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ DatabaseManager.
    
    Args:
        user: –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        password: –ü–∞—Ä–æ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        database: –ò–º—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        host: –•–æ—Å—Ç PostgreSQL
        port: –ü–æ—Ä—Ç PostgreSQL
        backup_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±—ç–∫–∞–ø–∞
        master_password: –ì–ª–∞–≤–Ω—ã–π –ø–∞—Ä–æ–ª—å –¥–ª—è —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
        
    Returns:
        –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –±—ç–∫–∞–ø—É –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    manager = DatabaseManager(master_password)
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    manager.config = {
        'user': user,
        'password': password,
        'database': database,
        'host': host,
        'port': port
    }
    return await manager.backup_database(backup_path)


async def migrate_to_timescale_standalone(
    user: str,
    password: str,
    database: str,
    host: str = "localhost",
    port: int = 5432,
    master_password: str = "default_master_password"
) -> bool:
    """
    –ú–∏–≥—Ä–∞—Ü–∏—è –∫ TimescaleDB –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ DatabaseManager.
    
    Args:
        user: –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        password: –ü–∞—Ä–æ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        database: –ò–º—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        host: –•–æ—Å—Ç PostgreSQL
        port: –ü–æ—Ä—Ç PostgreSQL
        master_password: –ì–ª–∞–≤–Ω—ã–π –ø–∞—Ä–æ–ª—å –¥–ª—è —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
        
    Returns:
        True –µ—Å–ª–∏ –º–∏–≥—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞
    """
    manager = DatabaseManager(master_password)
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    manager.config = {
        'user': user,
        'password': password,
        'database': database,
        'host': host,
        'port': port
    }
    return await manager.migrate_to_timescale()
