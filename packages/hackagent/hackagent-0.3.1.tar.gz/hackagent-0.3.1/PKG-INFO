Metadata-Version: 2.4
Name: hackagent
Version: 0.3.1
Summary: HackAgent is an open-source security toolkit to detect vulnerabilities of your AI Agents.
Author-email: AI Security Lab <ais@ai4i.it>
License: Apache-2.0
License-File: LICENSE
Keywords: agents,ai,security,testing,vulnerabilities
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.10
Requires-Dist: click>=8.1.0
Requires-Dist: litellm>=1.69.2
Requires-Dist: openai>=1.0.0
Requires-Dist: pandas>=2.2.3
Requires-Dist: pydantic>=2.0
Requires-Dist: python-dotenv>=1.1.0
Requires-Dist: pyyaml>=6.0.0
Requires-Dist: requests>=2.31.0
Requires-Dist: rich>=14.0.0
Requires-Dist: textual>=1.0.0
Description-Content-Type: text/markdown

<div align="center">

<p align="center">
  <img src="https://docs.hackagent.dev/img/banner.svg" alt="HackAgent - AI Agent Security Testing Toolkit" width="800">
</p>

  <strong>AI Security Red-Team Toolkit</strong> 

<br>

[App](https://app.hackagent.dev/) -- [Docs](https://docs.hackagent.dev/) -- [API](https://api.hackagent.dev/schema/redoc)


<br>

![Python Version](https://img.shields.io/badge/python-3.10%2B-blue)
![License](https://img.shields.io/badge/license-Apache%202.0-green)
![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)
[![Commitizen](https://img.shields.io/badge/commitizen-friendly-brightgreen.svg)](http://commitizen.github.io/cz-cli/)
![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)
![Test Coverage](https://img.shields.io/codecov/c/github/AISecurityLab/hackagent)
![CI Status](https://img.shields.io/github/actions/workflow/status/AISecurityLab/hackagent/ci.yml)


<br>

</div>


## Overview

HackAgent is an open-source toolkit designed to help security researchers, developers and AI safety practitioners evaluate the security of AI agents. 
It provides a structured approach to discover potential vulnerabilities, including prompt injection, jailbreaking techniques, and other attack vectors.

## üî• Features

- **Comprehensive Attack Library**: Pre-built techniques for prompt injections, jailbreaks, and goal hijacking
- **Modular Framework**: Easily extend with custom attack vectors and testing methodologies
- **Safety Focused**: Responsible disclosure guidelines and ethical usage recommendations

### üîå AI Agent Frameworks Supported

[![LiteLLM](https://img.shields.io/badge/LiteLLM-blue?style=flat&logo=github)](https://github.com/BerriAI/litellm)
[![ADK](https://img.shields.io/badge/Google-ADK-green?style=flat&logo=openai)](https://google.github.io/adk-docs/)
[![OpenAI](https://img.shields.io/badge/OpenAI-SDK-412991?style=flat&logo=openai)](https://platform.openai.com/docs)

## üöÄ Installation


### Installation from PyPI

HackAgent can be installed directly from PyPI:

```bash
# With uv (recommended)
uv add hackagent

# Or with pip
pip install hackagent
```

## üìö Quick Start

Run the interactive CLI to start testing your AI agents:

```bash
hackagent
```

Obtain your credentials at [https://app.hackagent.dev](https://app.hackagent.dev)

For detailed examples and advanced usage, visit our [documentation](https://docs.hackagent.dev).

## üìä Reporting

HackAgent automatically sends test results to the dashboard for analysis and visualization. 

Access your dashboard at [https://app.hackagent.dev](https://app.hackagent.dev)

## ü§ù Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) and [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) for guidelines.

## üìú License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ‚ö†Ô∏è Disclaimer

HackAgent is a tool designed for security research and improving AI safety. Always obtain proper authorization before testing any AI systems. The authors are not responsible for any misuse of this software.

---

*This project is for educational and research purposes. Always use responsibly and ethically.*
