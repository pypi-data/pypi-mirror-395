import matplotlib.pyplot as plt
import torch
from sklearn.metrics import classification_report,accuracy_score
import numpy as np
import polars as p
from scipy.sparse import csr_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.decomposition import TruncatedSVD



class MalwareClassifier:
    def __init__(self, X_train,num_classes:int=2, lr: float=0.01, max_epoch: int=1000, tol:float=1e-6):
        self.X_train = X_train
        self.num_features = X_train.shape[1]
        self.num_samples = X_train.shape[0]
        self.num_classes = num_classes
        self.lr =lr
        self.max_epoch = max_epoch
        self.tol=tol

        # self.X_train=None 
        # self.y_train=None


        # Model parameters, initialize
        self.W = torch.randn(self.num_features,num_classes, requires_grad=True)  # slope
        self.b = torch.randn(num_classes, requires_grad=True)  # intercept

        self.criterion = torch.nn.CrossEntropyLoss()
        self.optimizer = torch.optim.SGD([self.W,self.b], self.lr)

        self.fitted = False

        self.loss_history = []

    def forward(self, X):
        return X @ self.W + self.b
    
    def fit(self, X,y):
        # Convert to PyTorch tensors
        X = torch.tensor(X, dtype=torch.float32)
        y = torch.tensor(y, dtype=torch.long)
        
        # # Store statistics for confidence intervals
        # self.X_mean = float(np.mean(X))
        # self.X_var = float(np.var(X, ddof=1))  # Sample variance
        
        # Training loop
        prev_loss = float('inf')
        
        for epoch in range(self.max_epoch):
            # Zero gradients
            self.optimizer.zero_grad()
            
            # Forward pass
            y_pred = self.forward(X)

            # Compute loss
            loss = self.criterion(y_pred, y)
            
            # Backward pass
            loss.backward()
            
            # Update parameters
            self.optimizer.step()

             # Print progress every 100 epochs
            if (epoch + 1) % 100 == 0:
                print(f'Epoch [{epoch+1}/{self.max_epoch}], Loss: {loss.item():.4f}')
            
            # Store loss history
            current_loss = loss.item()
            self.loss_history.append(current_loss)
            
            # Check for convergence
            if abs(prev_loss - current_loss) < self.tol:
                print(f"Converged after {epoch + 1} epochs")
                break
            
            prev_loss = current_loss

        self.fitted = True
        return self

    def predict(self, X):
        if not self.fitted:
            raise ValueError("Model must be fitted before making predictions")
        
        X_tensor = torch.tensor(X, dtype=torch.float32)
        
        with torch.no_grad():
            logits = self.forward(X_tensor)
            predictions = torch.softmax(logits, dim=1)
        
        return torch.argmax(predictions, dim=1)

    def getParams(self):
        if not self.fitted:
            raise ValueError("Model must be fitted before accessing parameters")
        
        return self.W, self.b
    
    def plotLossHistory(self):
        plt.plot(self.loss_history)
        plt.title('Training Loss',fontsize=20)
        plt.xlabel('Epoch',fontsize=20)
        plt.ylabel('Loss Over Training',fontsize=20)
        plt.grid(True)
        plt.show()

    def labelBarGraph(self, y):
        # get bar plot of the class values present in data
        label_counts = y.value_counts()
        print(label_counts, label_counts.sum())
        bars = plt.barh(label_counts['class'],label_counts['count'])
        plt.xticks(fontsize=20)  # Set x-axis tick label font size
        plt.yticks(fontsize=20) 
        plt.bar_label(bars, label_type='edge',fontsize=20)
        plt.title("Malware Classes Present in VirusShare Dataset",fontsize=20)
        plt.show()

    def chartLabel(self, y, typeName:str="All Data"):
        label_counts = y.value_counts()
        print(label_counts, label_counts.sum())
        bars = plt.barh(label_counts['class'],label_counts['count'])
        plt.xticks(fontsize=20)  # Set x-axis tick label font size
        plt.yticks(fontsize=20) 
        plt.bar_label(bars, label_type='edge',fontsize=20)
        #type name should be either "All Data", "Training", "Testing"
        plt.title(f"Malware Classes Present - {typeName} ",fontsize=20)
        plt.show()


    def calculateCI(self):
        pass

# def preprocessAPIs(self):
#         # break out from one feature to each then encode
#         pass


if __name__ == "__main__":
    # load dataset
    data = p.read_csv('/home/radioactiveshrimp/586paper/data/VirusShare.csv')
    y = data['class']
    # print(type(y))
    # print(data)
    #labelBarGraph(y)
    encoder = LabelEncoder()
    y = encoder.fit_transform(y)
    
        
    # preprocess data to separate api calls per sample
    apiCalls = data.with_columns(p.col("api").str.split(','))
    explodedApis = apiCalls.explode("api")
    explodedApis = explodedApis.with_columns(p.lit(1).alias("value"))
    presentApis = explodedApis.pivot(on='api',values="value", index='file', aggregate_function="first").fill_null(0) 
    # presentApis.write_csv("presentApis.csv")
    print(presentApis.shape)
    # print(presentApis)

    # at this point data is split into 19000+ cols (one for each api call)
    # Convert to sparse matrix for further processing
    X = presentApis.drop("file")
    # print(X)

    print(type(X)) #polars DF
    X = X.to_numpy()

    X_sparse = csr_matrix(X)

    # reduce componants
    svd = TruncatedSVD(
        n_components=400,  # explained variance vals 400-.955, 550-97, 750 - .98 850 - 98.5
        random_state=42
    )

    X_reduced = svd.fit_transform(X_sparse)
    # print(svd.explained_variance_)
    print("explained sum:",svd.explained_variance_ratio_.sum())

    print("reduced shape:",X_reduced.shape)

    X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=.25, random_state=0,stratify=y)
    model = MalwareClassifier(X_train, X_train.shape[1], len(np.unique(y)))
    # print(model.W, model.W.shape)
    model.fit(X_train, y_train)
    print("FITTED:", model.fitted)
    preds = model.predict(X_test)

    print(y_test, preds)
    # preds_decoded= encoder.inverse_transform(preds)
    # print(preds_decoded)
    
    print("\nAccuracy:", accuracy_score(y_test, preds))
    print("\nClassification Report:")
    print(classification_report(y_test, preds))

    # model.plotLossHistory()

    model.chartLabel(p.Series("class",y_train), "Training Data")
    model.chartLabel(p.Series("class",y_test), "Testing Data")
