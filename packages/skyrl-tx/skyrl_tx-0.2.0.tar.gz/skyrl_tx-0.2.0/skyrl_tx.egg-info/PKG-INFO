Metadata-Version: 2.4
Name: skyrl-tx
Version: 0.2.0
Summary: Unified API for training and inference
Requires-Python: >=3.11
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: datasets>=4.0.0
Requires-Dist: flax>=0.12.0
Requires-Dist: optax>=0.2.5
Requires-Dist: pillow>=11.3.0
Requires-Dist: rich>=14.1.0
Requires-Dist: safetensors>=0.6.2
Requires-Dist: transformers>=4.56.1
Requires-Dist: typer>=0.17.4
Requires-Dist: peft
Requires-Dist: hf_transfer
Requires-Dist: cloudpathlib>=0.23.0
Requires-Dist: jax>=0.8
Provides-Extra: gpu
Requires-Dist: jax[cuda12]>=0.7.2; extra == "gpu"
Provides-Extra: tpu
Requires-Dist: jax[tpu]>=0.7.2; extra == "tpu"
Provides-Extra: tinker
Requires-Dist: tinker>=0.2.1; extra == "tinker"
Requires-Dist: fastapi[standard]; extra == "tinker"
Requires-Dist: sqlmodel; extra == "tinker"
Requires-Dist: sqlalchemy[asyncio]; extra == "tinker"
Requires-Dist: aiosqlite; extra == "tinker"
Requires-Dist: asyncpg; extra == "tinker"
Requires-Dist: psycopg2-binary; extra == "tinker"
Provides-Extra: aws
Requires-Dist: cloudpathlib[s3]; extra == "aws"
Provides-Extra: gcp
Requires-Dist: cloudpathlib[gs]; extra == "gcp"
Provides-Extra: azure
Requires-Dist: cloudpathlib[azure]; extra == "azure"
Provides-Extra: dev
Requires-Dist: mkdocs; extra == "dev"
Requires-Dist: mkdocs-material; extra == "dev"
Requires-Dist: pytest; extra == "dev"
Requires-Dist: pytest-forked; extra == "dev"
Requires-Dist: torch; extra == "dev"
Requires-Dist: ty; extra == "dev"
Requires-Dist: cloudpathlib[s3]; extra == "dev"
Dynamic: license-file

# SkyRL tx: Unified API for training and inference

> ‚ö†Ô∏è  The project is currently very early with lots of missing features
> (e.g. currently LoRA is only supported for the MLP layer, model sharding
> is in a very early state). Many of these are easy to implement and we
> welcome contributions! ‚ö†Ô∏è


SkyRL tx is an open-source cross-platform library that allows users to
set up their own service exposing a
[Tinker](https://tinker-docs.thinkingmachines.ai/) like REST API for
neural network forward and backward passes. It unifies inference and
training into a single, common API, abstracting away the
infrastructure challenges of managing GPUs.

The `t` in `tx` stands for transformers, training, or tinker, and the `x`
stands for "cross-platform".

## Getting Started
See the following SkyRL tx blog posts for more info and examples:
- [Initial blog post](https://novasky-ai.notion.site/skyrl-tx) with the piglatin training example
- [v0.0.2 release](https://novasky-ai.notion.site/skyrl-tx-v002) with a `Qwen/Qwen3-4B` training example
- [v0.0.3 release](https://novasky-ai.notion.site/skyrl-tx-003) with a `Qwen/Qwen3-Coder-30B-A3B` training and a sampling example
- [v0.1.0 release](https://novasky-ai.notion.site/skyrl-tx-v010) with an end-to-end RL example

See also our talk [SkyRL tx: A unified training and inference engine](https://docs.google.com/presentation/d/1g-u8zxz7FsnlQXXShBVoqjUJhS48c6rxkJJJn0sj78A/view) at Ray Summit 2025.

## Features

### ‚úÖ Implemented
- **Training**: MultiLoRA fine-tuning with gradient accumulation
- **Inference**: Text generation with
  - Temperature sampling
  - Stop token support
- **API**: REST API compatible with Tinker specification

### üöß In Progress
- Model sharding improvements
- Additional LoRA layer support

## Project Status

This is a very early release of SkyRL tx. While the project is
functional end-to-end, there is still a lot of work to be done. We are
sharing it with the community to invite feedback, testing, and
contributions.
