"""
ðŸ§  MirrorMind: Self-Learning AGI Framework
========================================

A unified framework where a model learns to improve itself by:
1. Getting feedback from environment
2. Analyzing its own performance
3. Adapting its weights/biases dynamically
4. Improving its learning strategy itself

The Framework = Stabilizer/Suppressor for the Model (Gun)
Model learns, Framework guides and improves that learning process.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import AdamW
from torch.utils.data import DataLoader, TensorDataset
from dataclasses import dataclass, field
from typing import Tuple, Dict, List, Optional, Any, Callable
import numpy as np
from collections import deque
import json
from pathlib import Path
from abc import ABC, abstractmethod
import logging
from datetime import datetime


# ==================== CONFIGURATION ====================

@dataclass
class FrameworkConfig:
    """Configuration for the self-learning framework"""
    # Model architecture
    model_dim: int = 256
    num_layers: int = 6
    num_heads: int = 8
    ff_dim: int = 1024
    dropout: float = 0.1
    
    # Learning parameters
    learning_rate: float = 1e-3
    meta_learning_rate: float = 1e-4
    batch_size: int = 32
    epochs: int = 10
    
    # Adaptation parameters
    weight_adaptation_lr: float = 1e-5  # Learning rate for weight adjustment
    bias_adaptation_lr: float = 1e-5
    
    # Framework parameters
    feedback_buffer_size: int = 10000
    evaluation_frequency: int = 100  # Evaluate and adapt every N steps
    adaptation_threshold: float = 0.05  # Adapt weights if loss improvement < 5%
    
    # Meta-learning
    inner_loop_steps: int = 5  # MAML-style inner loop iterations
    outer_loop_steps: int = 1
    
    # Logging
    log_frequency: int = 50
    checkpoint_frequency: int = 500


@dataclass
class FeedbackData:
    """Structure for feedback from environment"""
    input_data: torch.Tensor
    output: torch.Tensor
    target: torch.Tensor
    reward: float
    loss: float
    timestamp: float
    episode: int
    
    def to_device(self, device):
        """Move all tensors to device"""
        self.input_data = self.input_data.to(device)
        self.output = self.output.to(device)
        self.target = self.target.to(device)
        return self


@dataclass
class MetricsSnapshot:
    """Snapshot of model performance metrics"""
    timestamp: float
    episode: int
    step: int
    train_loss: float
    eval_loss: float
    adaptation_needed: bool
    weight_adaptation_magnitude: float
    bias_adaptation_magnitude: float
    learning_efficiency: float
    metadata: Dict[str, Any] = field(default_factory=dict)


# ==================== CORE MODEL ====================

class SelfLearningModel(nn.Module):
    """
    A model with introspection capability - it can analyze its own performance
    and adjust its learning strategy.
    """
    
    def __init__(self, config: FrameworkConfig):
        super().__init__()
        self.config = config
        
        # Main transformer layers
        self.embedding = nn.Linear(config.model_dim, config.model_dim)
        
        self.transformer_layers = nn.ModuleList([
            nn.TransformerEncoderLayer(
                d_model=config.model_dim,
                nhead=config.num_heads,
                dim_feedforward=config.ff_dim,
                dropout=config.dropout,
                batch_first=True
            ) for _ in range(config.num_layers)
        ])
        
        # Self-reflection components
        self.reflection_head = nn.Sequential(
            nn.Linear(config.model_dim, config.model_dim // 2),
            nn.ReLU(),
            nn.Linear(config.model_dim // 2, 1)  # Confidence score
        )
        
        # Output heads
        self.output_head = nn.Linear(config.model_dim, config.model_dim)
        self.uncertainty_head = nn.Linear(config.model_dim, 1)
        
    def forward(self, x, return_internals=False):
        """
        Forward pass with optional internal state return for introspection
        
        Args:
            x: Input tensor
            return_internals: If True, return intermediate activations
            
        Returns:
            output: Model output
            internals: (optional) Dictionary with internal representations
        """
        batch_size, seq_len, _ = x.shape
        
        # Embed input
        x = self.embedding(x)
        internals = {'embeddings': x.clone()}
        
        # Apply transformer layers
        for i, layer in enumerate(self.transformer_layers):
            x = layer(x)
            internals[f'layer_{i}'] = x.clone()
        
        # Self-reflection
        confidence = self.reflection_head(x)
        internals['confidence'] = confidence
        
        # Generate output
        output = self.output_head(x)
        uncertainty = self.uncertainty_head(x)
        
        if return_internals:
            return output, uncertainty, internals
        return output, uncertainty


# ==================== ADAPTIVE WEIGHT MANAGER ====================

class AdaptiveWeightManager:
    """
    Meta-learning component that adjusts model weights based on performance feedback.
    This is the "stabilizer/suppressor" that improves the learning process.
    """
    
    def __init__(self, model: SelfLearningModel, config: FrameworkConfig, device):
        self.model = model
        self.config = config
        self.device = device
        self.logger = logging.getLogger('AdaptiveWeightManager')
        
        # Track weight adaptation history
        self.weight_adaptation_history = deque(maxlen=1000)
        self.bias_adaptation_history = deque(maxlen=1000)
        
    def compute_layer_importance(self, activations: Dict[str, torch.Tensor]) -> Dict[str, float]:
        """
        Compute importance scores for each layer based on activation patterns.
        Layers with high variance in activations are more "important" for learning.
        """
        importance_scores = {}
        
        for layer_name, activation in activations.items():
            if 'layer_' in layer_name:
                # Compute activation statistics
                mean_activation = activation.abs().mean()
                std_activation = activation.std()
                activation_sparsity = (activation.abs() < 0.01).float().mean()
                
                # Importance = how much this layer "fires"
                importance = mean_activation * std_activation * (1 - activation_sparsity)
                importance_scores[layer_name] = float(importance)
        
        return importance_scores
    
    def compute_gradient_statistics(self, loss: torch.Tensor) -> Dict[str, float]:
        """Compute gradient statistics for adaptation decisions"""
        loss.backward(retain_graph=True)
        
        grad_stats = {
            'mean_grad': 0,
            'max_grad': 0,
            'min_grad': 0,
            'grad_variance': 0
        }
        
        total_grad_norm = 0
        num_params = 0
        
        for param in self.model.parameters():
            if param.grad is not None:
                total_grad_norm += param.grad.data.norm(2).item()
                num_params += 1
        
        grad_stats['mean_grad'] = total_grad_norm / max(num_params, 1)
        
        return grad_stats
    
    def adapt_weights(self, 
                     current_loss: float, 
                     previous_loss: float,
                     activations: Dict[str, torch.Tensor]) -> Tuple[float, float]:
        """
        Adapt model weights based on loss trajectory and layer importance.
        
        Returns:
            (weight_adaptation_magnitude, bias_adaptation_magnitude)
        """
        loss_improvement = (previous_loss - current_loss) / (previous_loss + 1e-9)
        
        # If loss is not improving sufficiently, adapt more aggressively
        adaptation_magnitude = 0.0
        
        if loss_improvement < self.config.adaptation_threshold:
            # Compute layer importance
            importance_scores = self.compute_layer_importance(activations)
            
            # Adapt weights with magnitude based on layer importance
            with torch.no_grad():
                for name, param in self.model.named_parameters():
                    if param.requires_grad:
                        # Compute adaptation based on layer importance
                        layer_importance = 0.5  # Default
                        for layer_name, importance in importance_scores.items():
                            if layer_name in name:
                                layer_importance = importance
                        
                        # Apply adaptive noise/regularization
                        adaptation = torch.randn_like(param) * self.config.weight_adaptation_lr * layer_importance
                        param.data += adaptation
                        adaptation_magnitude += adaptation.abs().mean().item()
        
        self.weight_adaptation_history.append(adaptation_magnitude)
        
        return adaptation_magnitude, 0.0  # bias adaptation not shown for brevity


# ==================== FEEDBACK COLLECTOR ====================

class FeedbackCollector:
    """Collects and manages feedback from the environment"""
    
    def __init__(self, config: FrameworkConfig, device):
        self.config = config
        self.device = device
        self.feedback_buffer = deque(maxlen=config.feedback_buffer_size)
        self.episode_count = 0
        self.step_count = 0
        
    def add_feedback(self, 
                    input_data: torch.Tensor,
                    output: torch.Tensor,
                    target: torch.Tensor,
                    reward: float,
                    loss: float):
        """Add feedback to the buffer"""
        feedback = FeedbackData(
            input_data=input_data.cpu().clone(),
            output=output.cpu().clone(),
            target=target.cpu().clone(),
            reward=reward,
            loss=loss,
            timestamp=datetime.now().timestamp(),
            episode=self.episode_count
        )
        self.feedback_buffer.append(feedback)
        self.step_count += 1
        
    def get_batch(self, batch_size: int) -> Optional[List[FeedbackData]]:
        """Sample a random batch from feedback buffer"""
        if len(self.feedback_buffer) < batch_size:
            return None
        
        indices = np.random.choice(len(self.feedback_buffer), batch_size, replace=False)
        return [list(self.feedback_buffer)[i] for i in indices]
    
    def get_recent_batch(self, batch_size: int) -> Optional[List[FeedbackData]]:
        """Get recent feedback (for on-policy learning)"""
        if len(self.feedback_buffer) < batch_size:
            return None
        
        return list(self.feedback_buffer)[-batch_size:]
    
    def new_episode(self):
        """Mark start of new episode"""
        self.episode_count += 1


# ==================== SELF-LEARNING FRAMEWORK ====================

class SelfLearningFramework:
    """
    Main framework that orchestrates the self-learning loop.
    This is where the model learns and improves itself.
    """
    
    def __init__(self, config: FrameworkConfig, device=None):
        if device is None:
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        self.device = device
        self.config = config
        self.logger = self._setup_logging()
        
        # Core components
        self.model = SelfLearningModel(config).to(device)
        self.weight_manager = AdaptiveWeightManager(self.model, config, device)
        self.feedback_collector = FeedbackCollector(config, device)
        
        # Optimizer
        self.optimizer = AdamW(self.model.parameters(), lr=config.learning_rate)
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, T_max=config.epochs
        )
        
        # Metrics
        self.metrics_history: List[MetricsSnapshot] = []
        self.loss_history = deque(maxlen=config.evaluation_frequency)
        
        self.step_count = 0
        self.epoch_count = 0
        
    def _setup_logging(self) -> logging.Logger:
        """Setup logging for the framework"""
        logger = logging.getLogger('SelfLearningFramework')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Forward pass through the model
        
        Args:
            x: Input tensor
            
        Returns:
            output, uncertainty
        """
        x = x.to(self.device)
        with torch.no_grad():
            output, uncertainty = self.model(x, return_internals=False)
        return output, uncertainty
    
    def train_step(self, 
                  input_data: torch.Tensor,
                  target: torch.Tensor) -> Dict[str, float]:
        """
        Single training step with introspection and adaptation
        
        Returns:
            Dictionary with metrics
        """
        input_data = input_data.to(self.device)
        target = target.to(self.device)
        
        # Forward pass with internals
        output, uncertainty, internals = self.model(input_data, return_internals=True)
        
        # Compute loss
        loss = F.mse_loss(output, target)
        
        # Backward pass
        self.optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
        self.optimizer.step()
        
        metrics = {
            'loss': loss.item(),
            'uncertainty_mean': uncertainty.mean().item()
        }
        
        # Add to loss history
        self.loss_history.append(loss.item())
        
        # Periodic adaptation
        if self.step_count % self.config.evaluation_frequency == 0:
            if len(self.loss_history) > 1:
                current_loss = np.mean(list(self.loss_history)[-10:])
                previous_loss = np.mean(list(self.loss_history)[-20:-10])
                
                weight_adapt_mag, bias_adapt_mag = self.weight_manager.adapt_weights(
                    current_loss, previous_loss, internals
                )
                
                metrics['weight_adaptation_magnitude'] = weight_adapt_mag
                metrics['bias_adaptation_magnitude'] = bias_adapt_mag
        
        self.step_count += 1
        
        return metrics
    
    def evaluate(self, 
                input_data: torch.Tensor,
                target: torch.Tensor) -> Dict[str, float]:
        """
        Evaluate model on validation data
        
        Returns:
            Evaluation metrics
        """
        input_data = input_data.to(self.device)
        target = target.to(self.device)
        
        self.model.eval()
        with torch.no_grad():
            output, uncertainty = self.model(input_data, return_internals=False)
            loss = F.mse_loss(output, target)
        self.model.train()
        
        return {
            'eval_loss': loss.item(),
            'uncertainty_mean': uncertainty.mean().item()
        }
    
    def learn_from_feedback(self, 
                           feedback_batch: List[FeedbackData],
                           num_epochs: int = 1) -> Dict[str, float]:
        """
        Learn from collected feedback
        
        Args:
            feedback_batch: List of FeedbackData objects
            num_epochs: Number of epochs to train
            
        Returns:
            Aggregate metrics
        """
        if not feedback_batch:
            return {}
        
        # Prepare batch
        inputs = torch.stack([f.input_data for f in feedback_batch]).to(self.device)
        targets = torch.stack([f.target for f in feedback_batch]).to(self.device)
        
        epoch_metrics = []
        
        for epoch in range(num_epochs):
            self.model.train()
            metrics = self.train_step(inputs, targets)
            epoch_metrics.append(metrics)
            
            if (epoch + 1) % self.config.log_frequency == 0:
                self.logger.info(f"Epoch {epoch + 1}/{num_epochs}: Loss = {metrics['loss']:.4f}")
        
        return {
            'avg_loss': np.mean([m['loss'] for m in epoch_metrics]),
            'final_loss': epoch_metrics[-1]['loss'] if epoch_metrics else 0
        }
    
    def save_checkpoint(self, path: str):
        """Save model checkpoint"""
        Path(path).parent.mkdir(parents=True, exist_ok=True)
        torch.save({
            'model_state': self.model.state_dict(),
            'optimizer_state': self.optimizer.state_dict(),
            'config': self.config,
            'metrics': self.metrics_history,
            'step_count': self.step_count,
            'epoch_count': self.epoch_count
        }, path)
        self.logger.info(f"Checkpoint saved to {path}")
    
    def load_checkpoint(self, path: str):
        """Load model checkpoint"""
        checkpoint = torch.load(path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state'])
        self.metrics_history = checkpoint.get('metrics', [])
        self.step_count = checkpoint.get('step_count', 0)
        self.epoch_count = checkpoint.get('epoch_count', 0)
        self.logger.info(f"Checkpoint loaded from {path}")
    
    def get_metrics_summary(self) -> Dict[str, Any]:
        """Get summary of all metrics collected so far"""
        if not self.metrics_history:
            return {}
        
        recent_metrics = self.metrics_history[-100:]
        
        return {
            'total_steps': self.step_count,
            'total_epochs': self.epoch_count,
            'avg_recent_loss': np.mean([m.train_loss for m in recent_metrics]),
            'best_loss': min([m.train_loss for m in self.metrics_history]),
            'adaptations_triggered': sum([1 for m in self.metrics_history if m.adaptation_needed]),
            'learning_efficiency': np.mean([m.learning_efficiency for m in recent_metrics])
        }


# ==================== SIMPLE USAGE EXAMPLE ====================

if __name__ == "__main__":
    # Create framework
    config = FrameworkConfig(
        model_dim=128,
        num_layers=4,
        num_heads=4,
        batch_size=16
    )
    
    framework = SelfLearningFramework(config)
    
    print("ðŸ§  MirrorMind Self-Learning Framework initialized")
    print(f"Device: {framework.device}")
    print(f"Model parameters: {sum(p.numel() for p in framework.model.parameters()):,}")
    
    # Generate dummy data
    batch_size = 16
    seq_len = 10
    model_dim = 128
    
    X = torch.randn(batch_size, seq_len, model_dim)
    y = torch.randn(batch_size, seq_len, model_dim)
    
    # Training loop
    print("\nðŸš€ Starting self-learning loop...")
    for epoch in range(3):
        framework.model.train()
        metrics = framework.train_step(X, y)
        print(f"Epoch {epoch}: Loss = {metrics['loss']:.4f}")
    
    print("\nâœ… Framework is working!")
