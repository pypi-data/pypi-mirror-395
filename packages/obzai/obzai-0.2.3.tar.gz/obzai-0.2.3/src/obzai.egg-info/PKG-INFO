Metadata-Version: 2.4
Name: obzai
Version: 0.2.3
Summary: Explainable AI, Model Monitoring, and Outlier Detection Tools for Computer Vision Systems
Author-email: Obz AI <hi@obz.ai>
Maintainer-email: Jakub Binda <binkuba@gmail.com>, Neo Christopher Chung <nchchung@gmail.com>
License: GPL-3.0
Project-URL: Homepage, https://obz.ai
Project-URL: Source, https://github.com/alethia-xai/obzai
Keywords: Explainable AI,AI Monitoring,Model Interpretability,Computer Vision,Feature Importance,Explainability,Anomaly Detection,Data Drift,Outlier,Observability,Attention Maps,Saliency Maps
Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Operating System :: OS Independent
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: Education
Classifier: Topic :: Scientific/Engineering
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch>=2.1.0
Requires-Dist: torchvision>=0.16
Requires-Dist: transformers[torch]>=4.40.0
Requires-Dist: accelerate>=0.26.0
Requires-Dist: timm>=0.9.0
Requires-Dist: captum>=0.6.0
Requires-Dist: numpy>=2.0.0
Requires-Dist: pandas>=2.0.0
Requires-Dist: scipy>=1.9.0
Requires-Dist: scikit-learn>=1.2.0
Requires-Dist: scikit-image>=0.19.0
Requires-Dist: umap-learn>=0.5.5
Requires-Dist: matplotlib>=3.8.0
Requires-Dist: cmasher>=1.7.0
Requires-Dist: tqdm>=4.65.0
Requires-Dist: pillow>=10.0.0
Requires-Dist: ipywidgets>=8.1.0
Requires-Dist: httpx>=0.26.0
Requires-Dist: pyarrow>=19.0.0
Provides-Extra: dev
Requires-Dist: pytest>=8.4.0; extra == "dev"
Requires-Dist: pytest-cov==6.3.0; extra == "dev"
Dynamic: license-file

# Obz AI üîç: Explainable AI, Model Monitoring, and Outlier Detection for Computer Vision Systems

Obz AI is a powerful Python package designed to bring explainability, continuous monitoring, and advanced outlier detection to AI-powered computer vision systems. With support for the latest deep learning architectures -- including vision transformers (ViT) and convolutional neural networks (CNN) -- Obz AI enables ML practitioners and data scientists to ensure transparency, reliability, and trustworthiness in their vision models.

Obz AI offers seamless integration, allowing you to use its robust features as a standalone tool or connect effortlessly to the dashboard for real-time model monitoring, data visualization, and configuration. Track your machine learning models, visualize image data, generate XAI (Explainable AI) heatmaps, and perform anomaly detection.

For more details, demo, and full documentation, visit [Obz.AI](https://obz.ai/).

## Key Features

- **Data Inspector Module**: Automatically extracts features and detects outliers, data drifts, or other anomalies in image datasets using advanced statistical and machine learning methods ‚Äî improving data quality and model robustness.
- **XAI Module**:  Generates state-of-the-art explainability heatmaps for computer vision models, including Saliency Maps, Attention Maps, CDAM, and more. Provides quantitative evaluation tools such as fidelity and compactness for model interpretability and explainability.
- **Obz Client**: Effortlessly log and monitor your models, inputs, outputs, and XAI explanations to the Obz AI server (cloud or on-prem) for comprehensive oversight and user-friendly visualization.

Obz AI is the all-in-one solution for anyone building, deploying, or monitoring computer vision models -- empowering explainable, reliable, and secure AI applications.
