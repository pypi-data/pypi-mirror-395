#!/usr/bin/env python3
"""
é…ç½®å¯¼å‡ºæœåŠ¡

æä¾›é…ç½®å¿«ç…§çš„å¯¼å‡ºåŠŸèƒ½ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œè¾“å‡ºæ–¹å¼
"""

import asyncio
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

from mcpstore.config.toml_config import get_config
from mcpstore.core.configuration.config_snapshot import (
    ConfigSnapshot, ConfigSnapshotFormatter, ConfigSnapshotError
)
from mcpstore.core.configuration.config_snapshot_generator import ConfigSnapshotGenerator

logger = logging.getLogger(__name__)


class ConfigExportService:
    """é…ç½®å¯¼å‡ºæœåŠ¡"""

    def __init__(self):
        """åˆå§‹åŒ–é…ç½®å¯¼å‡ºæœåŠ¡"""
        self.generator = None
        self._init_generator()

    def _init_generator(self):
        """åˆå§‹åŒ–å¿«ç…§ç”Ÿæˆå™¨"""
        try:
            config = get_config()
            self.generator = ConfigSnapshotGenerator(config)
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–é…ç½®å¿«ç…§ç”Ÿæˆå™¨å¤±è´¥: {e}")
            raise ConfigSnapshotError(f"æ— æ³•åˆå§‹åŒ–é…ç½®å¯¼å‡ºæœåŠ¡: {e}")

    async def export_config(self,
                           format: str = "table",
                           categories: Optional[List[str]] = None,
                           key_pattern: Optional[str] = None,
                           include_sensitive: bool = False,
                           output_file: Optional[Union[str, Path]] = None,
                           mask_sensitive: bool = True) -> str:
        """
        å¯¼å‡ºé…ç½®å¿«ç…§

        Args:
            format: è¾“å‡ºæ ¼å¼ ("json", "yaml", "table")
            categories: è¦åŒ…å«çš„é…ç½®åˆ†ç±»åˆ—è¡¨
            key_pattern: é”®åè¿‡æ»¤æ¨¡å¼ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰
            include_sensitive: æ˜¯å¦åŒ…å«æ•æ„Ÿé…ç½®
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ŒNone è¡¨ç¤ºè¿”å›å­—ç¬¦ä¸²
            mask_sensitive: æ˜¯å¦å±è”½æ•æ„Ÿé…ç½®å€¼

        Returns:
            str: é…ç½®å¿«ç…§å†…å®¹ï¼ˆå¦‚æœ output_file ä¸º Noneï¼‰

        Raises:
            ConfigSnapshotError: å¯¼å‡ºè¿‡ç¨‹ä¸­çš„é”™è¯¯
        """
        if not self.generator:
            raise ConfigSnapshotError("é…ç½®å¿«ç…§ç”Ÿæˆå™¨æœªåˆå§‹åŒ–")

        # éªŒè¯æ ¼å¼
        if format not in ["json", "yaml", "table"]:
            raise ConfigSnapshotError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}ï¼Œæ”¯æŒçš„æ ¼å¼: json, yaml, table")

        try:
            # ç”Ÿæˆé…ç½®å¿«ç…§
            snapshot = await self.generator.generate_snapshot(
                categories=categories,
                key_pattern=key_pattern,
                include_sensitive=include_sensitive
            )

            # æ ¼å¼åŒ–è¾“å‡º
            if format == "json":
                content = ConfigSnapshotFormatter.format_json(snapshot, mask_sensitive=mask_sensitive)
            elif format == "yaml":
                content = ConfigSnapshotFormatter.format_yaml(snapshot, mask_sensitive=mask_sensitive)
            else:  # table
                content = ConfigSnapshotFormatter.format_table(
                    snapshot, mask_sensitive=mask_sensitive, max_width=120
                )

            # è¾“å‡ºåˆ°æ–‡ä»¶æˆ–è¿”å›å­—ç¬¦ä¸²
            if output_file:
                await self._write_to_file(content, output_file)
                return f"é…ç½®å·²å¯¼å‡ºåˆ°: {output_file}"
            else:
                return content

        except Exception as e:
            logger.error(f"å¯¼å‡ºé…ç½®å¤±è´¥: {e}")
            raise ConfigSnapshotError(f"å¯¼å‡ºé…ç½®å¤±è´¥: {e}")

    async def _write_to_file(self, content: str, file_path: Union[str, Path]):
        """å†™å…¥å†…å®¹åˆ°æ–‡ä»¶"""
        try:
            path = Path(file_path)
            path.parent.mkdir(parents=True, exist_ok=True)

            with open(path, 'w', encoding='utf-8') as f:
                f.write(content)

            logger.info(f"é…ç½®å¿«ç…§å·²ä¿å­˜åˆ°: {path}")
        except Exception as e:
            raise ConfigSnapshotError(f"å†™å…¥æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

    async def get_config_summary(self) -> Dict[str, Any]:
        """
        è·å–é…ç½®æ‘˜è¦ä¿¡æ¯

        Returns:
            Dict[str, Any]: é…ç½®æ‘˜è¦
        """
        if not self.generator:
            raise ConfigSnapshotError("é…ç½®å¿«ç…§ç”Ÿæˆå™¨æœªåˆå§‹åŒ–")

        try:
            # ç”Ÿæˆå¿«ç…§ï¼ˆä¸åŒ…å«æ•æ„Ÿé…ç½®ï¼‰
            snapshot = await self.generator.generate_snapshot(include_sensitive=False)

            summary = {
                "timestamp": snapshot.timestamp.isoformat(),
                "total_items": snapshot.total_items,
                "group_count": len(snapshot.groups),
                "source_distribution": {
                    source.value: count for source, count in snapshot.source_summary.items()
                },
                "groups": {}
            }

            # å„ç»„è¯¦ç»†ä¿¡æ¯
            for group_name, group in snapshot.groups.items():
                summary["groups"][group_name] = {
                    "name": group.name,
                    "item_count": group.item_count,
                    "sensitive_count": group.get_sensitive_count(),
                    "dynamic_count": group.get_dynamic_count()
                }

            return summary

        except Exception as e:
            logger.error(f"è·å–é…ç½®æ‘˜è¦å¤±è´¥: {e}")
            raise ConfigSnapshotError(f"è·å–é…ç½®æ‘˜è¦å¤±è´¥: {e}")

    async def search_config(self,
                           query: str,
                           include_sensitive: bool = False) -> Dict[str, Any]:
        """
        æœç´¢é…ç½®é¡¹

        Args:
            query: æœç´¢æŸ¥è¯¢ï¼ˆé”®åæˆ–æè¿°ï¼‰
            include_sensitive: æ˜¯å¦åŒ…å«æ•æ„Ÿé…ç½®

        Returns:
            Dict[str, Any]: æœç´¢ç»“æœ
        """
        if not self.generator:
            raise ConfigSnapshotError("é…ç½®å¿«ç…§ç”Ÿæˆå™¨æœªåˆå§‹åŒ–")

        try:
            # ä½¿ç”¨æŸ¥è¯¢ä½œä¸ºæ­£åˆ™è¡¨è¾¾å¼è¿‡æ»¤
            snapshot = await self.generator.generate_snapshot(
                key_pattern=query,
                include_sensitive=include_sensitive
            )

            results = []
            for group_name, group in snapshot.groups.items():
                for item in group.items:
                    results.append({
                        "key": item.key,
                        "value": item.value,
                        "source": item.source.value,
                        "category": item.category,
                        "is_sensitive": item.is_sensitive,
                        "is_dynamic": item.is_dynamic,
                        "description": item.description,
                        "validation_info": item.validation_info
                    })

            return {
                "query": query,
                "timestamp": snapshot.timestamp.isoformat(),
                "result_count": len(results),
                "results": results
            }

        except Exception as e:
            logger.error(f"æœç´¢é…ç½®å¤±è´¥: {e}")
            raise ConfigSnapshotError(f"æœç´¢é…ç½®å¤±è´¥: {e}")

    async def validate_config(self) -> Dict[str, Any]:
        """
        éªŒè¯é…ç½®çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§

        Returns:
            Dict[str, Any]: éªŒè¯ç»“æœ
        """
        if not self.generator:
            raise ConfigSnapshotError("é…ç½®å¿«ç…§ç”Ÿæˆå™¨æœªåˆå§‹åŒ–")

        try:
            # ç”Ÿæˆå®Œæ•´å¿«ç…§
            snapshot = await self.generator.generate_snapshot(include_sensitive=True)

            validation_result = {
                "timestamp": snapshot.timestamp.isoformat(),
                "total_items": snapshot.total_items,
                "valid": True,
                "warnings": [],
                "errors": [],
                "statistics": {
                    "source_distribution": {
                        source.value: count for source, count in snapshot.source_summary.items()
                    },
                    "category_distribution": {},
                    "sensitive_items": 0,
                    "dynamic_items": 0
                }
            }

            # ç»Ÿè®¡å„ç±»é…ç½®
            for group_name, group in snapshot.groups.items():
                validation_result["statistics"]["category_distribution"][group_name] = group.item_count
                validation_result["statistics"]["sensitive_items"] += group.get_sensitive_count()
                validation_result["statistics"]["dynamic_items"] += group.get_dynamic_count()

            # æ£€æŸ¥é…ç½®ä¸€è‡´æ€§
            for group_name, group in snapshot.groups.items():
                for item in group.items:
                    # æ£€æŸ¥æ— æ•ˆçš„æ¥æº
                    if item.source.value not in ["default", "toml", "kv", "env"]:
                        validation_result["warnings"].append(
                            f"é…ç½®é¡¹ {item.key} å…·æœ‰æœªçŸ¥çš„æ¥æº: {item.source.value}"
                        )

                    # æ£€æŸ¥ç©ºå€¼
                    if item.value is None or item.value == "":
                        validation_result["warnings"].append(
                            f"é…ç½®é¡¹ {item.key} å€¼ä¸ºç©º"
                        )

            # å¦‚æœæœ‰é”™è¯¯ï¼Œæ ‡è®°ä¸ºæ— æ•ˆ
            if validation_result["errors"]:
                validation_result["valid"] = False

            return validation_result

        except Exception as e:
            logger.error(f"éªŒè¯é…ç½®å¤±è´¥: {e}")
            raise ConfigSnapshotError(f"éªŒè¯é…ç½®å¤±è´¥: {e}")

    async def export_diff(self,
                         baseline_file: Union[str, Path],
                         format: str = "table",
                         output_file: Optional[Union[str, Path]] = None) -> str:
        """
        å¯¼å‡ºå½“å‰é…ç½®ä¸åŸºçº¿çš„å·®å¼‚

        Args:
            baseline_file: åŸºçº¿é…ç½®æ–‡ä»¶è·¯å¾„
            format: è¾“å‡ºæ ¼å¼ ("json", "yaml", "table")
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            str: å·®å¼‚æŠ¥å‘Šå†…å®¹
        """
        try:
            # è¯»å–åŸºçº¿é…ç½®
            baseline_path = Path(baseline_file)
            if not baseline_path.exists():
                raise ConfigSnapshotError(f"åŸºçº¿æ–‡ä»¶ä¸å­˜åœ¨: {baseline_file}")

            import json
            with open(baseline_path, 'r', encoding='utf-8') as f:
                if baseline_path.suffix.lower() == '.json':
                    baseline_data = json.load(f)
                else:
                    # ç®€å•è§£æï¼Œå‡è®¾æ˜¯é”®å€¼å¯¹æ ¼å¼
                    baseline_data = {}
                    for line in f:
                        if '=' in line and not line.strip().startswith('#'):
                            key, value = line.split('=', 1)
                            baseline_data[key.strip()] = value.strip()

            # ç”Ÿæˆå½“å‰é…ç½®å¿«ç…§
            snapshot = await self.generator.generate_snapshot(include_sensitive=True)
            current_config = {item.key: item.value for group in snapshot.groups.values() for item in group.items}

            # è®¡ç®—å·®å¼‚
            diff = {
                "timestamp": snapshot.timestamp.isoformat(),
                "baseline_file": str(baseline_path),
                "added": {},
                "removed": {},
                "modified": {},
                "unchanged": {}
            }

            baseline_keys = set(baseline_data.keys())
            current_keys = set(current_config.keys())

            # æ–°å¢çš„é…ç½®
            for key in current_keys - baseline_keys:
                diff["added"][key] = current_config[key]

            # åˆ é™¤çš„é…ç½®
            for key in baseline_keys - current_keys:
                diff["removed"][key] = baseline_data[key]

            # ä¿®æ”¹çš„é…ç½®
            for key in baseline_keys & current_keys:
                if baseline_data[key] != current_config[key]:
                    diff["modified"][key] = {
                        "old": baseline_data[key],
                        "new": current_config[key]
                    }
                else:
                    diff["unchanged"][key] = current_config[key]

            # æ ¼å¼åŒ–è¾“å‡º
            if format == "json":
                content = json.dumps(diff, indent=2, ensure_ascii=False)
            elif format == "yaml":
                try:
                    import yaml
                    content = yaml.dump(diff, default_flow_style=False, allow_unicode=True)
                except ImportError:
                    content = "# PyYAML not installed, falling back to JSON\n" + \
                             json.dumps(diff, indent=2, ensure_ascii=False)
            else:  # table
                content = self._format_diff_table(diff)

            # è¾“å‡ºåˆ°æ–‡ä»¶æˆ–è¿”å›å­—ç¬¦ä¸²
            if output_file:
                await self._write_to_file(content, output_file)
                return f"é…ç½®å·®å¼‚å·²å¯¼å‡ºåˆ°: {output_file}"
            else:
                return content

        except Exception as e:
            logger.error(f"å¯¼å‡ºé…ç½®å·®å¼‚å¤±è´¥: {e}")
            raise ConfigSnapshotError(f"å¯¼å‡ºé…ç½®å·®å¼‚å¤±è´¥: {e}")

    def _format_diff_table(self, diff: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–å·®å¼‚ä¸ºè¡¨æ ¼"""
        lines = []
        lines.append("=" * 100)
        lines.append(f"é…ç½®å·®å¼‚æŠ¥å‘Š - {diff['timestamp']}")
        lines.append(f"åŸºçº¿æ–‡ä»¶: {diff['baseline_file']}")
        lines.append("=" * 100)

        # æ–°å¢é…ç½®
        if diff["added"]:
            lines.append(f"\nğŸ†• æ–°å¢é…ç½® ({len(diff['added'])} é¡¹):")
            lines.append("-" * 100)
            for key, value in diff["added"].items():
                lines.append(f"  {key:<50} = {value}")

        # åˆ é™¤é…ç½®
        if diff["removed"]:
            lines.append(f"\nâŒ åˆ é™¤é…ç½® ({len(diff['removed'])} é¡¹):")
            lines.append("-" * 100)
            for key, value in diff["removed"].items():
                lines.append(f"  {key:<50} = {value}")

        # ä¿®æ”¹é…ç½®
        if diff["modified"]:
            lines.append(f"\nğŸ”„ ä¿®æ”¹é…ç½® ({len(diff['modified'])} é¡¹):")
            lines.append("-" * 100)
            for key, change in diff["modified"].items():
                lines.append(f"  {key:<50}")
                lines.append(f"    æ—§å€¼: {change['old']}")
                lines.append(f"    æ–°å€¼: {change['new']}")

        # æœªå˜æ›´é…ç½®
        if diff["unchanged"]:
            lines.append(f"\n æœªå˜æ›´é…ç½® ({len(diff['unchanged'])} é¡¹):")
            lines.append("-" * 100)
            for key, value in list(diff["unchanged"].items())[:10]:  # åªæ˜¾ç¤ºå‰10é¡¹
                lines.append(f"  {key:<50} = {value}")
            if len(diff["unchanged"]) > 10:
                lines.append(f"  ... è¿˜æœ‰ {len(diff['unchanged']) - 10} é¡¹æœªå˜æ›´é…ç½®")

        return "\n".join(lines)


# å…¨å±€é…ç½®å¯¼å‡ºæœåŠ¡å®ä¾‹
_export_service: Optional[ConfigExportService] = None


def get_config_export_service() -> ConfigExportService:
    """è·å–å…¨å±€é…ç½®å¯¼å‡ºæœåŠ¡å®ä¾‹"""
    global _export_service
    if _export_service is None:
        _export_service = ConfigExportService()
    return _export_service


# ä¾¿æ·å‡½æ•°
async def export_config_snapshot(**kwargs) -> str:
    """ä¾¿æ·å‡½æ•°ï¼šå¯¼å‡ºé…ç½®å¿«ç…§"""
    service = get_config_export_service()
    return await service.export_config(**kwargs)


async def get_config_summary() -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šè·å–é…ç½®æ‘˜è¦"""
    service = get_config_export_service()
    return await service.get_config_summary()


async def search_config_items(query: str, **kwargs) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šæœç´¢é…ç½®é¡¹"""
    service = get_config_export_service()
    return await service.search_config(query, **kwargs)


async def validate_current_config() -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šéªŒè¯å½“å‰é…ç½®"""
    service = get_config_export_service()
    return await service.validate_config()